{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import keras\n",
    "print(keras.__version__)\n",
    "# from tensorflow import keras as keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>wage_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt  education  education_num  \\\n",
       "0   39         State-gov   77516  Bachelors             13   \n",
       "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2   38           Private  215646    HS-grad              9   \n",
       "3   53           Private  234721       11th              7   \n",
       "4   28           Private  338409  Bachelors             13   \n",
       "\n",
       "       marital_status         occupation   relationship   race     sex  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "   capital_gain  capital_loss  hours_per_week native_country wage_class  \n",
       "0          2174             0              40  United-States      <=50K  \n",
       "1             0             0              13  United-States      <=50K  \n",
       "2             0             0              40  United-States      <=50K  \n",
       "3             0             0              40  United-States      <=50K  \n",
       "4             0             0              40           Cuba      <=50K  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wczytaj dane treningowe i testowe\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "train_set = pd.read_csv('Dane/adult/adult.data', sep=\", \",header = None)\n",
    "test_set = pd.read_csv('Dane/adult/adult.test', sep=\", \",skiprows = 1, header = None) # Make sure to skip a row for the test set\n",
    "\n",
    "col_labels = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', 'occupation', \n",
    "              'relationship', 'race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country',\n",
    "             'wage_class']\n",
    "train_set.columns = col_labels\n",
    "test_set.columns = col_labels\n",
    "\n",
    "train = train_set.replace('?', np.nan).dropna()\n",
    "test = test_set.replace('?', np.nan).dropna()\n",
    "\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.concat([train,test])\n",
    "\n",
    "dataset['wage_class'] = dataset.wage_class.replace({'<=50K.': 0,'<=50K':0, '>50K.':1, '>50K':1})\n",
    "\n",
    "dataset.drop([\"fnlwgt\"],axis=1,inplace=True)\n",
    "\n",
    "dataset.drop([\"education\"],axis=1,inplace=True)\n",
    "\n",
    "x = dataset.groupby('native_country')[\"wage_class\"].mean()\n",
    "\n",
    "d = dict(pd.cut(x[x.index!=\" United-States\"],5,labels=range(5)))\n",
    "\n",
    "dataset['native_country'] = dataset['native_country'].replace(d)\n",
    "\n",
    "dataset = pd.get_dummies(dataset,drop_first=True)\n",
    "\n",
    "train = dataset.iloc[:train.shape[0]]\n",
    "test = dataset.iloc[train.shape[0]:]\n",
    "\n",
    "X_train = train.drop(\"wage_class\",axis=1)\n",
    "y_train = train.wage_class\n",
    "\n",
    "X_test = test.drop(\"wage_class\",axis=1)\n",
    "y_test = test.wage_class\n",
    "\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# sc = StandardScaler()\n",
    "# X_train = sc.fit_transform(X_train)\n",
    "# X_test = sc.transform(X_test)\n",
    "\n",
    "# print(X_train.shape)\n",
    "# X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_26 (Dense)             (None, 100)               4100      \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 50)                5000      \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 10)                500       \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 10,251\n",
      "Trainable params: 9,931\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "Train on 30162 samples, validate on 15060 samples\n",
      "Epoch 1/100\n",
      "30162/30162 [==============================] - 3s 116us/step - loss: 0.5682 - accuracy: 0.7456 - val_loss: 0.5206 - val_accuracy: 0.7622\n",
      "Epoch 2/100\n",
      "30162/30162 [==============================] - 2s 73us/step - loss: 0.5402 - accuracy: 0.7605 - val_loss: 0.4947 - val_accuracy: 0.7770\n",
      "Epoch 3/100\n",
      "30162/30162 [==============================] - 2s 73us/step - loss: 0.5174 - accuracy: 0.7680 - val_loss: 0.4675 - val_accuracy: 0.7830\n",
      "Epoch 4/100\n",
      "30162/30162 [==============================] - 2s 73us/step - loss: 0.4926 - accuracy: 0.7729 - val_loss: 0.4438 - val_accuracy: 0.7888\n",
      "Epoch 5/100\n",
      "30162/30162 [==============================] - 3s 86us/step - loss: 0.4757 - accuracy: 0.7749 - val_loss: 0.4247 - val_accuracy: 0.7958\n",
      "Epoch 6/100\n",
      "30162/30162 [==============================] - 2s 80us/step - loss: 0.4603 - accuracy: 0.7784 - val_loss: 0.4262 - val_accuracy: 0.7778\n",
      "Epoch 7/100\n",
      "30162/30162 [==============================] - 2s 83us/step - loss: 0.4462 - accuracy: 0.7841 - val_loss: 0.4038 - val_accuracy: 0.8021\n",
      "Epoch 8/100\n",
      "30162/30162 [==============================] - 2s 80us/step - loss: 0.4388 - accuracy: 0.7906 - val_loss: 0.3927 - val_accuracy: 0.8056\n",
      "Epoch 9/100\n",
      "30162/30162 [==============================] - 2s 80us/step - loss: 0.4305 - accuracy: 0.7926 - val_loss: 0.3969 - val_accuracy: 0.8019\n",
      "Epoch 10/100\n",
      "30162/30162 [==============================] - 2s 79us/step - loss: 0.4203 - accuracy: 0.7966 - val_loss: 0.3747 - val_accuracy: 0.8246\n",
      "Epoch 11/100\n",
      "30162/30162 [==============================] - 2s 80us/step - loss: 0.4190 - accuracy: 0.7972 - val_loss: 0.3785 - val_accuracy: 0.8169\n",
      "Epoch 12/100\n",
      "30162/30162 [==============================] - 2s 80us/step - loss: 0.4143 - accuracy: 0.8005 - val_loss: 0.3709 - val_accuracy: 0.8258\n",
      "Epoch 13/100\n",
      "30162/30162 [==============================] - 2s 79us/step - loss: 0.4135 - accuracy: 0.7996 - val_loss: 0.3686 - val_accuracy: 0.8290\n",
      "Epoch 14/100\n",
      "30162/30162 [==============================] - 2s 76us/step - loss: 0.4116 - accuracy: 0.7990 - val_loss: 0.3718 - val_accuracy: 0.8183\n",
      "Epoch 15/100\n",
      "30162/30162 [==============================] - 3s 84us/step - loss: 0.4093 - accuracy: 0.8046 - val_loss: 0.3677 - val_accuracy: 0.8284\n",
      "Epoch 16/100\n",
      "30162/30162 [==============================] - 2s 77us/step - loss: 0.4083 - accuracy: 0.8018 - val_loss: 0.3634 - val_accuracy: 0.8335\n",
      "Epoch 17/100\n",
      "30162/30162 [==============================] - 2s 77us/step - loss: 0.4056 - accuracy: 0.8001 - val_loss: 0.3635 - val_accuracy: 0.8326\n",
      "Epoch 18/100\n",
      "30162/30162 [==============================] - 2s 79us/step - loss: 0.4030 - accuracy: 0.8032 - val_loss: 0.3626 - val_accuracy: 0.8309\n",
      "Epoch 19/100\n",
      "30162/30162 [==============================] - 2s 81us/step - loss: 0.4036 - accuracy: 0.8047 - val_loss: 0.3633 - val_accuracy: 0.8305\n",
      "Epoch 20/100\n",
      "30162/30162 [==============================] - 3s 97us/step - loss: 0.4004 - accuracy: 0.8057 - val_loss: 0.3574 - val_accuracy: 0.8398\n",
      "Epoch 21/100\n",
      "30162/30162 [==============================] - 3s 93us/step - loss: 0.4015 - accuracy: 0.8048 - val_loss: 0.3560 - val_accuracy: 0.8423\n",
      "Epoch 22/100\n",
      "30162/30162 [==============================] - 3s 88us/step - loss: 0.4001 - accuracy: 0.8071 - val_loss: 0.3552 - val_accuracy: 0.8409\n",
      "Epoch 23/100\n",
      "30162/30162 [==============================] - 3s 86us/step - loss: 0.3987 - accuracy: 0.8092 - val_loss: 0.3541 - val_accuracy: 0.8456\n",
      "Epoch 24/100\n",
      "30162/30162 [==============================] - 3s 90us/step - loss: 0.3977 - accuracy: 0.8066 - val_loss: 0.3569 - val_accuracy: 0.8384\n",
      "Epoch 25/100\n",
      "30162/30162 [==============================] - 3s 89us/step - loss: 0.3983 - accuracy: 0.8059 - val_loss: 0.3571 - val_accuracy: 0.8394\n",
      "Epoch 26/100\n",
      "30162/30162 [==============================] - 3s 91us/step - loss: 0.3983 - accuracy: 0.8047 - val_loss: 0.3540 - val_accuracy: 0.8434\n",
      "Epoch 27/100\n",
      "30162/30162 [==============================] - 3s 90us/step - loss: 0.3978 - accuracy: 0.8064 - val_loss: 0.3522 - val_accuracy: 0.8429\n",
      "Epoch 28/100\n",
      "30162/30162 [==============================] - 3s 95us/step - loss: 0.3966 - accuracy: 0.8068 - val_loss: 0.3538 - val_accuracy: 0.8418\n",
      "Epoch 29/100\n",
      "30162/30162 [==============================] - 3s 91us/step - loss: 0.3942 - accuracy: 0.8078 - val_loss: 0.3525 - val_accuracy: 0.8442\n",
      "Epoch 30/100\n",
      "30162/30162 [==============================] - 3s 87us/step - loss: 0.3962 - accuracy: 0.8067 - val_loss: 0.3517 - val_accuracy: 0.8454\n",
      "Epoch 31/100\n",
      "30162/30162 [==============================] - 3s 88us/step - loss: 0.3961 - accuracy: 0.8055 - val_loss: 0.3522 - val_accuracy: 0.8453\n",
      "Epoch 32/100\n",
      "30162/30162 [==============================] - 3s 85us/step - loss: 0.3941 - accuracy: 0.8100 - val_loss: 0.3526 - val_accuracy: 0.8418\n",
      "Epoch 33/100\n",
      "30162/30162 [==============================] - 2s 82us/step - loss: 0.3948 - accuracy: 0.8098 - val_loss: 0.3525 - val_accuracy: 0.8428\n",
      "Epoch 34/100\n",
      "30162/30162 [==============================] - 3s 86us/step - loss: 0.3967 - accuracy: 0.8053 - val_loss: 0.3526 - val_accuracy: 0.8444\n",
      "Epoch 35/100\n",
      "30162/30162 [==============================] - 3s 86us/step - loss: 0.3928 - accuracy: 0.8098 - val_loss: 0.3519 - val_accuracy: 0.8438\n",
      "Epoch 36/100\n",
      "30162/30162 [==============================] - 3s 99us/step - loss: 0.3939 - accuracy: 0.8056 - val_loss: 0.3504 - val_accuracy: 0.8458\n",
      "Epoch 37/100\n",
      "30162/30162 [==============================] - 2s 74us/step - loss: 0.3940 - accuracy: 0.8073 - val_loss: 0.3521 - val_accuracy: 0.8446\n",
      "Epoch 38/100\n",
      "30162/30162 [==============================] - 2s 77us/step - loss: 0.3939 - accuracy: 0.8093 - val_loss: 0.3511 - val_accuracy: 0.8444\n",
      "Epoch 39/100\n",
      "30162/30162 [==============================] - 2s 77us/step - loss: 0.3961 - accuracy: 0.8077 - val_loss: 0.3515 - val_accuracy: 0.8450\n",
      "Epoch 40/100\n",
      "30162/30162 [==============================] - 3s 100us/step - loss: 0.3926 - accuracy: 0.8090 - val_loss: 0.3500 - val_accuracy: 0.8463\n",
      "Epoch 41/100\n",
      "30162/30162 [==============================] - 3s 93us/step - loss: 0.3939 - accuracy: 0.8086 - val_loss: 0.3502 - val_accuracy: 0.8450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/100\n",
      "30162/30162 [==============================] - 3s 88us/step - loss: 0.3921 - accuracy: 0.8102 - val_loss: 0.3495 - val_accuracy: 0.8465\n",
      "Epoch 43/100\n",
      "30162/30162 [==============================] - 3s 87us/step - loss: 0.3943 - accuracy: 0.8064 - val_loss: 0.3504 - val_accuracy: 0.8462\n",
      "Epoch 44/100\n",
      "30162/30162 [==============================] - 3s 87us/step - loss: 0.3926 - accuracy: 0.8074 - val_loss: 0.3498 - val_accuracy: 0.8467\n",
      "Epoch 45/100\n",
      "30162/30162 [==============================] - 3s 93us/step - loss: 0.3961 - accuracy: 0.8086 - val_loss: 0.3496 - val_accuracy: 0.8464\n",
      "Epoch 46/100\n",
      "30162/30162 [==============================] - 3s 89us/step - loss: 0.3934 - accuracy: 0.8096 - val_loss: 0.3500 - val_accuracy: 0.8454\n",
      "Epoch 47/100\n",
      "30162/30162 [==============================] - 3s 87us/step - loss: 0.3903 - accuracy: 0.8090 - val_loss: 0.3496 - val_accuracy: 0.8465\n",
      "Epoch 48/100\n",
      "30162/30162 [==============================] - 3s 86us/step - loss: 0.3912 - accuracy: 0.8094 - val_loss: 0.3496 - val_accuracy: 0.8456\n",
      "Epoch 49/100\n",
      "30162/30162 [==============================] - 3s 85us/step - loss: 0.3914 - accuracy: 0.8078 - val_loss: 0.3493 - val_accuracy: 0.8462\n",
      "Epoch 50/100\n",
      "30162/30162 [==============================] - 3s 84us/step - loss: 0.3915 - accuracy: 0.8110 - val_loss: 0.3499 - val_accuracy: 0.8463\n",
      "Epoch 51/100\n",
      "30162/30162 [==============================] - 3s 85us/step - loss: 0.3946 - accuracy: 0.8053 - val_loss: 0.3504 - val_accuracy: 0.8450\n",
      "Epoch 52/100\n",
      "30162/30162 [==============================] - 3s 87us/step - loss: 0.3907 - accuracy: 0.8094 - val_loss: 0.3506 - val_accuracy: 0.8453\n",
      "Epoch 53/100\n",
      "30162/30162 [==============================] - 3s 89us/step - loss: 0.3923 - accuracy: 0.8086 - val_loss: 0.3487 - val_accuracy: 0.8463\n",
      "Epoch 54/100\n",
      "30162/30162 [==============================] - 3s 86us/step - loss: 0.3945 - accuracy: 0.8090 - val_loss: 0.3500 - val_accuracy: 0.8458\n",
      "Epoch 55/100\n",
      "30162/30162 [==============================] - 3s 85us/step - loss: 0.3944 - accuracy: 0.8076 - val_loss: 0.3490 - val_accuracy: 0.8460\n",
      "Epoch 56/100\n",
      "30162/30162 [==============================] - 3s 86us/step - loss: 0.3935 - accuracy: 0.8105 - val_loss: 0.3496 - val_accuracy: 0.8464\n",
      "Epoch 57/100\n",
      "30162/30162 [==============================] - 3s 86us/step - loss: 0.3965 - accuracy: 0.8062 - val_loss: 0.3493 - val_accuracy: 0.8459\n",
      "Epoch 58/100\n",
      "30162/30162 [==============================] - 3s 83us/step - loss: 0.3938 - accuracy: 0.8097 - val_loss: 0.3498 - val_accuracy: 0.8458\n",
      "Epoch 59/100\n",
      "30162/30162 [==============================] - 3s 86us/step - loss: 0.3901 - accuracy: 0.8114 - val_loss: 0.3486 - val_accuracy: 0.8452\n",
      "Epoch 60/100\n",
      "30162/30162 [==============================] - 3s 85us/step - loss: 0.3922 - accuracy: 0.8096 - val_loss: 0.3489 - val_accuracy: 0.8459\n",
      "Epoch 61/100\n",
      "30162/30162 [==============================] - 3s 87us/step - loss: 0.3900 - accuracy: 0.8107 - val_loss: 0.3492 - val_accuracy: 0.8467\n",
      "Epoch 62/100\n",
      "30162/30162 [==============================] - 3s 85us/step - loss: 0.3907 - accuracy: 0.8110 - val_loss: 0.3492 - val_accuracy: 0.8463\n",
      "Epoch 63/100\n",
      "30162/30162 [==============================] - 3s 88us/step - loss: 0.3901 - accuracy: 0.8105 - val_loss: 0.3498 - val_accuracy: 0.8452\n",
      "Epoch 64/100\n",
      "30162/30162 [==============================] - 3s 83us/step - loss: 0.3928 - accuracy: 0.8087 - val_loss: 0.3489 - val_accuracy: 0.8464\n",
      "Epoch 65/100\n",
      "30162/30162 [==============================] - 3s 85us/step - loss: 0.3881 - accuracy: 0.8133 - val_loss: 0.3489 - val_accuracy: 0.8461\n",
      "Epoch 66/100\n",
      "30162/30162 [==============================] - 3s 86us/step - loss: 0.3905 - accuracy: 0.8098 - val_loss: 0.3494 - val_accuracy: 0.8453\n",
      "Epoch 67/100\n",
      "30162/30162 [==============================] - 3s 84us/step - loss: 0.3914 - accuracy: 0.8092 - val_loss: 0.3496 - val_accuracy: 0.8457\n",
      "Epoch 68/100\n",
      "30162/30162 [==============================] - 3s 85us/step - loss: 0.3918 - accuracy: 0.8103 - val_loss: 0.3490 - val_accuracy: 0.8462\n",
      "Epoch 69/100\n",
      "30162/30162 [==============================] - 3s 84us/step - loss: 0.3903 - accuracy: 0.8112 - val_loss: 0.3490 - val_accuracy: 0.8463\n",
      "Epoch 70/100\n",
      "30162/30162 [==============================] - 3s 85us/step - loss: 0.3880 - accuracy: 0.8109 - val_loss: 0.3492 - val_accuracy: 0.8464\n",
      "Epoch 71/100\n",
      "30162/30162 [==============================] - 2s 83us/step - loss: 0.3904 - accuracy: 0.8063 - val_loss: 0.3492 - val_accuracy: 0.8463\n",
      "Epoch 72/100\n",
      "30162/30162 [==============================] - 3s 84us/step - loss: 0.3910 - accuracy: 0.8111 - val_loss: 0.3492 - val_accuracy: 0.8467\n",
      "Epoch 73/100\n",
      "30162/30162 [==============================] - 3s 85us/step - loss: 0.3905 - accuracy: 0.8089 - val_loss: 0.3491 - val_accuracy: 0.8460\n",
      "Epoch 74/100\n",
      "30162/30162 [==============================] - 3s 84us/step - loss: 0.3938 - accuracy: 0.8117 - val_loss: 0.3494 - val_accuracy: 0.8465\n",
      "Epoch 75/100\n",
      "30162/30162 [==============================] - 3s 83us/step - loss: 0.3908 - accuracy: 0.8115 - val_loss: 0.3493 - val_accuracy: 0.8464\n",
      "Epoch 76/100\n",
      "30162/30162 [==============================] - 3s 84us/step - loss: 0.3917 - accuracy: 0.8093 - val_loss: 0.3483 - val_accuracy: 0.8459\n",
      "Epoch 77/100\n",
      "30162/30162 [==============================] - 3s 85us/step - loss: 0.3936 - accuracy: 0.8078 - val_loss: 0.3495 - val_accuracy: 0.8457\n",
      "Epoch 78/100\n",
      "30162/30162 [==============================] - 3s 85us/step - loss: 0.3923 - accuracy: 0.8083 - val_loss: 0.3486 - val_accuracy: 0.8461\n",
      "Epoch 79/100\n",
      "30162/30162 [==============================] - 3s 89us/step - loss: 0.3910 - accuracy: 0.8105 - val_loss: 0.3487 - val_accuracy: 0.8465\n",
      "Epoch 80/100\n",
      "30162/30162 [==============================] - 3s 87us/step - loss: 0.3931 - accuracy: 0.8079 - val_loss: 0.3490 - val_accuracy: 0.8461\n",
      "Epoch 81/100\n",
      "30162/30162 [==============================] - 3s 86us/step - loss: 0.3901 - accuracy: 0.8103 - val_loss: 0.3492 - val_accuracy: 0.8465\n",
      "Epoch 82/100\n",
      "30162/30162 [==============================] - 3s 87us/step - loss: 0.3891 - accuracy: 0.8107 - val_loss: 0.3490 - val_accuracy: 0.8461\n",
      "Epoch 83/100\n",
      "30162/30162 [==============================] - 3s 85us/step - loss: 0.3901 - accuracy: 0.8118 - val_loss: 0.3492 - val_accuracy: 0.8461\n",
      "Epoch 84/100\n",
      "30162/30162 [==============================] - 3s 85us/step - loss: 0.3902 - accuracy: 0.8105 - val_loss: 0.3493 - val_accuracy: 0.8460\n",
      "Epoch 85/100\n",
      "30162/30162 [==============================] - 3s 84us/step - loss: 0.3898 - accuracy: 0.8113 - val_loss: 0.3490 - val_accuracy: 0.8463\n",
      "Epoch 86/100\n",
      "30162/30162 [==============================] - 2s 82us/step - loss: 0.3893 - accuracy: 0.8085 - val_loss: 0.3489 - val_accuracy: 0.8459\n",
      "Epoch 87/100\n",
      "30162/30162 [==============================] - 3s 86us/step - loss: 0.3901 - accuracy: 0.8121 - val_loss: 0.3492 - val_accuracy: 0.8461\n",
      "Epoch 88/100\n",
      "30162/30162 [==============================] - 3s 89us/step - loss: 0.3901 - accuracy: 0.8142 - val_loss: 0.3487 - val_accuracy: 0.8464\n",
      "Epoch 89/100\n",
      "30162/30162 [==============================] - 3s 96us/step - loss: 0.3899 - accuracy: 0.8111 - val_loss: 0.3485 - val_accuracy: 0.8459\n",
      "Epoch 90/100\n",
      "30162/30162 [==============================] - 3s 89us/step - loss: 0.3894 - accuracy: 0.8093 - val_loss: 0.3489 - val_accuracy: 0.8463\n",
      "Epoch 91/100\n",
      "30162/30162 [==============================] - 3s 89us/step - loss: 0.3913 - accuracy: 0.8084 - val_loss: 0.3485 - val_accuracy: 0.8467\n",
      "Epoch 92/100\n",
      "30162/30162 [==============================] - 3s 88us/step - loss: 0.3935 - accuracy: 0.8079 - val_loss: 0.3489 - val_accuracy: 0.8458\n",
      "Epoch 93/100\n",
      "30162/30162 [==============================] - 3s 88us/step - loss: 0.3908 - accuracy: 0.8131 - val_loss: 0.3490 - val_accuracy: 0.8462\n",
      "Epoch 94/100\n",
      "30162/30162 [==============================] - 3s 86us/step - loss: 0.3917 - accuracy: 0.8109 - val_loss: 0.3493 - val_accuracy: 0.8459\n",
      "Epoch 95/100\n",
      "30162/30162 [==============================] - 3s 85us/step - loss: 0.3895 - accuracy: 0.8109 - val_loss: 0.3491 - val_accuracy: 0.8465\n",
      "Epoch 96/100\n",
      "30162/30162 [==============================] - 3s 92us/step - loss: 0.3935 - accuracy: 0.8089 - val_loss: 0.3486 - val_accuracy: 0.8461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00096: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2c7a952cf60>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Activation\n",
    "\n",
    "from keras.callbacks import History\n",
    "\n",
    "# learning rate schedule\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.0001\n",
    "    drop = 0.5\n",
    "    epochs_drop = 10.0\n",
    "    lrate = initial_lrate * np.power(drop, np.floor((1+epoch)/epochs_drop))\n",
    "    return lrate\n",
    "\n",
    "\n",
    "history_Adam = History()\n",
    "model = Sequential()\n",
    "model.add(Dense(100, use_bias=False,input_shape=(X_train.shape[1],)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(50, use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(10, use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "model.summary()\n",
    "\n",
    "Adam = keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=Adam, metrics=[\"accuracy\"])\n",
    "\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=1)\n",
    "model.fit(X_train, y_train, validation_data= (X_test, y_test), batch_size=32,epochs=100, callbacks=[lrate, history_Adam, early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_Adam.history['accuracy'], label = \"tarina Adam\")\n",
    "plt.plot(history_Adam.history['val_accuracy'], label = \"test Adam\")\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad.\n",
    "# Zad.\n",
    "Do do modelu \n",
    " \n",
    "```python\n",
    "model.add(Dense( ... , activity_regularizer=l1(0.00001)))\n",
    "```\n",
    "\n",
    "w kadej warstwie.\n",
    "\n",
    "Zwizualizuj wyniki dla obu modeli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "# generate 2d classification dataset\n",
    "X, y = make_moons(n_samples=100, noise=0.2, random_state=5)\n",
    "# split into train and test\n",
    "# n_train = 30\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.70, random_state=2)\n",
    "\n",
    "n_train=53\n",
    "X_train, X_test = X[:n_train, :], X[n_train:, :]\n",
    "y_train, y_test = y[:n_train], y[n_train:]\n",
    "\n",
    "plt.scatter(X_train[:,0],X_train[:,1], c=y_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_30 (Dense)             (None, 1000)              3000      \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 200)               100200    \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 603,901\n",
      "Trainable params: 603,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 53 samples, validate on 47 samples\n",
      "Epoch 1/1000\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.8130 - accuracy: 0.5472 - val_loss: 0.6743 - val_accuracy: 0.5532\n",
      "Epoch 2/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.6960 - accuracy: 0.4528 - val_loss: 0.6617 - val_accuracy: 0.5532\n",
      "Epoch 3/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.6711 - accuracy: 0.5472 - val_loss: 0.6543 - val_accuracy: 0.7447\n",
      "Epoch 4/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.6471 - accuracy: 0.6604 - val_loss: 0.6832 - val_accuracy: 0.4468\n",
      "Epoch 5/1000\n",
      "53/53 [==============================] - 0s 434us/step - loss: 0.6195 - accuracy: 0.5472 - val_loss: 0.6282 - val_accuracy: 0.7660\n",
      "Epoch 6/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.5796 - accuracy: 0.7547 - val_loss: 0.5799 - val_accuracy: 0.7447\n",
      "Epoch 7/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.5441 - accuracy: 0.8302 - val_loss: 0.5568 - val_accuracy: 0.7660\n",
      "Epoch 8/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.5119 - accuracy: 0.8302 - val_loss: 0.5304 - val_accuracy: 0.7447\n",
      "Epoch 9/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.4706 - accuracy: 0.8302 - val_loss: 0.5073 - val_accuracy: 0.7447\n",
      "Epoch 10/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.4270 - accuracy: 0.8302 - val_loss: 0.4906 - val_accuracy: 0.7447\n",
      "Epoch 11/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.3999 - accuracy: 0.8302 - val_loss: 0.4835 - val_accuracy: 0.7447\n",
      "Epoch 12/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.3740 - accuracy: 0.8491 - val_loss: 0.4927 - val_accuracy: 0.7447\n",
      "Epoch 13/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.3548 - accuracy: 0.8679 - val_loss: 0.5039 - val_accuracy: 0.7447\n",
      "Epoch 14/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.3383 - accuracy: 0.8491 - val_loss: 0.5049 - val_accuracy: 0.7447\n",
      "Epoch 15/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.3312 - accuracy: 0.8491 - val_loss: 0.5093 - val_accuracy: 0.7447\n",
      "Epoch 16/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.3206 - accuracy: 0.8491 - val_loss: 0.5076 - val_accuracy: 0.7447\n",
      "Epoch 17/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.3127 - accuracy: 0.8491 - val_loss: 0.5126 - val_accuracy: 0.7660\n",
      "Epoch 18/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.3043 - accuracy: 0.8679 - val_loss: 0.5202 - val_accuracy: 0.7872\n",
      "Epoch 19/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.2950 - accuracy: 0.8679 - val_loss: 0.5190 - val_accuracy: 0.7872\n",
      "Epoch 20/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.2838 - accuracy: 0.8679 - val_loss: 0.5283 - val_accuracy: 0.7872\n",
      "Epoch 21/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.2750 - accuracy: 0.8679 - val_loss: 0.5247 - val_accuracy: 0.7872\n",
      "Epoch 22/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.2669 - accuracy: 0.8679 - val_loss: 0.5099 - val_accuracy: 0.7872\n",
      "Epoch 23/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.2597 - accuracy: 0.8868 - val_loss: 0.4873 - val_accuracy: 0.8085\n",
      "Epoch 24/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.2539 - accuracy: 0.8868 - val_loss: 0.4690 - val_accuracy: 0.8085\n",
      "Epoch 25/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.2468 - accuracy: 0.8868 - val_loss: 0.4679 - val_accuracy: 0.8085\n",
      "Epoch 26/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.2411 - accuracy: 0.9057 - val_loss: 0.4598 - val_accuracy: 0.8085\n",
      "Epoch 27/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.2356 - accuracy: 0.9057 - val_loss: 0.4526 - val_accuracy: 0.8085\n",
      "Epoch 28/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.2350 - accuracy: 0.9057 - val_loss: 0.4534 - val_accuracy: 0.8085\n",
      "Epoch 29/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.2309 - accuracy: 0.9057 - val_loss: 0.4573 - val_accuracy: 0.8085\n",
      "Epoch 30/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.2281 - accuracy: 0.9057 - val_loss: 0.4587 - val_accuracy: 0.8298\n",
      "Epoch 31/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.2259 - accuracy: 0.9057 - val_loss: 0.4646 - val_accuracy: 0.8298\n",
      "Epoch 32/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2276 - accuracy: 0.8868 - val_loss: 0.4708 - val_accuracy: 0.8298\n",
      "Epoch 33/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.2214 - accuracy: 0.9057 - val_loss: 0.4947 - val_accuracy: 0.8085\n",
      "Epoch 34/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.2215 - accuracy: 0.9057 - val_loss: 0.4968 - val_accuracy: 0.8085\n",
      "Epoch 35/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.2166 - accuracy: 0.8868 - val_loss: 0.4767 - val_accuracy: 0.8298\n",
      "Epoch 36/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.2133 - accuracy: 0.8868 - val_loss: 0.4664 - val_accuracy: 0.8298\n",
      "Epoch 37/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.2108 - accuracy: 0.9057 - val_loss: 0.4709 - val_accuracy: 0.8298\n",
      "Epoch 38/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.2094 - accuracy: 0.8868 - val_loss: 0.4857 - val_accuracy: 0.8085\n",
      "Epoch 39/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.2076 - accuracy: 0.9057 - val_loss: 0.5014 - val_accuracy: 0.8085\n",
      "Epoch 40/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.2065 - accuracy: 0.9057 - val_loss: 0.5024 - val_accuracy: 0.8085\n",
      "Epoch 41/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.2065 - accuracy: 0.9057 - val_loss: 0.4853 - val_accuracy: 0.8085\n",
      "Epoch 42/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.2029 - accuracy: 0.9057 - val_loss: 0.4791 - val_accuracy: 0.8085\n",
      "Epoch 43/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.2057 - accuracy: 0.8868 - val_loss: 0.4576 - val_accuracy: 0.8298\n",
      "Epoch 44/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.1975 - accuracy: 0.9057 - val_loss: 0.4611 - val_accuracy: 0.8298\n",
      "Epoch 45/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.1953 - accuracy: 0.9057 - val_loss: 0.4636 - val_accuracy: 0.8298\n",
      "Epoch 46/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.1927 - accuracy: 0.9057 - val_loss: 0.4593 - val_accuracy: 0.8298\n",
      "Epoch 47/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.1914 - accuracy: 0.9245 - val_loss: 0.4568 - val_accuracy: 0.8298\n",
      "Epoch 48/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.1933 - accuracy: 0.9245 - val_loss: 0.4488 - val_accuracy: 0.8298\n",
      "Epoch 49/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.1937 - accuracy: 0.9057 - val_loss: 0.4620 - val_accuracy: 0.8298\n",
      "Epoch 50/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.1868 - accuracy: 0.9057 - val_loss: 0.4575 - val_accuracy: 0.8298\n",
      "Epoch 51/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.1861 - accuracy: 0.9057 - val_loss: 0.4612 - val_accuracy: 0.8298\n",
      "Epoch 52/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.1830 - accuracy: 0.9245 - val_loss: 0.4533 - val_accuracy: 0.8298\n",
      "Epoch 53/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.1829 - accuracy: 0.9245 - val_loss: 0.4498 - val_accuracy: 0.8298\n",
      "Epoch 54/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.1801 - accuracy: 0.9245 - val_loss: 0.4555 - val_accuracy: 0.8298\n",
      "Epoch 55/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.1773 - accuracy: 0.9245 - val_loss: 0.4689 - val_accuracy: 0.8298\n",
      "Epoch 56/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.1783 - accuracy: 0.9245 - val_loss: 0.4743 - val_accuracy: 0.8085\n",
      "Epoch 57/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.1781 - accuracy: 0.9434 - val_loss: 0.4820 - val_accuracy: 0.8085\n",
      "Epoch 58/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.1765 - accuracy: 0.9434 - val_loss: 0.4700 - val_accuracy: 0.8298\n",
      "Epoch 59/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.1711 - accuracy: 0.9434 - val_loss: 0.4501 - val_accuracy: 0.8298\n",
      "Epoch 60/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.1724 - accuracy: 0.9245 - val_loss: 0.4347 - val_accuracy: 0.8298\n",
      "Epoch 61/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.1811 - accuracy: 0.9245 - val_loss: 0.4327 - val_accuracy: 0.8298\n",
      "Epoch 62/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.1689 - accuracy: 0.9245 - val_loss: 0.4626 - val_accuracy: 0.8298\n",
      "Epoch 63/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.1639 - accuracy: 0.9434 - val_loss: 0.4786 - val_accuracy: 0.8511\n",
      "Epoch 64/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.1683 - accuracy: 0.9623 - val_loss: 0.4831 - val_accuracy: 0.8298\n",
      "Epoch 65/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.1673 - accuracy: 0.9623 - val_loss: 0.4628 - val_accuracy: 0.8298\n",
      "Epoch 66/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.1686 - accuracy: 0.9434 - val_loss: 0.4322 - val_accuracy: 0.8298\n",
      "Epoch 67/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.1574 - accuracy: 0.9434 - val_loss: 0.4245 - val_accuracy: 0.8298\n",
      "Epoch 68/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.1560 - accuracy: 0.9434 - val_loss: 0.4232 - val_accuracy: 0.8298\n",
      "Epoch 69/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.1569 - accuracy: 0.9434 - val_loss: 0.4202 - val_accuracy: 0.8298\n",
      "Epoch 70/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.1517 - accuracy: 0.9434 - val_loss: 0.4341 - val_accuracy: 0.8298\n",
      "Epoch 71/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.1505 - accuracy: 0.9623 - val_loss: 0.4398 - val_accuracy: 0.8298\n",
      "Epoch 72/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.1502 - accuracy: 0.9811 - val_loss: 0.4457 - val_accuracy: 0.8511\n",
      "Epoch 73/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.1494 - accuracy: 0.9811 - val_loss: 0.4358 - val_accuracy: 0.8298\n",
      "Epoch 74/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.1435 - accuracy: 0.9811 - val_loss: 0.4114 - val_accuracy: 0.8511\n",
      "Epoch 75/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.1423 - accuracy: 0.9623 - val_loss: 0.3889 - val_accuracy: 0.8511\n",
      "Epoch 76/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.1464 - accuracy: 0.9245 - val_loss: 0.3853 - val_accuracy: 0.8511\n",
      "Epoch 77/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.1416 - accuracy: 0.9245 - val_loss: 0.3795 - val_accuracy: 0.8511\n",
      "Epoch 78/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.1403 - accuracy: 0.9245 - val_loss: 0.3881 - val_accuracy: 0.8511\n",
      "Epoch 79/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.1348 - accuracy: 0.9434 - val_loss: 0.3899 - val_accuracy: 0.8511\n",
      "Epoch 80/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.1316 - accuracy: 0.9811 - val_loss: 0.4004 - val_accuracy: 0.8936\n",
      "Epoch 81/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.1325 - accuracy: 0.9811 - val_loss: 0.4016 - val_accuracy: 0.8936\n",
      "Epoch 82/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.1304 - accuracy: 0.9811 - val_loss: 0.4034 - val_accuracy: 0.8936\n",
      "Epoch 83/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.1269 - accuracy: 0.9811 - val_loss: 0.3885 - val_accuracy: 0.8723\n",
      "Epoch 84/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.1243 - accuracy: 0.9811 - val_loss: 0.3641 - val_accuracy: 0.8511\n",
      "Epoch 85/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.1259 - accuracy: 0.9623 - val_loss: 0.3511 - val_accuracy: 0.8511\n",
      "Epoch 86/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.1217 - accuracy: 0.9623 - val_loss: 0.3571 - val_accuracy: 0.8723\n",
      "Epoch 87/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.1174 - accuracy: 0.9623 - val_loss: 0.3789 - val_accuracy: 0.8723\n",
      "Epoch 88/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.1159 - accuracy: 0.9811 - val_loss: 0.3850 - val_accuracy: 0.8936\n",
      "Epoch 89/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.1165 - accuracy: 0.9811 - val_loss: 0.3798 - val_accuracy: 0.8936\n",
      "Epoch 90/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.1148 - accuracy: 0.9811 - val_loss: 0.3708 - val_accuracy: 0.8936\n",
      "Epoch 91/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.1114 - accuracy: 0.9811 - val_loss: 0.3440 - val_accuracy: 0.8723\n",
      "Epoch 92/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.1067 - accuracy: 0.9811 - val_loss: 0.3224 - val_accuracy: 0.8723\n",
      "Epoch 93/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.1086 - accuracy: 0.9623 - val_loss: 0.3102 - val_accuracy: 0.8723\n",
      "Epoch 94/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.1022 - accuracy: 0.9623 - val_loss: 0.3196 - val_accuracy: 0.8936\n",
      "Epoch 95/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0984 - accuracy: 0.9811 - val_loss: 0.3240 - val_accuracy: 0.8936\n",
      "Epoch 96/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0977 - accuracy: 0.9811 - val_loss: 0.3244 - val_accuracy: 0.8936\n",
      "Epoch 97/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0986 - accuracy: 0.9811 - val_loss: 0.3156 - val_accuracy: 0.8936\n",
      "Epoch 98/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0950 - accuracy: 0.9811 - val_loss: 0.3076 - val_accuracy: 0.8936\n",
      "Epoch 99/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0921 - accuracy: 0.9811 - val_loss: 0.2999 - val_accuracy: 0.8936\n",
      "Epoch 100/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0913 - accuracy: 0.9811 - val_loss: 0.2927 - val_accuracy: 0.8936\n",
      "Epoch 101/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0859 - accuracy: 0.9811 - val_loss: 0.2926 - val_accuracy: 0.8936\n",
      "Epoch 102/1000\n",
      "53/53 [==============================] - 0s 451us/step - loss: 0.0839 - accuracy: 0.9811 - val_loss: 0.2837 - val_accuracy: 0.8936\n",
      "Epoch 103/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0818 - accuracy: 0.9811 - val_loss: 0.2723 - val_accuracy: 0.8936\n",
      "Epoch 104/1000\n",
      "53/53 [==============================] - 0s 451us/step - loss: 0.0790 - accuracy: 0.9811 - val_loss: 0.2492 - val_accuracy: 0.8723\n",
      "Epoch 105/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0784 - accuracy: 0.9811 - val_loss: 0.2370 - val_accuracy: 0.8936\n",
      "Epoch 106/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0755 - accuracy: 0.9811 - val_loss: 0.2402 - val_accuracy: 0.9149\n",
      "Epoch 107/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 508us/step - loss: 0.0738 - accuracy: 0.9811 - val_loss: 0.2493 - val_accuracy: 0.8936\n",
      "Epoch 108/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0711 - accuracy: 0.9811 - val_loss: 0.2427 - val_accuracy: 0.9149\n",
      "Epoch 109/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0688 - accuracy: 0.9811 - val_loss: 0.2440 - val_accuracy: 0.9149\n",
      "Epoch 110/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0659 - accuracy: 0.9811 - val_loss: 0.2313 - val_accuracy: 0.9149\n",
      "Epoch 111/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0658 - accuracy: 0.9811 - val_loss: 0.2102 - val_accuracy: 0.9149\n",
      "Epoch 112/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0620 - accuracy: 1.0000 - val_loss: 0.2039 - val_accuracy: 0.9149\n",
      "Epoch 113/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0606 - accuracy: 1.0000 - val_loss: 0.2056 - val_accuracy: 0.9149\n",
      "Epoch 114/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0607 - accuracy: 0.9623 - val_loss: 0.2103 - val_accuracy: 0.9149\n",
      "Epoch 115/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0577 - accuracy: 0.9623 - val_loss: 0.1990 - val_accuracy: 0.9149\n",
      "Epoch 116/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0560 - accuracy: 1.0000 - val_loss: 0.1934 - val_accuracy: 0.9149\n",
      "Epoch 117/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0543 - accuracy: 1.0000 - val_loss: 0.1978 - val_accuracy: 0.9149\n",
      "Epoch 118/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0525 - accuracy: 1.0000 - val_loss: 0.1924 - val_accuracy: 0.9149\n",
      "Epoch 119/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0497 - accuracy: 1.0000 - val_loss: 0.1949 - val_accuracy: 0.9149\n",
      "Epoch 120/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0483 - accuracy: 1.0000 - val_loss: 0.1985 - val_accuracy: 0.9149\n",
      "Epoch 121/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0516 - accuracy: 0.9811 - val_loss: 0.2029 - val_accuracy: 0.9149\n",
      "Epoch 122/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0473 - accuracy: 1.0000 - val_loss: 0.1910 - val_accuracy: 0.9149\n",
      "Epoch 123/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0447 - accuracy: 1.0000 - val_loss: 0.1853 - val_accuracy: 0.9149\n",
      "Epoch 124/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0437 - accuracy: 1.0000 - val_loss: 0.1784 - val_accuracy: 0.9362\n",
      "Epoch 125/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0431 - accuracy: 1.0000 - val_loss: 0.1769 - val_accuracy: 0.9149\n",
      "Epoch 126/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0425 - accuracy: 1.0000 - val_loss: 0.1806 - val_accuracy: 0.9362\n",
      "Epoch 127/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0409 - accuracy: 1.0000 - val_loss: 0.1904 - val_accuracy: 0.9149\n",
      "Epoch 128/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0412 - accuracy: 1.0000 - val_loss: 0.2016 - val_accuracy: 0.9149\n",
      "Epoch 129/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0393 - accuracy: 1.0000 - val_loss: 0.1937 - val_accuracy: 0.9149\n",
      "Epoch 130/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0381 - accuracy: 1.0000 - val_loss: 0.1878 - val_accuracy: 0.9149\n",
      "Epoch 131/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0397 - accuracy: 1.0000 - val_loss: 0.1855 - val_accuracy: 0.9149\n",
      "Epoch 132/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0373 - accuracy: 1.0000 - val_loss: 0.1716 - val_accuracy: 0.9149\n",
      "Epoch 133/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0358 - accuracy: 1.0000 - val_loss: 0.1695 - val_accuracy: 0.9149\n",
      "Epoch 134/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0357 - accuracy: 1.0000 - val_loss: 0.1747 - val_accuracy: 0.9149\n",
      "Epoch 135/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0336 - accuracy: 1.0000 - val_loss: 0.1795 - val_accuracy: 0.9362\n",
      "Epoch 136/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0333 - accuracy: 1.0000 - val_loss: 0.1882 - val_accuracy: 0.9149\n",
      "Epoch 137/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0326 - accuracy: 1.0000 - val_loss: 0.1880 - val_accuracy: 0.9149\n",
      "Epoch 138/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0326 - accuracy: 1.0000 - val_loss: 0.1796 - val_accuracy: 0.9149\n",
      "Epoch 139/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0310 - accuracy: 1.0000 - val_loss: 0.1789 - val_accuracy: 0.9149\n",
      "Epoch 140/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0297 - accuracy: 1.0000 - val_loss: 0.1820 - val_accuracy: 0.9362\n",
      "Epoch 141/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0294 - accuracy: 1.0000 - val_loss: 0.1837 - val_accuracy: 0.9362\n",
      "Epoch 142/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0291 - accuracy: 1.0000 - val_loss: 0.1868 - val_accuracy: 0.9149\n",
      "Epoch 143/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0291 - accuracy: 1.0000 - val_loss: 0.1846 - val_accuracy: 0.9362\n",
      "Epoch 144/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 0.1811 - val_accuracy: 0.9362\n",
      "Epoch 145/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0292 - accuracy: 1.0000 - val_loss: 0.1766 - val_accuracy: 0.9149\n",
      "Epoch 146/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0266 - accuracy: 1.0000 - val_loss: 0.1797 - val_accuracy: 0.9149\n",
      "Epoch 147/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0270 - accuracy: 1.0000 - val_loss: 0.1820 - val_accuracy: 0.9362\n",
      "Epoch 148/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0265 - accuracy: 1.0000 - val_loss: 0.1811 - val_accuracy: 0.9149\n",
      "Epoch 149/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0265 - accuracy: 1.0000 - val_loss: 0.1816 - val_accuracy: 0.9149\n",
      "Epoch 150/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0256 - accuracy: 1.0000 - val_loss: 0.1753 - val_accuracy: 0.9149\n",
      "Epoch 151/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0259 - accuracy: 1.0000 - val_loss: 0.1755 - val_accuracy: 0.9149\n",
      "Epoch 152/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0239 - accuracy: 1.0000 - val_loss: 0.1838 - val_accuracy: 0.9362\n",
      "Epoch 153/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0244 - accuracy: 1.0000 - val_loss: 0.1894 - val_accuracy: 0.9362\n",
      "Epoch 154/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0238 - accuracy: 1.0000 - val_loss: 0.1852 - val_accuracy: 0.9362\n",
      "Epoch 155/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0231 - accuracy: 1.0000 - val_loss: 0.1775 - val_accuracy: 0.9149\n",
      "Epoch 156/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 0.1741 - val_accuracy: 0.9149\n",
      "Epoch 157/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0223 - accuracy: 1.0000 - val_loss: 0.1719 - val_accuracy: 0.9149\n",
      "Epoch 158/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0221 - accuracy: 1.0000 - val_loss: 0.1773 - val_accuracy: 0.9149\n",
      "Epoch 159/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 0.1803 - val_accuracy: 0.9149\n",
      "Epoch 160/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 0.1865 - val_accuracy: 0.9149\n",
      "Epoch 161/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 0.1902 - val_accuracy: 0.9362\n",
      "Epoch 162/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 0.1879 - val_accuracy: 0.9149\n",
      "Epoch 163/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 0.1843 - val_accuracy: 0.9149\n",
      "Epoch 164/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 0.1814 - val_accuracy: 0.8936\n",
      "Epoch 165/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 0.1824 - val_accuracy: 0.9149\n",
      "Epoch 166/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 0.1861 - val_accuracy: 0.9149\n",
      "Epoch 167/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 0.1902 - val_accuracy: 0.9362\n",
      "Epoch 168/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 0.1927 - val_accuracy: 0.9362\n",
      "Epoch 169/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.1901 - val_accuracy: 0.9362\n",
      "Epoch 170/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 0.1819 - val_accuracy: 0.9149\n",
      "Epoch 171/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.1763 - val_accuracy: 0.9149\n",
      "Epoch 172/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.1770 - val_accuracy: 0.9149\n",
      "Epoch 173/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 0.1795 - val_accuracy: 0.9149\n",
      "Epoch 174/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 0.1887 - val_accuracy: 0.9149\n",
      "Epoch 175/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 0.1958 - val_accuracy: 0.9362\n",
      "Epoch 176/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.1929 - val_accuracy: 0.9362\n",
      "Epoch 177/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.1844 - val_accuracy: 0.9149\n",
      "Epoch 178/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.1779 - val_accuracy: 0.8936\n",
      "Epoch 179/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.1789 - val_accuracy: 0.8936\n",
      "Epoch 180/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.1848 - val_accuracy: 0.9149\n",
      "Epoch 181/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.1915 - val_accuracy: 0.9149\n",
      "Epoch 182/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.1945 - val_accuracy: 0.9362\n",
      "Epoch 183/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.1917 - val_accuracy: 0.9362\n",
      "Epoch 184/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.1869 - val_accuracy: 0.9149\n",
      "Epoch 185/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.1812 - val_accuracy: 0.9149\n",
      "Epoch 186/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.1768 - val_accuracy: 0.9149\n",
      "Epoch 187/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.1767 - val_accuracy: 0.9362\n",
      "Epoch 188/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.1790 - val_accuracy: 0.9149\n",
      "Epoch 189/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.1820 - val_accuracy: 0.9149\n",
      "Epoch 190/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.1844 - val_accuracy: 0.9149\n",
      "Epoch 191/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.1867 - val_accuracy: 0.9149\n",
      "Epoch 192/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.1898 - val_accuracy: 0.9149\n",
      "Epoch 193/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.1930 - val_accuracy: 0.9149\n",
      "Epoch 194/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.1967 - val_accuracy: 0.9362\n",
      "Epoch 195/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.1965 - val_accuracy: 0.9362\n",
      "Epoch 196/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.1961 - val_accuracy: 0.9362\n",
      "Epoch 197/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.1919 - val_accuracy: 0.9149\n",
      "Epoch 198/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.1890 - val_accuracy: 0.9149\n",
      "Epoch 199/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.1874 - val_accuracy: 0.8936\n",
      "Epoch 200/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.1906 - val_accuracy: 0.9149\n",
      "Epoch 201/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.1939 - val_accuracy: 0.9149\n",
      "Epoch 202/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.1943 - val_accuracy: 0.9149\n",
      "Epoch 203/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.1944 - val_accuracy: 0.9149\n",
      "Epoch 204/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.1964 - val_accuracy: 0.9149\n",
      "Epoch 205/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.1941 - val_accuracy: 0.9149\n",
      "Epoch 206/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.1935 - val_accuracy: 0.9149\n",
      "Epoch 207/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.1906 - val_accuracy: 0.9149\n",
      "Epoch 208/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.1873 - val_accuracy: 0.9149\n",
      "Epoch 209/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.1868 - val_accuracy: 0.9362\n",
      "Epoch 210/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.1879 - val_accuracy: 0.9362\n",
      "Epoch 211/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.1900 - val_accuracy: 0.9149\n",
      "Epoch 212/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.1928 - val_accuracy: 0.9149\n",
      "Epoch 213/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.1936 - val_accuracy: 0.9149\n",
      "Epoch 214/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.1918 - val_accuracy: 0.9149\n",
      "Epoch 215/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.1913 - val_accuracy: 0.9149\n",
      "Epoch 216/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.1903 - val_accuracy: 0.9362\n",
      "Epoch 217/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.1910 - val_accuracy: 0.9149\n",
      "Epoch 218/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.1929 - val_accuracy: 0.9149\n",
      "Epoch 219/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 470us/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.1982 - val_accuracy: 0.9149\n",
      "Epoch 220/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.2023 - val_accuracy: 0.9149\n",
      "Epoch 221/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.2029 - val_accuracy: 0.9149\n",
      "Epoch 222/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.1985 - val_accuracy: 0.9149\n",
      "Epoch 223/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.1959 - val_accuracy: 0.9149\n",
      "Epoch 224/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.1962 - val_accuracy: 0.9149\n",
      "Epoch 225/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.1964 - val_accuracy: 0.9149\n",
      "Epoch 226/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.1967 - val_accuracy: 0.9149\n",
      "Epoch 227/1000\n",
      "53/53 [==============================] - 0s 564us/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.1982 - val_accuracy: 0.8936\n",
      "Epoch 228/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.2002 - val_accuracy: 0.9149\n",
      "Epoch 229/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.2028 - val_accuracy: 0.9149\n",
      "Epoch 230/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.2036 - val_accuracy: 0.9149\n",
      "Epoch 231/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.2000 - val_accuracy: 0.9149\n",
      "Epoch 232/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.1981 - val_accuracy: 0.9149\n",
      "Epoch 233/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.1978 - val_accuracy: 0.9149\n",
      "Epoch 234/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.1986 - val_accuracy: 0.9149\n",
      "Epoch 235/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.2001 - val_accuracy: 0.9149\n",
      "Epoch 236/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.2019 - val_accuracy: 0.9149\n",
      "Epoch 237/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.2025 - val_accuracy: 0.9149\n",
      "Epoch 238/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.2034 - val_accuracy: 0.9149\n",
      "Epoch 239/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.2029 - val_accuracy: 0.8936\n",
      "Epoch 240/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.2028 - val_accuracy: 0.9149\n",
      "Epoch 241/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.2038 - val_accuracy: 0.9149\n",
      "Epoch 242/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.2045 - val_accuracy: 0.8936\n",
      "Epoch 243/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.2057 - val_accuracy: 0.9149\n",
      "Epoch 244/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.2072 - val_accuracy: 0.9149\n",
      "Epoch 245/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.2074 - val_accuracy: 0.9149\n",
      "Epoch 246/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.2065 - val_accuracy: 0.9149\n",
      "Epoch 247/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.2040 - val_accuracy: 0.9149\n",
      "Epoch 248/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.2037 - val_accuracy: 0.9149\n",
      "Epoch 249/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.2042 - val_accuracy: 0.9362\n",
      "Epoch 250/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.2058 - val_accuracy: 0.9149\n",
      "Epoch 251/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.2066 - val_accuracy: 0.9149\n",
      "Epoch 252/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.2045 - val_accuracy: 0.9149\n",
      "Epoch 253/1000\n",
      "53/53 [==============================] - 0s 584us/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.2020 - val_accuracy: 0.9362\n",
      "Epoch 254/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.1994 - val_accuracy: 0.9149\n",
      "Epoch 255/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.1995 - val_accuracy: 0.9149\n",
      "Epoch 256/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.1997 - val_accuracy: 0.9149\n",
      "Epoch 257/1000\n",
      "53/53 [==============================] - 0s 471us/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.2010 - val_accuracy: 0.9362\n",
      "Epoch 258/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.2044 - val_accuracy: 0.9149\n",
      "Epoch 259/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.2075 - val_accuracy: 0.9362\n",
      "Epoch 260/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.2055 - val_accuracy: 0.9149\n",
      "Epoch 261/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.2022 - val_accuracy: 0.9362\n",
      "Epoch 262/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.2009 - val_accuracy: 0.9149\n",
      "Epoch 263/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.2018 - val_accuracy: 0.9149\n",
      "Epoch 264/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.2041 - val_accuracy: 0.9149\n",
      "Epoch 265/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.2061 - val_accuracy: 0.9149\n",
      "Epoch 266/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.2102 - val_accuracy: 0.9149\n",
      "Epoch 267/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.2135 - val_accuracy: 0.9149\n",
      "Epoch 268/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.2135 - val_accuracy: 0.9149\n",
      "Epoch 269/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.2113 - val_accuracy: 0.9362\n",
      "Epoch 270/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.2111 - val_accuracy: 0.9149\n",
      "Epoch 271/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.2117 - val_accuracy: 0.9149\n",
      "Epoch 272/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.2118 - val_accuracy: 0.9149\n",
      "Epoch 273/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.2129 - val_accuracy: 0.9362\n",
      "Epoch 274/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.2130 - val_accuracy: 0.9362\n",
      "Epoch 275/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.2119 - val_accuracy: 0.9149\n",
      "Epoch 276/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.2116 - val_accuracy: 0.9149\n",
      "Epoch 277/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.2119 - val_accuracy: 0.9149\n",
      "Epoch 278/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.2115 - val_accuracy: 0.9149\n",
      "Epoch 279/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.2108 - val_accuracy: 0.9149\n",
      "Epoch 280/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.2105 - val_accuracy: 0.9149\n",
      "Epoch 281/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.2111 - val_accuracy: 0.9149\n",
      "Epoch 282/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.2120 - val_accuracy: 0.9149\n",
      "Epoch 283/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.2128 - val_accuracy: 0.9149\n",
      "Epoch 284/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.2133 - val_accuracy: 0.9362\n",
      "Epoch 285/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.2139 - val_accuracy: 0.9362\n",
      "Epoch 286/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.2142 - val_accuracy: 0.9149\n",
      "Epoch 287/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.2149 - val_accuracy: 0.9149\n",
      "Epoch 288/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.2160 - val_accuracy: 0.9149\n",
      "Epoch 289/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.2178 - val_accuracy: 0.9149\n",
      "Epoch 290/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.2192 - val_accuracy: 0.9149\n",
      "Epoch 291/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.2207 - val_accuracy: 0.9149\n",
      "Epoch 292/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.2209 - val_accuracy: 0.9362\n",
      "Epoch 293/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.2193 - val_accuracy: 0.9149\n",
      "Epoch 294/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.2186 - val_accuracy: 0.9149\n",
      "Epoch 295/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.2192 - val_accuracy: 0.9149\n",
      "Epoch 296/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.2203 - val_accuracy: 0.9149\n",
      "Epoch 297/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.2208 - val_accuracy: 0.9149\n",
      "Epoch 298/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.2214 - val_accuracy: 0.9362\n",
      "Epoch 299/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.2219 - val_accuracy: 0.9362\n",
      "Epoch 300/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.2215 - val_accuracy: 0.9362\n",
      "Epoch 301/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.2211 - val_accuracy: 0.9149\n",
      "Epoch 302/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.2217 - val_accuracy: 0.9149\n",
      "Epoch 303/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.2230 - val_accuracy: 0.9149\n",
      "Epoch 304/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.2228 - val_accuracy: 0.9149\n",
      "Epoch 305/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.2232 - val_accuracy: 0.9149\n",
      "Epoch 306/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.2228 - val_accuracy: 0.9149\n",
      "Epoch 307/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.2223 - val_accuracy: 0.9362\n",
      "Epoch 308/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.2220 - val_accuracy: 0.9362\n",
      "Epoch 309/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.2213 - val_accuracy: 0.9362\n",
      "Epoch 310/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.2213 - val_accuracy: 0.9149\n",
      "Epoch 311/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.2214 - val_accuracy: 0.9149\n",
      "Epoch 312/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.2225 - val_accuracy: 0.9149\n",
      "Epoch 313/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.2226 - val_accuracy: 0.9149\n",
      "Epoch 314/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.2231 - val_accuracy: 0.9149\n",
      "Epoch 315/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.2227 - val_accuracy: 0.9149\n",
      "Epoch 316/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.2219 - val_accuracy: 0.9149\n",
      "Epoch 317/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.2219 - val_accuracy: 0.9149\n",
      "Epoch 318/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.2221 - val_accuracy: 0.9149\n",
      "Epoch 319/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.2225 - val_accuracy: 0.9149\n",
      "Epoch 320/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.2225 - val_accuracy: 0.9149\n",
      "Epoch 321/1000\n",
      "53/53 [==============================] - 0s 471us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.2227 - val_accuracy: 0.9149\n",
      "Epoch 322/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.2233 - val_accuracy: 0.9149\n",
      "Epoch 323/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2242 - val_accuracy: 0.9149\n",
      "Epoch 324/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.2240 - val_accuracy: 0.9149\n",
      "Epoch 325/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.2243 - val_accuracy: 0.9149\n",
      "Epoch 326/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.2250 - val_accuracy: 0.9149\n",
      "Epoch 327/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.2250 - val_accuracy: 0.9149\n",
      "Epoch 328/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.2254 - val_accuracy: 0.9149\n",
      "Epoch 329/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.2256 - val_accuracy: 0.9149\n",
      "Epoch 330/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2269 - val_accuracy: 0.9149\n",
      "Epoch 331/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 452us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2293 - val_accuracy: 0.9149\n",
      "Epoch 332/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.2311 - val_accuracy: 0.9149\n",
      "Epoch 333/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.2305 - val_accuracy: 0.9149\n",
      "Epoch 334/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2303 - val_accuracy: 0.9149\n",
      "Epoch 335/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2307 - val_accuracy: 0.9149\n",
      "Epoch 336/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2313 - val_accuracy: 0.9149\n",
      "Epoch 337/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.2311 - val_accuracy: 0.9149\n",
      "Epoch 338/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2312 - val_accuracy: 0.9149\n",
      "Epoch 339/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2308 - val_accuracy: 0.9149\n",
      "Epoch 340/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2320 - val_accuracy: 0.9149\n",
      "Epoch 341/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2336 - val_accuracy: 0.9149\n",
      "Epoch 342/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.2341 - val_accuracy: 0.9149\n",
      "Epoch 343/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2333 - val_accuracy: 0.9149\n",
      "Epoch 344/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2334 - val_accuracy: 0.9149\n",
      "Epoch 345/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2333 - val_accuracy: 0.9149\n",
      "Epoch 346/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2334 - val_accuracy: 0.9149\n",
      "Epoch 347/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2335 - val_accuracy: 0.9149\n",
      "Epoch 348/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2342 - val_accuracy: 0.9149\n",
      "Epoch 349/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2351 - val_accuracy: 0.9149\n",
      "Epoch 350/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2369 - val_accuracy: 0.9149\n",
      "Epoch 351/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2384 - val_accuracy: 0.9149\n",
      "Epoch 352/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2391 - val_accuracy: 0.9149\n",
      "Epoch 353/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2396 - val_accuracy: 0.9149\n",
      "Epoch 354/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2392 - val_accuracy: 0.9149\n",
      "Epoch 355/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2389 - val_accuracy: 0.9149\n",
      "Epoch 356/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2385 - val_accuracy: 0.9149\n",
      "Epoch 357/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2382 - val_accuracy: 0.9149\n",
      "Epoch 358/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2386 - val_accuracy: 0.9149\n",
      "Epoch 359/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2392 - val_accuracy: 0.9149\n",
      "Epoch 360/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2406 - val_accuracy: 0.9149\n",
      "Epoch 361/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2414 - val_accuracy: 0.9149\n",
      "Epoch 362/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2422 - val_accuracy: 0.9149\n",
      "Epoch 363/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2431 - val_accuracy: 0.9149\n",
      "Epoch 364/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2432 - val_accuracy: 0.9149\n",
      "Epoch 365/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2439 - val_accuracy: 0.9149\n",
      "Epoch 366/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2437 - val_accuracy: 0.9149\n",
      "Epoch 367/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2432 - val_accuracy: 0.9149\n",
      "Epoch 368/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2424 - val_accuracy: 0.9149\n",
      "Epoch 369/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2420 - val_accuracy: 0.9149\n",
      "Epoch 370/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2421 - val_accuracy: 0.9149\n",
      "Epoch 371/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2427 - val_accuracy: 0.9149\n",
      "Epoch 372/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2430 - val_accuracy: 0.9149\n",
      "Epoch 373/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2437 - val_accuracy: 0.9149\n",
      "Epoch 374/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2443 - val_accuracy: 0.9149\n",
      "Epoch 375/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2446 - val_accuracy: 0.9149\n",
      "Epoch 376/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2448 - val_accuracy: 0.9149\n",
      "Epoch 377/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2455 - val_accuracy: 0.9149\n",
      "Epoch 378/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2454 - val_accuracy: 0.9149\n",
      "Epoch 379/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2462 - val_accuracy: 0.9149\n",
      "Epoch 380/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2457 - val_accuracy: 0.9149\n",
      "Epoch 381/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2460 - val_accuracy: 0.9149\n",
      "Epoch 382/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2464 - val_accuracy: 0.9149\n",
      "Epoch 383/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2465 - val_accuracy: 0.9149\n",
      "Epoch 384/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2468 - val_accuracy: 0.9149\n",
      "Epoch 385/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2467 - val_accuracy: 0.9149\n",
      "Epoch 386/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2466 - val_accuracy: 0.9149\n",
      "Epoch 387/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2466 - val_accuracy: 0.9149\n",
      "Epoch 388/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2464 - val_accuracy: 0.9149\n",
      "Epoch 389/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2465 - val_accuracy: 0.9149\n",
      "Epoch 390/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2469 - val_accuracy: 0.9149\n",
      "Epoch 391/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2464 - val_accuracy: 0.9149\n",
      "Epoch 392/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2455 - val_accuracy: 0.9149\n",
      "Epoch 393/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2456 - val_accuracy: 0.9149\n",
      "Epoch 394/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2457 - val_accuracy: 0.9149\n",
      "Epoch 395/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2462 - val_accuracy: 0.9149\n",
      "Epoch 396/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2471 - val_accuracy: 0.9149\n",
      "Epoch 397/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2485 - val_accuracy: 0.9149\n",
      "Epoch 398/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2495 - val_accuracy: 0.9149\n",
      "Epoch 399/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2495 - val_accuracy: 0.9149\n",
      "Epoch 400/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2485 - val_accuracy: 0.9149\n",
      "Epoch 401/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2482 - val_accuracy: 0.9149\n",
      "Epoch 402/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2482 - val_accuracy: 0.9149\n",
      "Epoch 403/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2481 - val_accuracy: 0.9149\n",
      "Epoch 404/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2485 - val_accuracy: 0.9149\n",
      "Epoch 405/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2497 - val_accuracy: 0.9149\n",
      "Epoch 406/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2508 - val_accuracy: 0.9149\n",
      "Epoch 407/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2526 - val_accuracy: 0.9149\n",
      "Epoch 408/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2533 - val_accuracy: 0.9149\n",
      "Epoch 409/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2533 - val_accuracy: 0.9149\n",
      "Epoch 410/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2537 - val_accuracy: 0.9149\n",
      "Epoch 411/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2535 - val_accuracy: 0.9149\n",
      "Epoch 412/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2532 - val_accuracy: 0.9149\n",
      "Epoch 413/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2534 - val_accuracy: 0.9149\n",
      "Epoch 414/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2535 - val_accuracy: 0.9149\n",
      "Epoch 415/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2548 - val_accuracy: 0.9149\n",
      "Epoch 416/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2565 - val_accuracy: 0.9149\n",
      "Epoch 417/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2580 - val_accuracy: 0.9149\n",
      "Epoch 418/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2588 - val_accuracy: 0.9149\n",
      "Epoch 419/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2597 - val_accuracy: 0.9149\n",
      "Epoch 420/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2601 - val_accuracy: 0.9149\n",
      "Epoch 421/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2605 - val_accuracy: 0.9149\n",
      "Epoch 422/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2602 - val_accuracy: 0.9149\n",
      "Epoch 423/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2599 - val_accuracy: 0.9149\n",
      "Epoch 424/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2597 - val_accuracy: 0.9149\n",
      "Epoch 425/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2598 - val_accuracy: 0.9149\n",
      "Epoch 426/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2602 - val_accuracy: 0.9149\n",
      "Epoch 427/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2610 - val_accuracy: 0.9149\n",
      "Epoch 428/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2615 - val_accuracy: 0.9149\n",
      "Epoch 429/1000\n",
      "53/53 [==============================] - 0s 564us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2613 - val_accuracy: 0.9149\n",
      "Epoch 430/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2618 - val_accuracy: 0.9149\n",
      "Epoch 431/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2620 - val_accuracy: 0.9149\n",
      "Epoch 432/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2624 - val_accuracy: 0.9149\n",
      "Epoch 433/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2633 - val_accuracy: 0.9149\n",
      "Epoch 434/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2635 - val_accuracy: 0.9149\n",
      "Epoch 435/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2630 - val_accuracy: 0.9149\n",
      "Epoch 436/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2632 - val_accuracy: 0.9149\n",
      "Epoch 437/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2640 - val_accuracy: 0.9149\n",
      "Epoch 438/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2658 - val_accuracy: 0.9149\n",
      "Epoch 439/1000\n",
      "53/53 [==============================] - 0s 471us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2668 - val_accuracy: 0.9149\n",
      "Epoch 440/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2679 - val_accuracy: 0.9149\n",
      "Epoch 441/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2684 - val_accuracy: 0.9149\n",
      "Epoch 442/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2680 - val_accuracy: 0.9149\n",
      "Epoch 443/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 470us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2680 - val_accuracy: 0.9149\n",
      "Epoch 444/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2676 - val_accuracy: 0.9149\n",
      "Epoch 445/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2679 - val_accuracy: 0.9149\n",
      "Epoch 446/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2690 - val_accuracy: 0.9149\n",
      "Epoch 447/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2702 - val_accuracy: 0.9149\n",
      "Epoch 448/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2710 - val_accuracy: 0.9149\n",
      "Epoch 449/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2708 - val_accuracy: 0.9149\n",
      "Epoch 450/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2708 - val_accuracy: 0.9149\n",
      "Epoch 451/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2712 - val_accuracy: 0.9149\n",
      "Epoch 452/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2717 - val_accuracy: 0.9149\n",
      "Epoch 453/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2718 - val_accuracy: 0.9149\n",
      "Epoch 454/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2723 - val_accuracy: 0.9149\n",
      "Epoch 455/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2732 - val_accuracy: 0.9149\n",
      "Epoch 456/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2734 - val_accuracy: 0.9149\n",
      "Epoch 457/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2739 - val_accuracy: 0.9149\n",
      "Epoch 458/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2738 - val_accuracy: 0.9149\n",
      "Epoch 459/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2742 - val_accuracy: 0.9149\n",
      "Epoch 460/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2748 - val_accuracy: 0.9149\n",
      "Epoch 461/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2754 - val_accuracy: 0.9149\n",
      "Epoch 462/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2761 - val_accuracy: 0.9149\n",
      "Epoch 463/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2768 - val_accuracy: 0.9149\n",
      "Epoch 464/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2771 - val_accuracy: 0.9149\n",
      "Epoch 465/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2770 - val_accuracy: 0.9149\n",
      "Epoch 466/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2773 - val_accuracy: 0.9149\n",
      "Epoch 467/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2780 - val_accuracy: 0.9149\n",
      "Epoch 468/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2786 - val_accuracy: 0.9149\n",
      "Epoch 469/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2796 - val_accuracy: 0.9149\n",
      "Epoch 470/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2814 - val_accuracy: 0.9149\n",
      "Epoch 471/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2816 - val_accuracy: 0.9149\n",
      "Epoch 472/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2820 - val_accuracy: 0.9149\n",
      "Epoch 473/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2815 - val_accuracy: 0.9149\n",
      "Epoch 474/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2814 - val_accuracy: 0.8936\n",
      "Epoch 475/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2819 - val_accuracy: 0.8936\n",
      "Epoch 476/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2825 - val_accuracy: 0.8936\n",
      "Epoch 477/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2828 - val_accuracy: 0.8936\n",
      "Epoch 478/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2836 - val_accuracy: 0.8936\n",
      "Epoch 479/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2844 - val_accuracy: 0.9149\n",
      "Epoch 480/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2857 - val_accuracy: 0.9149\n",
      "Epoch 481/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2866 - val_accuracy: 0.9149\n",
      "Epoch 482/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2870 - val_accuracy: 0.9149\n",
      "Epoch 483/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2871 - val_accuracy: 0.9149\n",
      "Epoch 484/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2866 - val_accuracy: 0.8936\n",
      "Epoch 485/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2868 - val_accuracy: 0.8936\n",
      "Epoch 486/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2872 - val_accuracy: 0.8936\n",
      "Epoch 487/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2880 - val_accuracy: 0.8936\n",
      "Epoch 488/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2892 - val_accuracy: 0.8936\n",
      "Epoch 489/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2901 - val_accuracy: 0.8936\n",
      "Epoch 490/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2911 - val_accuracy: 0.9149\n",
      "Epoch 491/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2909 - val_accuracy: 0.8936\n",
      "Epoch 492/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2906 - val_accuracy: 0.8936\n",
      "Epoch 493/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2906 - val_accuracy: 0.8936\n",
      "Epoch 494/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2913 - val_accuracy: 0.8936\n",
      "Epoch 495/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2923 - val_accuracy: 0.8936\n",
      "Epoch 496/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2933 - val_accuracy: 0.8936\n",
      "Epoch 497/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2938 - val_accuracy: 0.8936\n",
      "Epoch 498/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 9.9024e-04 - accuracy: 1.0000 - val_loss: 0.2941 - val_accuracy: 0.8936\n",
      "Epoch 499/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 9.8146e-04 - accuracy: 1.0000 - val_loss: 0.2941 - val_accuracy: 0.8936\n",
      "Epoch 500/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 9.7647e-04 - accuracy: 1.0000 - val_loss: 0.2942 - val_accuracy: 0.8936\n",
      "Epoch 501/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 9.9091e-04 - accuracy: 1.0000 - val_loss: 0.2946 - val_accuracy: 0.8936\n",
      "Epoch 502/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2948 - val_accuracy: 0.8936\n",
      "Epoch 503/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 9.7113e-04 - accuracy: 1.0000 - val_loss: 0.2955 - val_accuracy: 0.8936\n",
      "Epoch 504/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 9.5683e-04 - accuracy: 1.0000 - val_loss: 0.2961 - val_accuracy: 0.8936\n",
      "Epoch 505/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 9.9388e-04 - accuracy: 1.0000 - val_loss: 0.2968 - val_accuracy: 0.8936\n",
      "Epoch 506/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 9.5024e-04 - accuracy: 1.0000 - val_loss: 0.2971 - val_accuracy: 0.8936\n",
      "Epoch 507/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 9.7807e-04 - accuracy: 1.0000 - val_loss: 0.2972 - val_accuracy: 0.8936\n",
      "Epoch 508/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 9.7344e-04 - accuracy: 1.0000 - val_loss: 0.2979 - val_accuracy: 0.8936\n",
      "Epoch 509/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 9.3348e-04 - accuracy: 1.0000 - val_loss: 0.2980 - val_accuracy: 0.8936\n",
      "Epoch 510/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 9.2776e-04 - accuracy: 1.0000 - val_loss: 0.2982 - val_accuracy: 0.8936\n",
      "Epoch 511/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 9.2219e-04 - accuracy: 1.0000 - val_loss: 0.2985 - val_accuracy: 0.8936\n",
      "Epoch 512/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 9.4105e-04 - accuracy: 1.0000 - val_loss: 0.2988 - val_accuracy: 0.8936\n",
      "Epoch 513/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 9.5627e-04 - accuracy: 1.0000 - val_loss: 0.2998 - val_accuracy: 0.8936\n",
      "Epoch 514/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 9.3528e-04 - accuracy: 1.0000 - val_loss: 0.3004 - val_accuracy: 0.8936\n",
      "Epoch 515/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 9.0637e-04 - accuracy: 1.0000 - val_loss: 0.3004 - val_accuracy: 0.8936\n",
      "Epoch 516/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 8.9947e-04 - accuracy: 1.0000 - val_loss: 0.3005 - val_accuracy: 0.8936\n",
      "Epoch 517/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 9.1354e-04 - accuracy: 1.0000 - val_loss: 0.3008 - val_accuracy: 0.8936\n",
      "Epoch 518/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 9.0405e-04 - accuracy: 1.0000 - val_loss: 0.3011 - val_accuracy: 0.8936\n",
      "Epoch 519/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 9.5141e-04 - accuracy: 1.0000 - val_loss: 0.3014 - val_accuracy: 0.8936\n",
      "Epoch 520/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 9.3767e-04 - accuracy: 1.0000 - val_loss: 0.3021 - val_accuracy: 0.8936\n",
      "Epoch 521/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 8.8059e-04 - accuracy: 1.0000 - val_loss: 0.3024 - val_accuracy: 0.8936\n",
      "Epoch 522/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 8.8260e-04 - accuracy: 1.0000 - val_loss: 0.3028 - val_accuracy: 0.8936\n",
      "Epoch 523/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 8.6290e-04 - accuracy: 1.0000 - val_loss: 0.3038 - val_accuracy: 0.8936\n",
      "Epoch 524/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 8.6624e-04 - accuracy: 1.0000 - val_loss: 0.3050 - val_accuracy: 0.8936\n",
      "Epoch 525/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 8.8191e-04 - accuracy: 1.0000 - val_loss: 0.3058 - val_accuracy: 0.8936\n",
      "Epoch 526/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 9.0544e-04 - accuracy: 1.0000 - val_loss: 0.3062 - val_accuracy: 0.8936\n",
      "Epoch 527/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 8.7771e-04 - accuracy: 1.0000 - val_loss: 0.3066 - val_accuracy: 0.8936\n",
      "Epoch 528/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 8.7097e-04 - accuracy: 1.0000 - val_loss: 0.3066 - val_accuracy: 0.8936\n",
      "Epoch 529/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 8.4798e-04 - accuracy: 1.0000 - val_loss: 0.3062 - val_accuracy: 0.8936\n",
      "Epoch 530/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 8.3901e-04 - accuracy: 1.0000 - val_loss: 0.3062 - val_accuracy: 0.8936\n",
      "Epoch 531/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 9.1193e-04 - accuracy: 1.0000 - val_loss: 0.3060 - val_accuracy: 0.8936\n",
      "Epoch 532/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 8.7275e-04 - accuracy: 1.0000 - val_loss: 0.3067 - val_accuracy: 0.8936\n",
      "Epoch 533/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 8.9853e-04 - accuracy: 1.0000 - val_loss: 0.3081 - val_accuracy: 0.8936\n",
      "Epoch 534/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 8.2121e-04 - accuracy: 1.0000 - val_loss: 0.3093 - val_accuracy: 0.8936\n",
      "Epoch 535/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 8.2798e-04 - accuracy: 1.0000 - val_loss: 0.3101 - val_accuracy: 0.8936\n",
      "Epoch 536/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 8.3237e-04 - accuracy: 1.0000 - val_loss: 0.3106 - val_accuracy: 0.8936\n",
      "Epoch 537/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 8.4755e-04 - accuracy: 1.0000 - val_loss: 0.3108 - val_accuracy: 0.8936\n",
      "Epoch 538/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 8.3228e-04 - accuracy: 1.0000 - val_loss: 0.3112 - val_accuracy: 0.8936\n",
      "Epoch 539/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 8.0490e-04 - accuracy: 1.0000 - val_loss: 0.3117 - val_accuracy: 0.8936\n",
      "Epoch 540/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 8.0240e-04 - accuracy: 1.0000 - val_loss: 0.3121 - val_accuracy: 0.8936\n",
      "Epoch 541/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 8.1347e-04 - accuracy: 1.0000 - val_loss: 0.3124 - val_accuracy: 0.8936\n",
      "Epoch 542/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 8.3479e-04 - accuracy: 1.0000 - val_loss: 0.3121 - val_accuracy: 0.8936\n",
      "Epoch 543/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 8.1148e-04 - accuracy: 1.0000 - val_loss: 0.3121 - val_accuracy: 0.8936\n",
      "Epoch 544/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 8.1412e-04 - accuracy: 1.0000 - val_loss: 0.3130 - val_accuracy: 0.8936\n",
      "Epoch 545/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 7.9789e-04 - accuracy: 1.0000 - val_loss: 0.3133 - val_accuracy: 0.8936\n",
      "Epoch 546/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 7.7516e-04 - accuracy: 1.0000 - val_loss: 0.3140 - val_accuracy: 0.8936\n",
      "Epoch 547/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 7.8285e-04 - accuracy: 1.0000 - val_loss: 0.3146 - val_accuracy: 0.8936\n",
      "Epoch 548/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 7.7351e-04 - accuracy: 1.0000 - val_loss: 0.3152 - val_accuracy: 0.8936\n",
      "Epoch 549/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 7.8587e-04 - accuracy: 1.0000 - val_loss: 0.3155 - val_accuracy: 0.8936\n",
      "Epoch 550/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 7.6719e-04 - accuracy: 1.0000 - val_loss: 0.3160 - val_accuracy: 0.8936\n",
      "Epoch 551/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 7.8580e-04 - accuracy: 1.0000 - val_loss: 0.3166 - val_accuracy: 0.8936\n",
      "Epoch 552/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 7.6084e-04 - accuracy: 1.0000 - val_loss: 0.3166 - val_accuracy: 0.8936\n",
      "Epoch 553/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 7.8956e-04 - accuracy: 1.0000 - val_loss: 0.3167 - val_accuracy: 0.8936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 554/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 7.6675e-04 - accuracy: 1.0000 - val_loss: 0.3174 - val_accuracy: 0.8936\n",
      "Epoch 555/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 7.4491e-04 - accuracy: 1.0000 - val_loss: 0.3177 - val_accuracy: 0.8936\n",
      "Epoch 556/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 7.6774e-04 - accuracy: 1.0000 - val_loss: 0.3178 - val_accuracy: 0.8936\n",
      "Epoch 557/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 7.4129e-04 - accuracy: 1.0000 - val_loss: 0.3184 - val_accuracy: 0.8936\n",
      "Epoch 558/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 7.6586e-04 - accuracy: 1.0000 - val_loss: 0.3192 - val_accuracy: 0.8936\n",
      "Epoch 559/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 7.3225e-04 - accuracy: 1.0000 - val_loss: 0.3195 - val_accuracy: 0.8936\n",
      "Epoch 560/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 7.4227e-04 - accuracy: 1.0000 - val_loss: 0.3200 - val_accuracy: 0.8936\n",
      "Epoch 561/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 7.2385e-04 - accuracy: 1.0000 - val_loss: 0.3202 - val_accuracy: 0.8936\n",
      "Epoch 562/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 7.5641e-04 - accuracy: 1.0000 - val_loss: 0.3202 - val_accuracy: 0.8936\n",
      "Epoch 563/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 7.2356e-04 - accuracy: 1.0000 - val_loss: 0.3205 - val_accuracy: 0.8936\n",
      "Epoch 564/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 7.2451e-04 - accuracy: 1.0000 - val_loss: 0.3209 - val_accuracy: 0.8936\n",
      "Epoch 565/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 7.4513e-04 - accuracy: 1.0000 - val_loss: 0.3219 - val_accuracy: 0.8936\n",
      "Epoch 566/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 7.3155e-04 - accuracy: 1.0000 - val_loss: 0.3224 - val_accuracy: 0.8936\n",
      "Epoch 567/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 7.0412e-04 - accuracy: 1.0000 - val_loss: 0.3223 - val_accuracy: 0.8936\n",
      "Epoch 568/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 7.0346e-04 - accuracy: 1.0000 - val_loss: 0.3223 - val_accuracy: 0.8936\n",
      "Epoch 569/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 7.3773e-04 - accuracy: 1.0000 - val_loss: 0.3221 - val_accuracy: 0.8936\n",
      "Epoch 570/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 7.1562e-04 - accuracy: 1.0000 - val_loss: 0.3224 - val_accuracy: 0.8936\n",
      "Epoch 571/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 6.9504e-04 - accuracy: 1.0000 - val_loss: 0.3227 - val_accuracy: 0.8936\n",
      "Epoch 572/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 6.9257e-04 - accuracy: 1.0000 - val_loss: 0.3233 - val_accuracy: 0.8936\n",
      "Epoch 573/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 6.8534e-04 - accuracy: 1.0000 - val_loss: 0.3239 - val_accuracy: 0.8936\n",
      "Epoch 574/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 7.0192e-04 - accuracy: 1.0000 - val_loss: 0.3246 - val_accuracy: 0.8936\n",
      "Epoch 575/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 6.7584e-04 - accuracy: 1.0000 - val_loss: 0.3248 - val_accuracy: 0.8936\n",
      "Epoch 576/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 6.8538e-04 - accuracy: 1.0000 - val_loss: 0.3249 - val_accuracy: 0.8936\n",
      "Epoch 577/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 6.6944e-04 - accuracy: 1.0000 - val_loss: 0.3249 - val_accuracy: 0.8936\n",
      "Epoch 578/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 6.6825e-04 - accuracy: 1.0000 - val_loss: 0.3252 - val_accuracy: 0.8936\n",
      "Epoch 579/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 6.7830e-04 - accuracy: 1.0000 - val_loss: 0.3257 - val_accuracy: 0.8936\n",
      "Epoch 580/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 6.8857e-04 - accuracy: 1.0000 - val_loss: 0.3259 - val_accuracy: 0.8936\n",
      "Epoch 581/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 6.6137e-04 - accuracy: 1.0000 - val_loss: 0.3267 - val_accuracy: 0.8936\n",
      "Epoch 582/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 6.5673e-04 - accuracy: 1.0000 - val_loss: 0.3276 - val_accuracy: 0.8936\n",
      "Epoch 583/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 6.5509e-04 - accuracy: 1.0000 - val_loss: 0.3283 - val_accuracy: 0.8936\n",
      "Epoch 584/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 6.4928e-04 - accuracy: 1.0000 - val_loss: 0.3292 - val_accuracy: 0.8936\n",
      "Epoch 585/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 6.5864e-04 - accuracy: 1.0000 - val_loss: 0.3297 - val_accuracy: 0.8936\n",
      "Epoch 586/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 6.8555e-04 - accuracy: 1.0000 - val_loss: 0.3302 - val_accuracy: 0.8936\n",
      "Epoch 587/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 6.6050e-04 - accuracy: 1.0000 - val_loss: 0.3300 - val_accuracy: 0.8936\n",
      "Epoch 588/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 6.4236e-04 - accuracy: 1.0000 - val_loss: 0.3300 - val_accuracy: 0.8936\n",
      "Epoch 589/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 6.2357e-04 - accuracy: 1.0000 - val_loss: 0.3300 - val_accuracy: 0.8936\n",
      "Epoch 590/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 6.3288e-04 - accuracy: 1.0000 - val_loss: 0.3296 - val_accuracy: 0.8936\n",
      "Epoch 591/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 6.4954e-04 - accuracy: 1.0000 - val_loss: 0.3296 - val_accuracy: 0.8936\n",
      "Epoch 592/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 6.5994e-04 - accuracy: 1.0000 - val_loss: 0.3300 - val_accuracy: 0.8936\n",
      "Epoch 593/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 6.6418e-04 - accuracy: 1.0000 - val_loss: 0.3305 - val_accuracy: 0.8936\n",
      "Epoch 594/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 6.4843e-04 - accuracy: 1.0000 - val_loss: 0.3313 - val_accuracy: 0.8936\n",
      "Epoch 595/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 6.2726e-04 - accuracy: 1.0000 - val_loss: 0.3320 - val_accuracy: 0.8936\n",
      "Epoch 596/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 6.4722e-04 - accuracy: 1.0000 - val_loss: 0.3326 - val_accuracy: 0.8936\n",
      "Epoch 597/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 6.1473e-04 - accuracy: 1.0000 - val_loss: 0.3329 - val_accuracy: 0.8936\n",
      "Epoch 598/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 6.1277e-04 - accuracy: 1.0000 - val_loss: 0.3331 - val_accuracy: 0.8936\n",
      "Epoch 599/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 6.0957e-04 - accuracy: 1.0000 - val_loss: 0.3335 - val_accuracy: 0.8936\n",
      "Epoch 600/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 6.0457e-04 - accuracy: 1.0000 - val_loss: 0.3337 - val_accuracy: 0.8936\n",
      "Epoch 601/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 6.2134e-04 - accuracy: 1.0000 - val_loss: 0.3339 - val_accuracy: 0.8936\n",
      "Epoch 602/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 6.0025e-04 - accuracy: 1.0000 - val_loss: 0.3343 - val_accuracy: 0.8936\n",
      "Epoch 603/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 5.9755e-04 - accuracy: 1.0000 - val_loss: 0.3347 - val_accuracy: 0.8936\n",
      "Epoch 604/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 6.0548e-04 - accuracy: 1.0000 - val_loss: 0.3350 - val_accuracy: 0.8936\n",
      "Epoch 605/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 5.9303e-04 - accuracy: 1.0000 - val_loss: 0.3356 - val_accuracy: 0.8936\n",
      "Epoch 606/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 5.9413e-04 - accuracy: 1.0000 - val_loss: 0.3361 - val_accuracy: 0.8936\n",
      "Epoch 607/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 6.0615e-04 - accuracy: 1.0000 - val_loss: 0.3363 - val_accuracy: 0.8936\n",
      "Epoch 608/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 5.8780e-04 - accuracy: 1.0000 - val_loss: 0.3366 - val_accuracy: 0.8936\n",
      "Epoch 609/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 5.9730e-04 - accuracy: 1.0000 - val_loss: 0.3369 - val_accuracy: 0.8936\n",
      "Epoch 610/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 5.8281e-04 - accuracy: 1.0000 - val_loss: 0.3376 - val_accuracy: 0.8936\n",
      "Epoch 611/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 5.9404e-04 - accuracy: 1.0000 - val_loss: 0.3381 - val_accuracy: 0.8936\n",
      "Epoch 612/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 5.7581e-04 - accuracy: 1.0000 - val_loss: 0.3382 - val_accuracy: 0.8936\n",
      "Epoch 613/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 5.9807e-04 - accuracy: 1.0000 - val_loss: 0.3382 - val_accuracy: 0.8936\n",
      "Epoch 614/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 5.7232e-04 - accuracy: 1.0000 - val_loss: 0.3385 - val_accuracy: 0.8936\n",
      "Epoch 615/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 5.8016e-04 - accuracy: 1.0000 - val_loss: 0.3390 - val_accuracy: 0.8936\n",
      "Epoch 616/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 5.6439e-04 - accuracy: 1.0000 - val_loss: 0.3397 - val_accuracy: 0.8936\n",
      "Epoch 617/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 5.6293e-04 - accuracy: 1.0000 - val_loss: 0.3406 - val_accuracy: 0.8936\n",
      "Epoch 618/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 5.6297e-04 - accuracy: 1.0000 - val_loss: 0.3412 - val_accuracy: 0.8936\n",
      "Epoch 619/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 5.7980e-04 - accuracy: 1.0000 - val_loss: 0.3418 - val_accuracy: 0.8936\n",
      "Epoch 620/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 5.6266e-04 - accuracy: 1.0000 - val_loss: 0.3419 - val_accuracy: 0.8936\n",
      "Epoch 621/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 5.4565e-04 - accuracy: 1.0000 - val_loss: 0.3419 - val_accuracy: 0.8936\n",
      "Epoch 622/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 5.4227e-04 - accuracy: 1.0000 - val_loss: 0.3415 - val_accuracy: 0.8936\n",
      "Epoch 623/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 5.5513e-04 - accuracy: 1.0000 - val_loss: 0.3415 - val_accuracy: 0.8936\n",
      "Epoch 624/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 5.7782e-04 - accuracy: 1.0000 - val_loss: 0.3417 - val_accuracy: 0.8936\n",
      "Epoch 625/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 5.9075e-04 - accuracy: 1.0000 - val_loss: 0.3423 - val_accuracy: 0.8936\n",
      "Epoch 626/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 5.7700e-04 - accuracy: 1.0000 - val_loss: 0.3430 - val_accuracy: 0.8936\n",
      "Epoch 627/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 5.8646e-04 - accuracy: 1.0000 - val_loss: 0.3442 - val_accuracy: 0.8936\n",
      "Epoch 628/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 5.6395e-04 - accuracy: 1.0000 - val_loss: 0.3452 - val_accuracy: 0.8936\n",
      "Epoch 629/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 5.4199e-04 - accuracy: 1.0000 - val_loss: 0.3457 - val_accuracy: 0.8936\n",
      "Epoch 630/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 5.3546e-04 - accuracy: 1.0000 - val_loss: 0.3465 - val_accuracy: 0.8936\n",
      "Epoch 631/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 5.3292e-04 - accuracy: 1.0000 - val_loss: 0.3473 - val_accuracy: 0.8936\n",
      "Epoch 632/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 5.5840e-04 - accuracy: 1.0000 - val_loss: 0.3479 - val_accuracy: 0.8936\n",
      "Epoch 633/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 5.4205e-04 - accuracy: 1.0000 - val_loss: 0.3479 - val_accuracy: 0.8936\n",
      "Epoch 634/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 5.2944e-04 - accuracy: 1.0000 - val_loss: 0.3475 - val_accuracy: 0.8936\n",
      "Epoch 635/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 5.2141e-04 - accuracy: 1.0000 - val_loss: 0.3474 - val_accuracy: 0.8936\n",
      "Epoch 636/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 5.2594e-04 - accuracy: 1.0000 - val_loss: 0.3473 - val_accuracy: 0.8936\n",
      "Epoch 637/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 5.5511e-04 - accuracy: 1.0000 - val_loss: 0.3475 - val_accuracy: 0.8936\n",
      "Epoch 638/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 5.5280e-04 - accuracy: 1.0000 - val_loss: 0.3484 - val_accuracy: 0.8936\n",
      "Epoch 639/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 5.1755e-04 - accuracy: 1.0000 - val_loss: 0.3492 - val_accuracy: 0.8936\n",
      "Epoch 640/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 5.1189e-04 - accuracy: 1.0000 - val_loss: 0.3498 - val_accuracy: 0.8936\n",
      "Epoch 641/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 5.0902e-04 - accuracy: 1.0000 - val_loss: 0.3503 - val_accuracy: 0.8936\n",
      "Epoch 642/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 5.2400e-04 - accuracy: 1.0000 - val_loss: 0.3509 - val_accuracy: 0.8936\n",
      "Epoch 643/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 5.0633e-04 - accuracy: 1.0000 - val_loss: 0.3509 - val_accuracy: 0.8936\n",
      "Epoch 644/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 5.0546e-04 - accuracy: 1.0000 - val_loss: 0.3511 - val_accuracy: 0.8936\n",
      "Epoch 645/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 5.0088e-04 - accuracy: 1.0000 - val_loss: 0.3509 - val_accuracy: 0.8936\n",
      "Epoch 646/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 5.0231e-04 - accuracy: 1.0000 - val_loss: 0.3507 - val_accuracy: 0.8936\n",
      "Epoch 647/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 5.2380e-04 - accuracy: 1.0000 - val_loss: 0.3507 - val_accuracy: 0.8936\n",
      "Epoch 648/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 5.2272e-04 - accuracy: 1.0000 - val_loss: 0.3515 - val_accuracy: 0.8936\n",
      "Epoch 649/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 4.9518e-04 - accuracy: 1.0000 - val_loss: 0.3522 - val_accuracy: 0.8936\n",
      "Epoch 650/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 4.9144e-04 - accuracy: 1.0000 - val_loss: 0.3528 - val_accuracy: 0.8936\n",
      "Epoch 651/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 4.9355e-04 - accuracy: 1.0000 - val_loss: 0.3534 - val_accuracy: 0.8936\n",
      "Epoch 652/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 4.8779e-04 - accuracy: 1.0000 - val_loss: 0.3542 - val_accuracy: 0.8936\n",
      "Epoch 653/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 4.9034e-04 - accuracy: 1.0000 - val_loss: 0.3551 - val_accuracy: 0.8936\n",
      "Epoch 654/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 4.9122e-04 - accuracy: 1.0000 - val_loss: 0.3556 - val_accuracy: 0.8936\n",
      "Epoch 655/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 4.9015e-04 - accuracy: 1.0000 - val_loss: 0.3559 - val_accuracy: 0.8936\n",
      "Epoch 656/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 4.9785e-04 - accuracy: 1.0000 - val_loss: 0.3559 - val_accuracy: 0.8936\n",
      "Epoch 657/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 4.9046e-04 - accuracy: 1.0000 - val_loss: 0.3561 - val_accuracy: 0.8936\n",
      "Epoch 658/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 4.9677e-04 - accuracy: 1.0000 - val_loss: 0.3560 - val_accuracy: 0.8936\n",
      "Epoch 659/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 4.7303e-04 - accuracy: 1.0000 - val_loss: 0.3563 - val_accuracy: 0.8936\n",
      "Epoch 660/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 4.8047e-04 - accuracy: 1.0000 - val_loss: 0.3568 - val_accuracy: 0.8936\n",
      "Epoch 661/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 4.6985e-04 - accuracy: 1.0000 - val_loss: 0.3571 - val_accuracy: 0.8936\n",
      "Epoch 662/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 4.8295e-04 - accuracy: 1.0000 - val_loss: 0.3574 - val_accuracy: 0.8936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 663/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 4.6877e-04 - accuracy: 1.0000 - val_loss: 0.3583 - val_accuracy: 0.8936\n",
      "Epoch 664/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 4.6455e-04 - accuracy: 1.0000 - val_loss: 0.3591 - val_accuracy: 0.8936\n",
      "Epoch 665/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 4.6221e-04 - accuracy: 1.0000 - val_loss: 0.3599 - val_accuracy: 0.8936\n",
      "Epoch 666/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 4.6695e-04 - accuracy: 1.0000 - val_loss: 0.3602 - val_accuracy: 0.8936\n",
      "Epoch 667/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 4.6188e-04 - accuracy: 1.0000 - val_loss: 0.3608 - val_accuracy: 0.8936\n",
      "Epoch 668/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 4.8019e-04 - accuracy: 1.0000 - val_loss: 0.3615 - val_accuracy: 0.8936\n",
      "Epoch 669/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 4.6378e-04 - accuracy: 1.0000 - val_loss: 0.3616 - val_accuracy: 0.8936\n",
      "Epoch 670/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 4.5616e-04 - accuracy: 1.0000 - val_loss: 0.3617 - val_accuracy: 0.8936\n",
      "Epoch 671/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 4.6885e-04 - accuracy: 1.0000 - val_loss: 0.3616 - val_accuracy: 0.8936\n",
      "Epoch 672/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 4.5955e-04 - accuracy: 1.0000 - val_loss: 0.3618 - val_accuracy: 0.8936\n",
      "Epoch 673/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 4.4731e-04 - accuracy: 1.0000 - val_loss: 0.3623 - val_accuracy: 0.8936\n",
      "Epoch 674/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 4.6005e-04 - accuracy: 1.0000 - val_loss: 0.3630 - val_accuracy: 0.8936\n",
      "Epoch 675/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 4.5073e-04 - accuracy: 1.0000 - val_loss: 0.3634 - val_accuracy: 0.8936\n",
      "Epoch 676/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 4.6203e-04 - accuracy: 1.0000 - val_loss: 0.3635 - val_accuracy: 0.8936\n",
      "Epoch 677/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 4.5305e-04 - accuracy: 1.0000 - val_loss: 0.3638 - val_accuracy: 0.8936\n",
      "Epoch 678/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 4.3896e-04 - accuracy: 1.0000 - val_loss: 0.3645 - val_accuracy: 0.8936\n",
      "Epoch 679/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 4.3740e-04 - accuracy: 1.0000 - val_loss: 0.3653 - val_accuracy: 0.8936\n",
      "Epoch 680/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 4.4915e-04 - accuracy: 1.0000 - val_loss: 0.3661 - val_accuracy: 0.8936\n",
      "Epoch 681/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 4.4564e-04 - accuracy: 1.0000 - val_loss: 0.3662 - val_accuracy: 0.8936\n",
      "Epoch 682/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 4.4301e-04 - accuracy: 1.0000 - val_loss: 0.3666 - val_accuracy: 0.8936\n",
      "Epoch 683/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 4.3114e-04 - accuracy: 1.0000 - val_loss: 0.3666 - val_accuracy: 0.8936\n",
      "Epoch 684/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 4.4159e-04 - accuracy: 1.0000 - val_loss: 0.3666 - val_accuracy: 0.8936\n",
      "Epoch 685/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 4.2740e-04 - accuracy: 1.0000 - val_loss: 0.3671 - val_accuracy: 0.8936\n",
      "Epoch 686/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 4.3549e-04 - accuracy: 1.0000 - val_loss: 0.3677 - val_accuracy: 0.8936\n",
      "Epoch 687/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 4.3554e-04 - accuracy: 1.0000 - val_loss: 0.3679 - val_accuracy: 0.8936\n",
      "Epoch 688/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 4.2228e-04 - accuracy: 1.0000 - val_loss: 0.3685 - val_accuracy: 0.8936\n",
      "Epoch 689/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 4.1948e-04 - accuracy: 1.0000 - val_loss: 0.3690 - val_accuracy: 0.8936\n",
      "Epoch 690/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 4.1826e-04 - accuracy: 1.0000 - val_loss: 0.3694 - val_accuracy: 0.8936\n",
      "Epoch 691/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 4.1732e-04 - accuracy: 1.0000 - val_loss: 0.3697 - val_accuracy: 0.8936\n",
      "Epoch 692/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 4.1572e-04 - accuracy: 1.0000 - val_loss: 0.3699 - val_accuracy: 0.8936\n",
      "Epoch 693/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 4.1399e-04 - accuracy: 1.0000 - val_loss: 0.3701 - val_accuracy: 0.8936\n",
      "Epoch 694/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 4.2128e-04 - accuracy: 1.0000 - val_loss: 0.3704 - val_accuracy: 0.8936\n",
      "Epoch 695/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 4.1474e-04 - accuracy: 1.0000 - val_loss: 0.3709 - val_accuracy: 0.8936\n",
      "Epoch 696/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 4.0960e-04 - accuracy: 1.0000 - val_loss: 0.3716 - val_accuracy: 0.8936\n",
      "Epoch 697/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 4.0993e-04 - accuracy: 1.0000 - val_loss: 0.3720 - val_accuracy: 0.8936\n",
      "Epoch 698/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 4.2020e-04 - accuracy: 1.0000 - val_loss: 0.3725 - val_accuracy: 0.8936\n",
      "Epoch 699/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 4.0988e-04 - accuracy: 1.0000 - val_loss: 0.3725 - val_accuracy: 0.8936\n",
      "Epoch 700/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 4.2355e-04 - accuracy: 1.0000 - val_loss: 0.3722 - val_accuracy: 0.8936\n",
      "Epoch 701/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 4.0281e-04 - accuracy: 1.0000 - val_loss: 0.3724 - val_accuracy: 0.8936\n",
      "Epoch 702/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 4.1393e-04 - accuracy: 1.0000 - val_loss: 0.3728 - val_accuracy: 0.8936\n",
      "Epoch 703/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 4.0180e-04 - accuracy: 1.0000 - val_loss: 0.3734 - val_accuracy: 0.8936\n",
      "Epoch 704/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 3.9811e-04 - accuracy: 1.0000 - val_loss: 0.3738 - val_accuracy: 0.8936\n",
      "Epoch 705/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 3.9575e-04 - accuracy: 1.0000 - val_loss: 0.3746 - val_accuracy: 0.8936\n",
      "Epoch 706/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 4.1458e-04 - accuracy: 1.0000 - val_loss: 0.3753 - val_accuracy: 0.8936\n",
      "Epoch 707/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 4.0655e-04 - accuracy: 1.0000 - val_loss: 0.3755 - val_accuracy: 0.8936\n",
      "Epoch 708/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 3.9340e-04 - accuracy: 1.0000 - val_loss: 0.3753 - val_accuracy: 0.8936\n",
      "Epoch 709/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 3.9003e-04 - accuracy: 1.0000 - val_loss: 0.3751 - val_accuracy: 0.8936\n",
      "Epoch 710/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 4.0712e-04 - accuracy: 1.0000 - val_loss: 0.3751 - val_accuracy: 0.8936\n",
      "Epoch 711/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 3.9222e-04 - accuracy: 1.0000 - val_loss: 0.3755 - val_accuracy: 0.8936\n",
      "Epoch 712/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 3.8911e-04 - accuracy: 1.0000 - val_loss: 0.3761 - val_accuracy: 0.8936\n",
      "Epoch 713/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 3.8915e-04 - accuracy: 1.0000 - val_loss: 0.3766 - val_accuracy: 0.8936\n",
      "Epoch 714/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 3.8089e-04 - accuracy: 1.0000 - val_loss: 0.3773 - val_accuracy: 0.8936\n",
      "Epoch 715/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 4.0095e-04 - accuracy: 1.0000 - val_loss: 0.3783 - val_accuracy: 0.8936\n",
      "Epoch 716/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 3.8635e-04 - accuracy: 1.0000 - val_loss: 0.3786 - val_accuracy: 0.8936\n",
      "Epoch 717/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 3.8522e-04 - accuracy: 1.0000 - val_loss: 0.3787 - val_accuracy: 0.8936\n",
      "Epoch 718/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 3.8406e-04 - accuracy: 1.0000 - val_loss: 0.3788 - val_accuracy: 0.8936\n",
      "Epoch 719/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 3.7417e-04 - accuracy: 1.0000 - val_loss: 0.3785 - val_accuracy: 0.8936\n",
      "Epoch 720/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 3.6810e-04 - accuracy: 1.0000 - val_loss: 0.3783 - val_accuracy: 0.8936\n",
      "Epoch 721/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 3.7103e-04 - accuracy: 1.0000 - val_loss: 0.3781 - val_accuracy: 0.8936\n",
      "Epoch 722/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 3.8375e-04 - accuracy: 1.0000 - val_loss: 0.3780 - val_accuracy: 0.8936\n",
      "Epoch 723/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 3.9891e-04 - accuracy: 1.0000 - val_loss: 0.3780 - val_accuracy: 0.8936\n",
      "Epoch 724/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 3.9471e-04 - accuracy: 1.0000 - val_loss: 0.3787 - val_accuracy: 0.8936\n",
      "Epoch 725/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 3.9357e-04 - accuracy: 1.0000 - val_loss: 0.3794 - val_accuracy: 0.8936\n",
      "Epoch 726/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 3.8053e-04 - accuracy: 1.0000 - val_loss: 0.3801 - val_accuracy: 0.8936\n",
      "Epoch 727/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 3.7329e-04 - accuracy: 1.0000 - val_loss: 0.3805 - val_accuracy: 0.8936\n",
      "Epoch 728/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 3.6355e-04 - accuracy: 1.0000 - val_loss: 0.3804 - val_accuracy: 0.8936\n",
      "Epoch 729/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 3.6210e-04 - accuracy: 1.0000 - val_loss: 0.3806 - val_accuracy: 0.8936\n",
      "Epoch 730/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 3.6095e-04 - accuracy: 1.0000 - val_loss: 0.3808 - val_accuracy: 0.8936\n",
      "Epoch 731/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 3.5966e-04 - accuracy: 1.0000 - val_loss: 0.3811 - val_accuracy: 0.8936\n",
      "Epoch 732/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 3.5881e-04 - accuracy: 1.0000 - val_loss: 0.3813 - val_accuracy: 0.8936\n",
      "Epoch 733/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 3.5734e-04 - accuracy: 1.0000 - val_loss: 0.3815 - val_accuracy: 0.8936\n",
      "Epoch 734/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 3.6370e-04 - accuracy: 1.0000 - val_loss: 0.3817 - val_accuracy: 0.8936\n",
      "Epoch 735/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 3.5465e-04 - accuracy: 1.0000 - val_loss: 0.3818 - val_accuracy: 0.8936\n",
      "Epoch 736/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 3.5712e-04 - accuracy: 1.0000 - val_loss: 0.3820 - val_accuracy: 0.8936\n",
      "Epoch 737/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 3.5365e-04 - accuracy: 1.0000 - val_loss: 0.3821 - val_accuracy: 0.8936\n",
      "Epoch 738/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 3.6811e-04 - accuracy: 1.0000 - val_loss: 0.3820 - val_accuracy: 0.8936\n",
      "Epoch 739/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 3.5491e-04 - accuracy: 1.0000 - val_loss: 0.3823 - val_accuracy: 0.8936\n",
      "Epoch 740/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 3.5555e-04 - accuracy: 1.0000 - val_loss: 0.3826 - val_accuracy: 0.8936\n",
      "Epoch 741/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 3.4939e-04 - accuracy: 1.0000 - val_loss: 0.3834 - val_accuracy: 0.8936\n",
      "Epoch 742/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 3.4628e-04 - accuracy: 1.0000 - val_loss: 0.3841 - val_accuracy: 0.8936\n",
      "Epoch 743/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 3.4688e-04 - accuracy: 1.0000 - val_loss: 0.3846 - val_accuracy: 0.8936\n",
      "Epoch 744/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 3.4810e-04 - accuracy: 1.0000 - val_loss: 0.3850 - val_accuracy: 0.8936\n",
      "Epoch 745/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 3.5530e-04 - accuracy: 1.0000 - val_loss: 0.3854 - val_accuracy: 0.8936\n",
      "Epoch 746/1000\n",
      "53/53 [==============================] - 0s 471us/step - loss: 3.4584e-04 - accuracy: 1.0000 - val_loss: 0.3853 - val_accuracy: 0.8936\n",
      "Epoch 747/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 3.3997e-04 - accuracy: 1.0000 - val_loss: 0.3850 - val_accuracy: 0.8936\n",
      "Epoch 748/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 3.5698e-04 - accuracy: 1.0000 - val_loss: 0.3849 - val_accuracy: 0.8936\n",
      "Epoch 749/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 3.4312e-04 - accuracy: 1.0000 - val_loss: 0.3853 - val_accuracy: 0.8936\n",
      "Epoch 750/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 3.4066e-04 - accuracy: 1.0000 - val_loss: 0.3859 - val_accuracy: 0.8936\n",
      "Epoch 751/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 3.4868e-04 - accuracy: 1.0000 - val_loss: 0.3865 - val_accuracy: 0.8936\n",
      "Epoch 752/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 3.4174e-04 - accuracy: 1.0000 - val_loss: 0.3870 - val_accuracy: 0.8936\n",
      "Epoch 753/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 3.4142e-04 - accuracy: 1.0000 - val_loss: 0.3871 - val_accuracy: 0.8936\n",
      "Epoch 754/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 3.4019e-04 - accuracy: 1.0000 - val_loss: 0.3877 - val_accuracy: 0.8936\n",
      "Epoch 755/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 3.3052e-04 - accuracy: 1.0000 - val_loss: 0.3881 - val_accuracy: 0.8936\n",
      "Epoch 756/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 3.2945e-04 - accuracy: 1.0000 - val_loss: 0.3886 - val_accuracy: 0.8936\n",
      "Epoch 757/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 3.2825e-04 - accuracy: 1.0000 - val_loss: 0.3890 - val_accuracy: 0.8936\n",
      "Epoch 758/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 3.3334e-04 - accuracy: 1.0000 - val_loss: 0.3894 - val_accuracy: 0.8936\n",
      "Epoch 759/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 3.2732e-04 - accuracy: 1.0000 - val_loss: 0.3898 - val_accuracy: 0.8936\n",
      "Epoch 760/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 3.2498e-04 - accuracy: 1.0000 - val_loss: 0.3904 - val_accuracy: 0.8936\n",
      "Epoch 761/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 3.2541e-04 - accuracy: 1.0000 - val_loss: 0.3909 - val_accuracy: 0.8936\n",
      "Epoch 762/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 3.3701e-04 - accuracy: 1.0000 - val_loss: 0.3913 - val_accuracy: 0.8936\n",
      "Epoch 763/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 3.2763e-04 - accuracy: 1.0000 - val_loss: 0.3912 - val_accuracy: 0.8936\n",
      "Epoch 764/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 3.2260e-04 - accuracy: 1.0000 - val_loss: 0.3913 - val_accuracy: 0.8936\n",
      "Epoch 765/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 3.1575e-04 - accuracy: 1.0000 - val_loss: 0.3911 - val_accuracy: 0.8936\n",
      "Epoch 766/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 3.1820e-04 - accuracy: 1.0000 - val_loss: 0.3909 - val_accuracy: 0.8936\n",
      "Epoch 767/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 3.2624e-04 - accuracy: 1.0000 - val_loss: 0.3909 - val_accuracy: 0.8936\n",
      "Epoch 768/1000\n",
      "53/53 [==============================] - 0s 471us/step - loss: 3.3093e-04 - accuracy: 1.0000 - val_loss: 0.3913 - val_accuracy: 0.8936\n",
      "Epoch 769/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 3.2433e-04 - accuracy: 1.0000 - val_loss: 0.3915 - val_accuracy: 0.8936\n",
      "Epoch 770/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 3.2202e-04 - accuracy: 1.0000 - val_loss: 0.3921 - val_accuracy: 0.8936\n",
      "Epoch 771/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 3.2584e-04 - accuracy: 1.0000 - val_loss: 0.3928 - val_accuracy: 0.8936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 772/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 3.1502e-04 - accuracy: 1.0000 - val_loss: 0.3933 - val_accuracy: 0.8936\n",
      "Epoch 773/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 3.0974e-04 - accuracy: 1.0000 - val_loss: 0.3939 - val_accuracy: 0.8936\n",
      "Epoch 774/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 3.2277e-04 - accuracy: 1.0000 - val_loss: 0.3949 - val_accuracy: 0.8936\n",
      "Epoch 775/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 3.1159e-04 - accuracy: 1.0000 - val_loss: 0.3953 - val_accuracy: 0.8936\n",
      "Epoch 776/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 3.1528e-04 - accuracy: 1.0000 - val_loss: 0.3955 - val_accuracy: 0.8936\n",
      "Epoch 777/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 3.1487e-04 - accuracy: 1.0000 - val_loss: 0.3959 - val_accuracy: 0.8936\n",
      "Epoch 778/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 3.0641e-04 - accuracy: 1.0000 - val_loss: 0.3958 - val_accuracy: 0.8936\n",
      "Epoch 779/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 3.0467e-04 - accuracy: 1.0000 - val_loss: 0.3956 - val_accuracy: 0.8936\n",
      "Epoch 780/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 3.0329e-04 - accuracy: 1.0000 - val_loss: 0.3956 - val_accuracy: 0.8936\n",
      "Epoch 781/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 3.0134e-04 - accuracy: 1.0000 - val_loss: 0.3956 - val_accuracy: 0.8936\n",
      "Epoch 782/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 3.0564e-04 - accuracy: 1.0000 - val_loss: 0.3954 - val_accuracy: 0.8936\n",
      "Epoch 783/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 3.1564e-04 - accuracy: 1.0000 - val_loss: 0.3956 - val_accuracy: 0.8936\n",
      "Epoch 784/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 3.0655e-04 - accuracy: 1.0000 - val_loss: 0.3963 - val_accuracy: 0.8936\n",
      "Epoch 785/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 2.9905e-04 - accuracy: 1.0000 - val_loss: 0.3969 - val_accuracy: 0.8936\n",
      "Epoch 786/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 2.9744e-04 - accuracy: 1.0000 - val_loss: 0.3979 - val_accuracy: 0.8936\n",
      "Epoch 787/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.9675e-04 - accuracy: 1.0000 - val_loss: 0.3987 - val_accuracy: 0.8936\n",
      "Epoch 788/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.9957e-04 - accuracy: 1.0000 - val_loss: 0.3993 - val_accuracy: 0.8936\n",
      "Epoch 789/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 3.0938e-04 - accuracy: 1.0000 - val_loss: 0.3996 - val_accuracy: 0.8936\n",
      "Epoch 790/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 3.0120e-04 - accuracy: 1.0000 - val_loss: 0.3995 - val_accuracy: 0.8936\n",
      "Epoch 791/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 2.9577e-04 - accuracy: 1.0000 - val_loss: 0.3990 - val_accuracy: 0.8936\n",
      "Epoch 792/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.9104e-04 - accuracy: 1.0000 - val_loss: 0.3987 - val_accuracy: 0.8936\n",
      "Epoch 793/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 2.9175e-04 - accuracy: 1.0000 - val_loss: 0.3987 - val_accuracy: 0.8936\n",
      "Epoch 794/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 2.9381e-04 - accuracy: 1.0000 - val_loss: 0.3988 - val_accuracy: 0.8936\n",
      "Epoch 795/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 2.9462e-04 - accuracy: 1.0000 - val_loss: 0.3992 - val_accuracy: 0.8936\n",
      "Epoch 796/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.9863e-04 - accuracy: 1.0000 - val_loss: 0.3998 - val_accuracy: 0.8936\n",
      "Epoch 797/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 2.9462e-04 - accuracy: 1.0000 - val_loss: 0.4001 - val_accuracy: 0.8936\n",
      "Epoch 798/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 2.9769e-04 - accuracy: 1.0000 - val_loss: 0.4010 - val_accuracy: 0.8936\n",
      "Epoch 799/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.8481e-04 - accuracy: 1.0000 - val_loss: 0.4016 - val_accuracy: 0.8936\n",
      "Epoch 800/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.8357e-04 - accuracy: 1.0000 - val_loss: 0.4022 - val_accuracy: 0.8936\n",
      "Epoch 801/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.8281e-04 - accuracy: 1.0000 - val_loss: 0.4026 - val_accuracy: 0.8936\n",
      "Epoch 802/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 2.8219e-04 - accuracy: 1.0000 - val_loss: 0.4029 - val_accuracy: 0.8936\n",
      "Epoch 803/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.8123e-04 - accuracy: 1.0000 - val_loss: 0.4032 - val_accuracy: 0.8936\n",
      "Epoch 804/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.8068e-04 - accuracy: 1.0000 - val_loss: 0.4033 - val_accuracy: 0.8936\n",
      "Epoch 805/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.7915e-04 - accuracy: 1.0000 - val_loss: 0.4035 - val_accuracy: 0.8936\n",
      "Epoch 806/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 2.7816e-04 - accuracy: 1.0000 - val_loss: 0.4037 - val_accuracy: 0.8936\n",
      "Epoch 807/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 2.7760e-04 - accuracy: 1.0000 - val_loss: 0.4040 - val_accuracy: 0.8936\n",
      "Epoch 808/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.8030e-04 - accuracy: 1.0000 - val_loss: 0.4044 - val_accuracy: 0.8936\n",
      "Epoch 809/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.8403e-04 - accuracy: 1.0000 - val_loss: 0.4044 - val_accuracy: 0.8936\n",
      "Epoch 810/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 2.7577e-04 - accuracy: 1.0000 - val_loss: 0.4049 - val_accuracy: 0.8936\n",
      "Epoch 811/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 2.7457e-04 - accuracy: 1.0000 - val_loss: 0.4052 - val_accuracy: 0.8936\n",
      "Epoch 812/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.7289e-04 - accuracy: 1.0000 - val_loss: 0.4056 - val_accuracy: 0.8936\n",
      "Epoch 813/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.7237e-04 - accuracy: 1.0000 - val_loss: 0.4060 - val_accuracy: 0.8936\n",
      "Epoch 814/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 2.7152e-04 - accuracy: 1.0000 - val_loss: 0.4064 - val_accuracy: 0.8936\n",
      "Epoch 815/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.7080e-04 - accuracy: 1.0000 - val_loss: 0.4067 - val_accuracy: 0.8936\n",
      "Epoch 816/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 2.7414e-04 - accuracy: 1.0000 - val_loss: 0.4069 - val_accuracy: 0.8936\n",
      "Epoch 817/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 2.7650e-04 - accuracy: 1.0000 - val_loss: 0.4074 - val_accuracy: 0.8936\n",
      "Epoch 818/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.6896e-04 - accuracy: 1.0000 - val_loss: 0.4075 - val_accuracy: 0.8936\n",
      "Epoch 819/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.7351e-04 - accuracy: 1.0000 - val_loss: 0.4076 - val_accuracy: 0.8936\n",
      "Epoch 820/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.7180e-04 - accuracy: 1.0000 - val_loss: 0.4080 - val_accuracy: 0.8936\n",
      "Epoch 821/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 2.7174e-04 - accuracy: 1.0000 - val_loss: 0.4079 - val_accuracy: 0.8936\n",
      "Epoch 822/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.6501e-04 - accuracy: 1.0000 - val_loss: 0.4083 - val_accuracy: 0.8936\n",
      "Epoch 823/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.6415e-04 - accuracy: 1.0000 - val_loss: 0.4086 - val_accuracy: 0.8936\n",
      "Epoch 824/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.6673e-04 - accuracy: 1.0000 - val_loss: 0.4088 - val_accuracy: 0.8936\n",
      "Epoch 825/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.7005e-04 - accuracy: 1.0000 - val_loss: 0.4094 - val_accuracy: 0.8936\n",
      "Epoch 826/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.6730e-04 - accuracy: 1.0000 - val_loss: 0.4096 - val_accuracy: 0.8936\n",
      "Epoch 827/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.6102e-04 - accuracy: 1.0000 - val_loss: 0.4100 - val_accuracy: 0.8936\n",
      "Epoch 828/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 2.6063e-04 - accuracy: 1.0000 - val_loss: 0.4102 - val_accuracy: 0.8936\n",
      "Epoch 829/1000\n",
      "53/53 [==============================] - 0s 564us/step - loss: 2.5978e-04 - accuracy: 1.0000 - val_loss: 0.4104 - val_accuracy: 0.8936\n",
      "Epoch 830/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.6317e-04 - accuracy: 1.0000 - val_loss: 0.4106 - val_accuracy: 0.8936\n",
      "Epoch 831/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.5781e-04 - accuracy: 1.0000 - val_loss: 0.4110 - val_accuracy: 0.8936\n",
      "Epoch 832/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 2.6015e-04 - accuracy: 1.0000 - val_loss: 0.4113 - val_accuracy: 0.8936\n",
      "Epoch 833/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.5643e-04 - accuracy: 1.0000 - val_loss: 0.4117 - val_accuracy: 0.8936\n",
      "Epoch 834/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 2.5660e-04 - accuracy: 1.0000 - val_loss: 0.4120 - val_accuracy: 0.8936\n",
      "Epoch 835/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 2.5996e-04 - accuracy: 1.0000 - val_loss: 0.4122 - val_accuracy: 0.8936\n",
      "Epoch 836/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.5493e-04 - accuracy: 1.0000 - val_loss: 0.4126 - val_accuracy: 0.8936\n",
      "Epoch 837/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.5826e-04 - accuracy: 1.0000 - val_loss: 0.4128 - val_accuracy: 0.8936\n",
      "Epoch 838/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.5363e-04 - accuracy: 1.0000 - val_loss: 0.4128 - val_accuracy: 0.8936\n",
      "Epoch 839/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 2.5172e-04 - accuracy: 1.0000 - val_loss: 0.4128 - val_accuracy: 0.8936\n",
      "Epoch 840/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 2.6087e-04 - accuracy: 1.0000 - val_loss: 0.4126 - val_accuracy: 0.8936\n",
      "Epoch 841/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 2.5170e-04 - accuracy: 1.0000 - val_loss: 0.4128 - val_accuracy: 0.8936\n",
      "Epoch 842/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 2.5492e-04 - accuracy: 1.0000 - val_loss: 0.4129 - val_accuracy: 0.8936\n",
      "Epoch 843/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.4892e-04 - accuracy: 1.0000 - val_loss: 0.4135 - val_accuracy: 0.8936\n",
      "Epoch 844/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.4791e-04 - accuracy: 1.0000 - val_loss: 0.4142 - val_accuracy: 0.8936\n",
      "Epoch 845/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.4749e-04 - accuracy: 1.0000 - val_loss: 0.4148 - val_accuracy: 0.8936\n",
      "Epoch 846/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 2.5598e-04 - accuracy: 1.0000 - val_loss: 0.4155 - val_accuracy: 0.8936\n",
      "Epoch 847/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 2.4826e-04 - accuracy: 1.0000 - val_loss: 0.4157 - val_accuracy: 0.8936\n",
      "Epoch 848/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.4687e-04 - accuracy: 1.0000 - val_loss: 0.4158 - val_accuracy: 0.8936\n",
      "Epoch 849/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.5023e-04 - accuracy: 1.0000 - val_loss: 0.4159 - val_accuracy: 0.8936\n",
      "Epoch 850/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 2.4336e-04 - accuracy: 1.0000 - val_loss: 0.4161 - val_accuracy: 0.8936\n",
      "Epoch 851/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 2.4588e-04 - accuracy: 1.0000 - val_loss: 0.4163 - val_accuracy: 0.8936\n",
      "Epoch 852/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.4177e-04 - accuracy: 1.0000 - val_loss: 0.4162 - val_accuracy: 0.8936\n",
      "Epoch 853/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.4076e-04 - accuracy: 1.0000 - val_loss: 0.4161 - val_accuracy: 0.8936\n",
      "Epoch 854/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.4063e-04 - accuracy: 1.0000 - val_loss: 0.4162 - val_accuracy: 0.8936\n",
      "Epoch 855/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.4299e-04 - accuracy: 1.0000 - val_loss: 0.4165 - val_accuracy: 0.8936\n",
      "Epoch 856/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.4114e-04 - accuracy: 1.0000 - val_loss: 0.4166 - val_accuracy: 0.8936\n",
      "Epoch 857/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.3986e-04 - accuracy: 1.0000 - val_loss: 0.4167 - val_accuracy: 0.8936\n",
      "Epoch 858/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 2.4826e-04 - accuracy: 1.0000 - val_loss: 0.4168 - val_accuracy: 0.8936\n",
      "Epoch 859/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.4109e-04 - accuracy: 1.0000 - val_loss: 0.4173 - val_accuracy: 0.8936\n",
      "Epoch 860/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 2.4008e-04 - accuracy: 1.0000 - val_loss: 0.4177 - val_accuracy: 0.8936\n",
      "Epoch 861/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.4508e-04 - accuracy: 1.0000 - val_loss: 0.4186 - val_accuracy: 0.8936\n",
      "Epoch 862/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.3446e-04 - accuracy: 1.0000 - val_loss: 0.4189 - val_accuracy: 0.8936\n",
      "Epoch 863/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.3572e-04 - accuracy: 1.0000 - val_loss: 0.4192 - val_accuracy: 0.8936\n",
      "Epoch 864/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.3418e-04 - accuracy: 1.0000 - val_loss: 0.4197 - val_accuracy: 0.8936\n",
      "Epoch 865/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 2.3449e-04 - accuracy: 1.0000 - val_loss: 0.4200 - val_accuracy: 0.8936\n",
      "Epoch 866/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.3698e-04 - accuracy: 1.0000 - val_loss: 0.4202 - val_accuracy: 0.8936\n",
      "Epoch 867/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.3945e-04 - accuracy: 1.0000 - val_loss: 0.4201 - val_accuracy: 0.8936\n",
      "Epoch 868/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.3204e-04 - accuracy: 1.0000 - val_loss: 0.4203 - val_accuracy: 0.8936\n",
      "Epoch 869/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 2.2948e-04 - accuracy: 1.0000 - val_loss: 0.4202 - val_accuracy: 0.8936\n",
      "Epoch 870/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.2923e-04 - accuracy: 1.0000 - val_loss: 0.4202 - val_accuracy: 0.8936\n",
      "Epoch 871/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.2945e-04 - accuracy: 1.0000 - val_loss: 0.4203 - val_accuracy: 0.8936\n",
      "Epoch 872/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.2934e-04 - accuracy: 1.0000 - val_loss: 0.4204 - val_accuracy: 0.8936\n",
      "Epoch 873/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.2852e-04 - accuracy: 1.0000 - val_loss: 0.4208 - val_accuracy: 0.8936\n",
      "Epoch 874/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 2.2686e-04 - accuracy: 1.0000 - val_loss: 0.4210 - val_accuracy: 0.8936\n",
      "Epoch 875/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.2610e-04 - accuracy: 1.0000 - val_loss: 0.4215 - val_accuracy: 0.8936\n",
      "Epoch 876/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 2.2634e-04 - accuracy: 1.0000 - val_loss: 0.4218 - val_accuracy: 0.8936\n",
      "Epoch 877/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 2.2373e-04 - accuracy: 1.0000 - val_loss: 0.4223 - val_accuracy: 0.8936\n",
      "Epoch 878/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 2.3319e-04 - accuracy: 1.0000 - val_loss: 0.4230 - val_accuracy: 0.8936\n",
      "Epoch 879/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 2.3014e-04 - accuracy: 1.0000 - val_loss: 0.4233 - val_accuracy: 0.8936\n",
      "Epoch 880/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 2.2535e-04 - accuracy: 1.0000 - val_loss: 0.4232 - val_accuracy: 0.8936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 881/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 2.2898e-04 - accuracy: 1.0000 - val_loss: 0.4229 - val_accuracy: 0.8936\n",
      "Epoch 882/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.2067e-04 - accuracy: 1.0000 - val_loss: 0.4229 - val_accuracy: 0.8936\n",
      "Epoch 883/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.2261e-04 - accuracy: 1.0000 - val_loss: 0.4230 - val_accuracy: 0.8936\n",
      "Epoch 884/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 2.1965e-04 - accuracy: 1.0000 - val_loss: 0.4229 - val_accuracy: 0.8936\n",
      "Epoch 885/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 2.1936e-04 - accuracy: 1.0000 - val_loss: 0.4229 - val_accuracy: 0.8936\n",
      "Epoch 886/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 2.1920e-04 - accuracy: 1.0000 - val_loss: 0.4231 - val_accuracy: 0.8936\n",
      "Epoch 887/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.1860e-04 - accuracy: 1.0000 - val_loss: 0.4235 - val_accuracy: 0.8936\n",
      "Epoch 888/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.1774e-04 - accuracy: 1.0000 - val_loss: 0.4238 - val_accuracy: 0.8936\n",
      "Epoch 889/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.2094e-04 - accuracy: 1.0000 - val_loss: 0.4242 - val_accuracy: 0.8936\n",
      "Epoch 890/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 2.1585e-04 - accuracy: 1.0000 - val_loss: 0.4243 - val_accuracy: 0.8936\n",
      "Epoch 891/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 2.1533e-04 - accuracy: 1.0000 - val_loss: 0.4245 - val_accuracy: 0.8936\n",
      "Epoch 892/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 2.1772e-04 - accuracy: 1.0000 - val_loss: 0.4248 - val_accuracy: 0.8936\n",
      "Epoch 893/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.1544e-04 - accuracy: 1.0000 - val_loss: 0.4249 - val_accuracy: 0.8936\n",
      "Epoch 894/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.2056e-04 - accuracy: 1.0000 - val_loss: 0.4248 - val_accuracy: 0.8936\n",
      "Epoch 895/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 2.1434e-04 - accuracy: 1.0000 - val_loss: 0.4251 - val_accuracy: 0.8936\n",
      "Epoch 896/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 2.1322e-04 - accuracy: 1.0000 - val_loss: 0.4255 - val_accuracy: 0.8936\n",
      "Epoch 897/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.1645e-04 - accuracy: 1.0000 - val_loss: 0.4259 - val_accuracy: 0.8936\n",
      "Epoch 898/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 2.1094e-04 - accuracy: 1.0000 - val_loss: 0.4261 - val_accuracy: 0.8936\n",
      "Epoch 899/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.1396e-04 - accuracy: 1.0000 - val_loss: 0.4263 - val_accuracy: 0.8936\n",
      "Epoch 900/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.1518e-04 - accuracy: 1.0000 - val_loss: 0.4269 - val_accuracy: 0.8936\n",
      "Epoch 901/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 2.0933e-04 - accuracy: 1.0000 - val_loss: 0.4271 - val_accuracy: 0.8936\n",
      "Epoch 902/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 2.1179e-04 - accuracy: 1.0000 - val_loss: 0.4272 - val_accuracy: 0.8936\n",
      "Epoch 903/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.0791e-04 - accuracy: 1.0000 - val_loss: 0.4277 - val_accuracy: 0.8936\n",
      "Epoch 904/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.0946e-04 - accuracy: 1.0000 - val_loss: 0.4280 - val_accuracy: 0.8936\n",
      "Epoch 905/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 2.0715e-04 - accuracy: 1.0000 - val_loss: 0.4286 - val_accuracy: 0.8936\n",
      "Epoch 906/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.0708e-04 - accuracy: 1.0000 - val_loss: 0.4290 - val_accuracy: 0.8936\n",
      "Epoch 907/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 2.0665e-04 - accuracy: 1.0000 - val_loss: 0.4293 - val_accuracy: 0.8936\n",
      "Epoch 908/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 2.0617e-04 - accuracy: 1.0000 - val_loss: 0.4295 - val_accuracy: 0.8936\n",
      "Epoch 909/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 2.0686e-04 - accuracy: 1.0000 - val_loss: 0.4296 - val_accuracy: 0.8936\n",
      "Epoch 910/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.1041e-04 - accuracy: 1.0000 - val_loss: 0.4294 - val_accuracy: 0.8936\n",
      "Epoch 911/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.0709e-04 - accuracy: 1.0000 - val_loss: 0.4295 - val_accuracy: 0.8936\n",
      "Epoch 912/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.0692e-04 - accuracy: 1.0000 - val_loss: 0.4301 - val_accuracy: 0.8936\n",
      "Epoch 913/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 2.0520e-04 - accuracy: 1.0000 - val_loss: 0.4302 - val_accuracy: 0.8936\n",
      "Epoch 914/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.0152e-04 - accuracy: 1.0000 - val_loss: 0.4308 - val_accuracy: 0.8936\n",
      "Epoch 915/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.0518e-04 - accuracy: 1.0000 - val_loss: 0.4313 - val_accuracy: 0.8936\n",
      "Epoch 916/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 2.0425e-04 - accuracy: 1.0000 - val_loss: 0.4314 - val_accuracy: 0.8936\n",
      "Epoch 917/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.0185e-04 - accuracy: 1.0000 - val_loss: 0.4315 - val_accuracy: 0.8936\n",
      "Epoch 918/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 1.9917e-04 - accuracy: 1.0000 - val_loss: 0.4319 - val_accuracy: 0.8936\n",
      "Epoch 919/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 1.9900e-04 - accuracy: 1.0000 - val_loss: 0.4323 - val_accuracy: 0.8936\n",
      "Epoch 920/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 2.0244e-04 - accuracy: 1.0000 - val_loss: 0.4326 - val_accuracy: 0.8936\n",
      "Epoch 921/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 1.9849e-04 - accuracy: 1.0000 - val_loss: 0.4325 - val_accuracy: 0.8936\n",
      "Epoch 922/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 1.9717e-04 - accuracy: 1.0000 - val_loss: 0.4325 - val_accuracy: 0.8936\n",
      "Epoch 923/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 1.9722e-04 - accuracy: 1.0000 - val_loss: 0.4325 - val_accuracy: 0.8936\n",
      "Epoch 924/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 1.9563e-04 - accuracy: 1.0000 - val_loss: 0.4323 - val_accuracy: 0.8936\n",
      "Epoch 925/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 1.9585e-04 - accuracy: 1.0000 - val_loss: 0.4320 - val_accuracy: 0.8936\n",
      "Epoch 926/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.0351e-04 - accuracy: 1.0000 - val_loss: 0.4318 - val_accuracy: 0.8936\n",
      "Epoch 927/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 1.9824e-04 - accuracy: 1.0000 - val_loss: 0.4323 - val_accuracy: 0.8936\n",
      "Epoch 928/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.0044e-04 - accuracy: 1.0000 - val_loss: 0.4329 - val_accuracy: 0.8936\n",
      "Epoch 929/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 1.9591e-04 - accuracy: 1.0000 - val_loss: 0.4332 - val_accuracy: 0.8936\n",
      "Epoch 930/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 1.9309e-04 - accuracy: 1.0000 - val_loss: 0.4338 - val_accuracy: 0.8936\n",
      "Epoch 931/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 1.9210e-04 - accuracy: 1.0000 - val_loss: 0.4343 - val_accuracy: 0.8936\n",
      "Epoch 932/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 1.9213e-04 - accuracy: 1.0000 - val_loss: 0.4346 - val_accuracy: 0.8936\n",
      "Epoch 933/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 1.9218e-04 - accuracy: 1.0000 - val_loss: 0.4349 - val_accuracy: 0.8936\n",
      "Epoch 934/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 1.9414e-04 - accuracy: 1.0000 - val_loss: 0.4351 - val_accuracy: 0.8936\n",
      "Epoch 935/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 1.9606e-04 - accuracy: 1.0000 - val_loss: 0.4349 - val_accuracy: 0.8936\n",
      "Epoch 936/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 1.8955e-04 - accuracy: 1.0000 - val_loss: 0.4350 - val_accuracy: 0.8936\n",
      "Epoch 937/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 1.8879e-04 - accuracy: 1.0000 - val_loss: 0.4352 - val_accuracy: 0.8936\n",
      "Epoch 938/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 1.8849e-04 - accuracy: 1.0000 - val_loss: 0.4353 - val_accuracy: 0.8936\n",
      "Epoch 939/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 1.8799e-04 - accuracy: 1.0000 - val_loss: 0.4354 - val_accuracy: 0.8936\n",
      "Epoch 940/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 1.9030e-04 - accuracy: 1.0000 - val_loss: 0.4355 - val_accuracy: 0.8936\n",
      "Epoch 941/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 1.8764e-04 - accuracy: 1.0000 - val_loss: 0.4358 - val_accuracy: 0.8936\n",
      "Epoch 942/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 1.8571e-04 - accuracy: 1.0000 - val_loss: 0.4365 - val_accuracy: 0.8936\n",
      "Epoch 943/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 1.8476e-04 - accuracy: 1.0000 - val_loss: 0.4372 - val_accuracy: 0.8936\n",
      "Epoch 944/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 1.8681e-04 - accuracy: 1.0000 - val_loss: 0.4380 - val_accuracy: 0.8936\n",
      "Epoch 945/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 1.8910e-04 - accuracy: 1.0000 - val_loss: 0.4383 - val_accuracy: 0.8936\n",
      "Epoch 946/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 1.9555e-04 - accuracy: 1.0000 - val_loss: 0.4387 - val_accuracy: 0.8936\n",
      "Epoch 947/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 1.9109e-04 - accuracy: 1.0000 - val_loss: 0.4386 - val_accuracy: 0.8936\n",
      "Epoch 948/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 1.9167e-04 - accuracy: 1.0000 - val_loss: 0.4383 - val_accuracy: 0.8936\n",
      "Epoch 949/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 1.8473e-04 - accuracy: 1.0000 - val_loss: 0.4383 - val_accuracy: 0.8936\n",
      "Epoch 950/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 1.8164e-04 - accuracy: 1.0000 - val_loss: 0.4380 - val_accuracy: 0.8936\n",
      "Epoch 951/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 1.7963e-04 - accuracy: 1.0000 - val_loss: 0.4377 - val_accuracy: 0.8936\n",
      "Epoch 952/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 1.8019e-04 - accuracy: 1.0000 - val_loss: 0.4373 - val_accuracy: 0.8936\n",
      "Epoch 953/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 1.9359e-04 - accuracy: 1.0000 - val_loss: 0.4370 - val_accuracy: 0.9149\n",
      "Epoch 954/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 1.8835e-04 - accuracy: 1.0000 - val_loss: 0.4375 - val_accuracy: 0.8936\n",
      "Epoch 955/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 1.8648e-04 - accuracy: 1.0000 - val_loss: 0.4381 - val_accuracy: 0.8936\n",
      "Epoch 956/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 1.8340e-04 - accuracy: 1.0000 - val_loss: 0.4386 - val_accuracy: 0.8936\n",
      "Epoch 957/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 1.7812e-04 - accuracy: 1.0000 - val_loss: 0.4395 - val_accuracy: 0.8936\n",
      "Epoch 958/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 1.7856e-04 - accuracy: 1.0000 - val_loss: 0.4406 - val_accuracy: 0.8936\n",
      "Epoch 959/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 1.8034e-04 - accuracy: 1.0000 - val_loss: 0.4414 - val_accuracy: 0.8936\n",
      "Epoch 960/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 1.8684e-04 - accuracy: 1.0000 - val_loss: 0.4419 - val_accuracy: 0.8936\n",
      "Epoch 961/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 1.8265e-04 - accuracy: 1.0000 - val_loss: 0.4419 - val_accuracy: 0.8936\n",
      "Epoch 962/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 1.7910e-04 - accuracy: 1.0000 - val_loss: 0.4418 - val_accuracy: 0.8936\n",
      "Epoch 963/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 1.8246e-04 - accuracy: 1.0000 - val_loss: 0.4415 - val_accuracy: 0.8936\n",
      "Epoch 964/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 1.7953e-04 - accuracy: 1.0000 - val_loss: 0.4414 - val_accuracy: 0.8936\n",
      "Epoch 965/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 1.7718e-04 - accuracy: 1.0000 - val_loss: 0.4416 - val_accuracy: 0.8936\n",
      "Epoch 966/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 1.7858e-04 - accuracy: 1.0000 - val_loss: 0.4421 - val_accuracy: 0.8936\n",
      "Epoch 967/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 1.7421e-04 - accuracy: 1.0000 - val_loss: 0.4423 - val_accuracy: 0.8936\n",
      "Epoch 968/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 1.7562e-04 - accuracy: 1.0000 - val_loss: 0.4425 - val_accuracy: 0.8936\n",
      "Epoch 969/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 1.7289e-04 - accuracy: 1.0000 - val_loss: 0.4424 - val_accuracy: 0.8936\n",
      "Epoch 970/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 1.7335e-04 - accuracy: 1.0000 - val_loss: 0.4425 - val_accuracy: 0.8936\n",
      "Epoch 971/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 1.7725e-04 - accuracy: 1.0000 - val_loss: 0.4423 - val_accuracy: 0.8936\n",
      "Epoch 972/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 1.7531e-04 - accuracy: 1.0000 - val_loss: 0.4425 - val_accuracy: 0.8936\n",
      "Epoch 973/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 1.7221e-04 - accuracy: 1.0000 - val_loss: 0.4431 - val_accuracy: 0.8936\n",
      "Epoch 974/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 1.7083e-04 - accuracy: 1.0000 - val_loss: 0.4436 - val_accuracy: 0.8936\n",
      "Epoch 975/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 1.7065e-04 - accuracy: 1.0000 - val_loss: 0.4439 - val_accuracy: 0.8936\n",
      "Epoch 976/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 1.7517e-04 - accuracy: 1.0000 - val_loss: 0.4446 - val_accuracy: 0.8936\n",
      "Epoch 977/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 1.7064e-04 - accuracy: 1.0000 - val_loss: 0.4448 - val_accuracy: 0.8936\n",
      "Epoch 978/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 1.7234e-04 - accuracy: 1.0000 - val_loss: 0.4449 - val_accuracy: 0.8936\n",
      "Epoch 979/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 1.7092e-04 - accuracy: 1.0000 - val_loss: 0.4451 - val_accuracy: 0.8936\n",
      "Epoch 980/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 1.6862e-04 - accuracy: 1.0000 - val_loss: 0.4455 - val_accuracy: 0.8936\n",
      "Epoch 981/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 1.6854e-04 - accuracy: 1.0000 - val_loss: 0.4458 - val_accuracy: 0.8936\n",
      "Epoch 982/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 1.6819e-04 - accuracy: 1.0000 - val_loss: 0.4460 - val_accuracy: 0.8936\n",
      "Epoch 983/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 1.7010e-04 - accuracy: 1.0000 - val_loss: 0.4461 - val_accuracy: 0.8936\n",
      "Epoch 984/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 1.6832e-04 - accuracy: 1.0000 - val_loss: 0.4462 - val_accuracy: 0.8936\n",
      "Epoch 985/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 1.6627e-04 - accuracy: 1.0000 - val_loss: 0.4465 - val_accuracy: 0.8936\n",
      "Epoch 986/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 1.6611e-04 - accuracy: 1.0000 - val_loss: 0.4466 - val_accuracy: 0.8936\n",
      "Epoch 987/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 1.6559e-04 - accuracy: 1.0000 - val_loss: 0.4468 - val_accuracy: 0.8936\n",
      "Epoch 988/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 1.6805e-04 - accuracy: 1.0000 - val_loss: 0.4468 - val_accuracy: 0.8936\n",
      "Epoch 989/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 1.6688e-04 - accuracy: 1.0000 - val_loss: 0.4472 - val_accuracy: 0.8936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 990/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 1.6733e-04 - accuracy: 1.0000 - val_loss: 0.4473 - val_accuracy: 0.8936\n",
      "Epoch 991/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 1.6307e-04 - accuracy: 1.0000 - val_loss: 0.4476 - val_accuracy: 0.8936\n",
      "Epoch 992/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 1.6262e-04 - accuracy: 1.0000 - val_loss: 0.4478 - val_accuracy: 0.8936\n",
      "Epoch 993/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 1.6444e-04 - accuracy: 1.0000 - val_loss: 0.4481 - val_accuracy: 0.8936\n",
      "Epoch 994/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 1.6258e-04 - accuracy: 1.0000 - val_loss: 0.4481 - val_accuracy: 0.8936\n",
      "Epoch 995/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 1.6106e-04 - accuracy: 1.0000 - val_loss: 0.4481 - val_accuracy: 0.8936\n",
      "Epoch 996/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 1.6131e-04 - accuracy: 1.0000 - val_loss: 0.4479 - val_accuracy: 0.8936\n",
      "Epoch 997/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 1.6270e-04 - accuracy: 1.0000 - val_loss: 0.4478 - val_accuracy: 0.8936\n",
      "Epoch 998/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 1.6545e-04 - accuracy: 1.0000 - val_loss: 0.4480 - val_accuracy: 0.8936\n",
      "Epoch 999/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 1.6226e-04 - accuracy: 1.0000 - val_loss: 0.4487 - val_accuracy: 0.8936\n",
      "Epoch 1000/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 1.6423e-04 - accuracy: 1.0000 - val_loss: 0.4494 - val_accuracy: 0.8936\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2c79df4e898>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import History\n",
    "\n",
    "\n",
    "history_Adam = History()\n",
    "model = Sequential()\n",
    "model.add(Dense(1000,activation=\"relu\",input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(500,activation=\"sigmoid\"))\n",
    "model.add(Dense(200,activation=\"sigmoid\"))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "model.fit(X_train, y_train, validation_data= (X_test, y_test), epochs=1000, callbacks=[history_Adam])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_Adam.history['loss'], label = \"tarina\")\n",
    "plt.plot(history_Adam.history['val_loss'], label = \"test \")\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n",
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from help_plot import plot_decision_regions\n",
    "plot_decision_regions(X_test, y_test, model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_54 (Dense)             (None, 1000)              2000      \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 500)               500000    \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 500)               2000      \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 200)               100000    \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 609,001\n",
      "Trainable params: 605,601\n",
      "Non-trainable params: 3,400\n",
      "_________________________________________________________________\n",
      "Train on 53 samples, validate on 47 samples\n",
      "Epoch 1/1000\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.7322 - accuracy: 0.6038 - val_loss: 0.7922 - val_accuracy: 0.4468\n",
      "Epoch 2/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.6343 - accuracy: 0.6415 - val_loss: 0.7696 - val_accuracy: 0.4468\n",
      "Epoch 3/1000\n",
      "53/53 [==============================] - 0s 714us/step - loss: 0.5073 - accuracy: 0.8113 - val_loss: 0.7604 - val_accuracy: 0.4468\n",
      "Epoch 4/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.4333 - accuracy: 0.8113 - val_loss: 0.7491 - val_accuracy: 0.4468\n",
      "Epoch 5/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.4025 - accuracy: 0.7925 - val_loss: 0.7346 - val_accuracy: 0.4468\n",
      "Epoch 6/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3448 - accuracy: 0.8302 - val_loss: 0.7253 - val_accuracy: 0.4468\n",
      "Epoch 7/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3514 - accuracy: 0.8868 - val_loss: 0.7190 - val_accuracy: 0.4468\n",
      "Epoch 8/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.3036 - accuracy: 0.8491 - val_loss: 0.7126 - val_accuracy: 0.4468\n",
      "Epoch 9/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3530 - accuracy: 0.8302 - val_loss: 0.7083 - val_accuracy: 0.4468\n",
      "Epoch 10/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2658 - accuracy: 0.9057 - val_loss: 0.7025 - val_accuracy: 0.4468\n",
      "Epoch 11/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3142 - accuracy: 0.8679 - val_loss: 0.6991 - val_accuracy: 0.4468\n",
      "Epoch 12/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2382 - accuracy: 0.9057 - val_loss: 0.6969 - val_accuracy: 0.4468\n",
      "Epoch 13/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2714 - accuracy: 0.8868 - val_loss: 0.6952 - val_accuracy: 0.4468\n",
      "Epoch 14/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3691 - accuracy: 0.8491 - val_loss: 0.6953 - val_accuracy: 0.4468\n",
      "Epoch 15/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.3402 - accuracy: 0.8679 - val_loss: 0.6925 - val_accuracy: 0.4468\n",
      "Epoch 16/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2500 - accuracy: 0.8868 - val_loss: 0.6874 - val_accuracy: 0.4468\n",
      "Epoch 17/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3288 - accuracy: 0.8868 - val_loss: 0.6797 - val_accuracy: 0.4468\n",
      "Epoch 18/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3376 - accuracy: 0.9057 - val_loss: 0.6725 - val_accuracy: 0.4468\n",
      "Epoch 19/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2128 - accuracy: 0.9434 - val_loss: 0.6650 - val_accuracy: 0.4468\n",
      "Epoch 20/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2801 - accuracy: 0.8868 - val_loss: 0.6615 - val_accuracy: 0.4681\n",
      "Epoch 21/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3973 - accuracy: 0.8491 - val_loss: 0.6586 - val_accuracy: 0.4681\n",
      "Epoch 22/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2773 - accuracy: 0.9057 - val_loss: 0.6556 - val_accuracy: 0.4681\n",
      "Epoch 23/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.4194 - accuracy: 0.8113 - val_loss: 0.6534 - val_accuracy: 0.4681\n",
      "Epoch 24/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2578 - accuracy: 0.8868 - val_loss: 0.6558 - val_accuracy: 0.4681\n",
      "Epoch 25/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2794 - accuracy: 0.8868 - val_loss: 0.6627 - val_accuracy: 0.4681\n",
      "Epoch 26/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.3252 - accuracy: 0.8868 - val_loss: 0.6678 - val_accuracy: 0.4468\n",
      "Epoch 27/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.3064 - accuracy: 0.8679 - val_loss: 0.6675 - val_accuracy: 0.4468\n",
      "Epoch 28/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3298 - accuracy: 0.8679 - val_loss: 0.6648 - val_accuracy: 0.4468\n",
      "Epoch 29/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.3332 - accuracy: 0.8868 - val_loss: 0.6691 - val_accuracy: 0.4468\n",
      "Epoch 30/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2777 - accuracy: 0.8491 - val_loss: 0.6708 - val_accuracy: 0.4468\n",
      "Epoch 31/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2304 - accuracy: 0.9057 - val_loss: 0.6741 - val_accuracy: 0.4468\n",
      "Epoch 32/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 0.2876 - accuracy: 0.8679 - val_loss: 0.6763 - val_accuracy: 0.4468\n",
      "Epoch 33/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2984 - accuracy: 0.8868 - val_loss: 0.6782 - val_accuracy: 0.4468\n",
      "Epoch 34/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2255 - accuracy: 0.9245 - val_loss: 0.6785 - val_accuracy: 0.4468\n",
      "Epoch 35/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2843 - accuracy: 0.8868 - val_loss: 0.6788 - val_accuracy: 0.4468\n",
      "Epoch 36/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2436 - accuracy: 0.9057 - val_loss: 0.6805 - val_accuracy: 0.4468\n",
      "Epoch 37/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2705 - accuracy: 0.8868 - val_loss: 0.6796 - val_accuracy: 0.4468\n",
      "Epoch 38/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2426 - accuracy: 0.8868 - val_loss: 0.6754 - val_accuracy: 0.4468\n",
      "Epoch 39/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2684 - accuracy: 0.9057 - val_loss: 0.6718 - val_accuracy: 0.4468\n",
      "Epoch 40/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.3096 - accuracy: 0.8679 - val_loss: 0.6647 - val_accuracy: 0.4681\n",
      "Epoch 41/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2627 - accuracy: 0.8491 - val_loss: 0.6607 - val_accuracy: 0.4681\n",
      "Epoch 42/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.3501 - accuracy: 0.8491 - val_loss: 0.6608 - val_accuracy: 0.4681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2537 - accuracy: 0.9057 - val_loss: 0.6612 - val_accuracy: 0.4681\n",
      "Epoch 44/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3370 - accuracy: 0.9057 - val_loss: 0.6640 - val_accuracy: 0.4681\n",
      "Epoch 45/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2454 - accuracy: 0.9057 - val_loss: 0.6646 - val_accuracy: 0.4681\n",
      "Epoch 46/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.3327 - accuracy: 0.8491 - val_loss: 0.6606 - val_accuracy: 0.5106\n",
      "Epoch 47/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2399 - accuracy: 0.8868 - val_loss: 0.6530 - val_accuracy: 0.5106\n",
      "Epoch 48/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2456 - accuracy: 0.8868 - val_loss: 0.6441 - val_accuracy: 0.5319\n",
      "Epoch 49/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2851 - accuracy: 0.8679 - val_loss: 0.6362 - val_accuracy: 0.5319\n",
      "Epoch 50/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3188 - accuracy: 0.8491 - val_loss: 0.6262 - val_accuracy: 0.5319\n",
      "Epoch 51/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3139 - accuracy: 0.8679 - val_loss: 0.6169 - val_accuracy: 0.5957\n",
      "Epoch 52/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2478 - accuracy: 0.8679 - val_loss: 0.6092 - val_accuracy: 0.6383\n",
      "Epoch 53/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3016 - accuracy: 0.8679 - val_loss: 0.6012 - val_accuracy: 0.6809\n",
      "Epoch 54/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2207 - accuracy: 0.9057 - val_loss: 0.5951 - val_accuracy: 0.7234\n",
      "Epoch 55/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3655 - accuracy: 0.8491 - val_loss: 0.5898 - val_accuracy: 0.7234\n",
      "Epoch 56/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3459 - accuracy: 0.8679 - val_loss: 0.5832 - val_accuracy: 0.7021\n",
      "Epoch 57/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3326 - accuracy: 0.8302 - val_loss: 0.5786 - val_accuracy: 0.7234\n",
      "Epoch 58/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.3166 - accuracy: 0.8679 - val_loss: 0.5744 - val_accuracy: 0.7447\n",
      "Epoch 59/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3046 - accuracy: 0.8491 - val_loss: 0.5708 - val_accuracy: 0.7447\n",
      "Epoch 60/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2580 - accuracy: 0.8868 - val_loss: 0.5664 - val_accuracy: 0.7660\n",
      "Epoch 61/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3034 - accuracy: 0.8868 - val_loss: 0.5641 - val_accuracy: 0.7660\n",
      "Epoch 62/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2506 - accuracy: 0.9245 - val_loss: 0.5592 - val_accuracy: 0.7872\n",
      "Epoch 63/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2369 - accuracy: 0.8868 - val_loss: 0.5539 - val_accuracy: 0.8085\n",
      "Epoch 64/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3291 - accuracy: 0.8491 - val_loss: 0.5500 - val_accuracy: 0.7660\n",
      "Epoch 65/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2767 - accuracy: 0.8679 - val_loss: 0.5491 - val_accuracy: 0.7660\n",
      "Epoch 66/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.4087 - accuracy: 0.8679 - val_loss: 0.5459 - val_accuracy: 0.7872\n",
      "Epoch 67/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2960 - accuracy: 0.8679 - val_loss: 0.5438 - val_accuracy: 0.7660\n",
      "Epoch 68/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.3889 - accuracy: 0.8302 - val_loss: 0.5397 - val_accuracy: 0.7872\n",
      "Epoch 69/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.3971 - accuracy: 0.8679 - val_loss: 0.5369 - val_accuracy: 0.8085\n",
      "Epoch 70/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2469 - accuracy: 0.9057 - val_loss: 0.5330 - val_accuracy: 0.8085\n",
      "Epoch 71/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2850 - accuracy: 0.9245 - val_loss: 0.5302 - val_accuracy: 0.8085\n",
      "Epoch 72/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2192 - accuracy: 0.9057 - val_loss: 0.5285 - val_accuracy: 0.8085\n",
      "Epoch 73/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2872 - accuracy: 0.8679 - val_loss: 0.5276 - val_accuracy: 0.8085\n",
      "Epoch 74/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.3052 - accuracy: 0.9057 - val_loss: 0.5258 - val_accuracy: 0.8085\n",
      "Epoch 75/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2613 - accuracy: 0.8868 - val_loss: 0.5246 - val_accuracy: 0.7872\n",
      "Epoch 76/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.4488 - accuracy: 0.8302 - val_loss: 0.5241 - val_accuracy: 0.7660\n",
      "Epoch 77/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2408 - accuracy: 0.9057 - val_loss: 0.5250 - val_accuracy: 0.7660\n",
      "Epoch 78/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2763 - accuracy: 0.9057 - val_loss: 0.5254 - val_accuracy: 0.7660\n",
      "Epoch 79/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2625 - accuracy: 0.8679 - val_loss: 0.5259 - val_accuracy: 0.7660\n",
      "Epoch 80/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2821 - accuracy: 0.8868 - val_loss: 0.5260 - val_accuracy: 0.7660\n",
      "Epoch 81/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2330 - accuracy: 0.8868 - val_loss: 0.5261 - val_accuracy: 0.7660\n",
      "Epoch 82/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.3465 - accuracy: 0.8868 - val_loss: 0.5259 - val_accuracy: 0.7447\n",
      "Epoch 83/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2144 - accuracy: 0.9245 - val_loss: 0.5253 - val_accuracy: 0.7447\n",
      "Epoch 84/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3338 - accuracy: 0.8302 - val_loss: 0.5240 - val_accuracy: 0.7660\n",
      "Epoch 85/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2504 - accuracy: 0.8679 - val_loss: 0.5233 - val_accuracy: 0.7660\n",
      "Epoch 86/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2587 - accuracy: 0.9057 - val_loss: 0.5225 - val_accuracy: 0.7660\n",
      "Epoch 87/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2912 - accuracy: 0.8491 - val_loss: 0.5209 - val_accuracy: 0.7660\n",
      "Epoch 88/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2322 - accuracy: 0.8491 - val_loss: 0.5189 - val_accuracy: 0.7660\n",
      "Epoch 89/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.3007 - accuracy: 0.8868 - val_loss: 0.5164 - val_accuracy: 0.7660\n",
      "Epoch 90/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2420 - accuracy: 0.8868 - val_loss: 0.5145 - val_accuracy: 0.7660\n",
      "Epoch 91/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2161 - accuracy: 0.9245 - val_loss: 0.5123 - val_accuracy: 0.7872\n",
      "Epoch 92/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2880 - accuracy: 0.8868 - val_loss: 0.5107 - val_accuracy: 0.8085\n",
      "Epoch 93/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2611 - accuracy: 0.9057 - val_loss: 0.5098 - val_accuracy: 0.8085\n",
      "Epoch 94/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2569 - accuracy: 0.8679 - val_loss: 0.5097 - val_accuracy: 0.8085\n",
      "Epoch 95/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2395 - accuracy: 0.9057 - val_loss: 0.5095 - val_accuracy: 0.8085\n",
      "Epoch 96/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3248 - accuracy: 0.8491 - val_loss: 0.5099 - val_accuracy: 0.8085\n",
      "Epoch 97/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2810 - accuracy: 0.8868 - val_loss: 0.5104 - val_accuracy: 0.8085\n",
      "Epoch 98/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2320 - accuracy: 0.9245 - val_loss: 0.5097 - val_accuracy: 0.8085\n",
      "Epoch 99/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.3278 - accuracy: 0.9057 - val_loss: 0.5092 - val_accuracy: 0.8085\n",
      "Epoch 100/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.3221 - accuracy: 0.8868 - val_loss: 0.5094 - val_accuracy: 0.8085\n",
      "Epoch 101/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2705 - accuracy: 0.8868 - val_loss: 0.5097 - val_accuracy: 0.8085\n",
      "Epoch 102/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2632 - accuracy: 0.8679 - val_loss: 0.5088 - val_accuracy: 0.8085\n",
      "Epoch 103/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2232 - accuracy: 0.9057 - val_loss: 0.5088 - val_accuracy: 0.7872\n",
      "Epoch 104/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2743 - accuracy: 0.9057 - val_loss: 0.5087 - val_accuracy: 0.7872\n",
      "Epoch 105/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2214 - accuracy: 0.9245 - val_loss: 0.5078 - val_accuracy: 0.7872\n",
      "Epoch 106/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3505 - accuracy: 0.8491 - val_loss: 0.5067 - val_accuracy: 0.7872\n",
      "Epoch 107/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3447 - accuracy: 0.8113 - val_loss: 0.5038 - val_accuracy: 0.7872\n",
      "Epoch 108/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.3736 - accuracy: 0.8302 - val_loss: 0.5007 - val_accuracy: 0.7872\n",
      "Epoch 109/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2809 - accuracy: 0.9057 - val_loss: 0.4977 - val_accuracy: 0.7872\n",
      "Epoch 110/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2678 - accuracy: 0.8491 - val_loss: 0.4955 - val_accuracy: 0.7872\n",
      "Epoch 111/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2186 - accuracy: 0.9245 - val_loss: 0.4934 - val_accuracy: 0.7872\n",
      "Epoch 112/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.3334 - accuracy: 0.8679 - val_loss: 0.4904 - val_accuracy: 0.7872\n",
      "Epoch 113/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3478 - accuracy: 0.8679 - val_loss: 0.4888 - val_accuracy: 0.7872\n",
      "Epoch 114/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.3631 - accuracy: 0.8679 - val_loss: 0.4881 - val_accuracy: 0.7872\n",
      "Epoch 115/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2888 - accuracy: 0.9057 - val_loss: 0.4885 - val_accuracy: 0.7872\n",
      "Epoch 116/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2308 - accuracy: 0.9434 - val_loss: 0.4888 - val_accuracy: 0.7872\n",
      "Epoch 117/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3062 - accuracy: 0.9057 - val_loss: 0.4883 - val_accuracy: 0.7872\n",
      "Epoch 118/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2733 - accuracy: 0.9057 - val_loss: 0.4873 - val_accuracy: 0.7872\n",
      "Epoch 119/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2736 - accuracy: 0.8868 - val_loss: 0.4856 - val_accuracy: 0.7872\n",
      "Epoch 120/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2643 - accuracy: 0.8491 - val_loss: 0.4835 - val_accuracy: 0.7872\n",
      "Epoch 121/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2425 - accuracy: 0.8679 - val_loss: 0.4816 - val_accuracy: 0.7872\n",
      "Epoch 122/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2517 - accuracy: 0.8868 - val_loss: 0.4803 - val_accuracy: 0.7872\n",
      "Epoch 123/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2819 - accuracy: 0.9245 - val_loss: 0.4805 - val_accuracy: 0.7660\n",
      "Epoch 124/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.4073 - accuracy: 0.8302 - val_loss: 0.4803 - val_accuracy: 0.7660\n",
      "Epoch 125/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3116 - accuracy: 0.9057 - val_loss: 0.4796 - val_accuracy: 0.7660\n",
      "Epoch 126/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2908 - accuracy: 0.8868 - val_loss: 0.4780 - val_accuracy: 0.7660\n",
      "Epoch 127/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2956 - accuracy: 0.8868 - val_loss: 0.4775 - val_accuracy: 0.7660\n",
      "Epoch 128/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2840 - accuracy: 0.8491 - val_loss: 0.4762 - val_accuracy: 0.7660\n",
      "Epoch 129/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2846 - accuracy: 0.8491 - val_loss: 0.4750 - val_accuracy: 0.7660\n",
      "Epoch 130/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.3597 - accuracy: 0.8868 - val_loss: 0.4736 - val_accuracy: 0.7660\n",
      "Epoch 131/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3334 - accuracy: 0.8491 - val_loss: 0.4728 - val_accuracy: 0.7660\n",
      "Epoch 132/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2530 - accuracy: 0.9057 - val_loss: 0.4708 - val_accuracy: 0.7660\n",
      "Epoch 133/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2602 - accuracy: 0.8491 - val_loss: 0.4693 - val_accuracy: 0.7660\n",
      "Epoch 134/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2955 - accuracy: 0.8868 - val_loss: 0.4682 - val_accuracy: 0.7660\n",
      "Epoch 135/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2839 - accuracy: 0.9057 - val_loss: 0.4677 - val_accuracy: 0.7660\n",
      "Epoch 136/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3515 - accuracy: 0.8491 - val_loss: 0.4679 - val_accuracy: 0.7660\n",
      "Epoch 137/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2997 - accuracy: 0.8679 - val_loss: 0.4700 - val_accuracy: 0.7660\n",
      "Epoch 138/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3234 - accuracy: 0.8868 - val_loss: 0.4697 - val_accuracy: 0.7447\n",
      "Epoch 139/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2849 - accuracy: 0.9245 - val_loss: 0.4692 - val_accuracy: 0.7447\n",
      "Epoch 140/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2652 - accuracy: 0.8679 - val_loss: 0.4701 - val_accuracy: 0.7447\n",
      "Epoch 141/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.3725 - accuracy: 0.8679 - val_loss: 0.4702 - val_accuracy: 0.7447\n",
      "Epoch 142/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2897 - accuracy: 0.8679 - val_loss: 0.4688 - val_accuracy: 0.7447\n",
      "Epoch 143/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2368 - accuracy: 0.9057 - val_loss: 0.4680 - val_accuracy: 0.7447\n",
      "Epoch 144/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2845 - accuracy: 0.8868 - val_loss: 0.4653 - val_accuracy: 0.7660\n",
      "Epoch 145/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2001 - accuracy: 0.8868 - val_loss: 0.4629 - val_accuracy: 0.7872\n",
      "Epoch 146/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2334 - accuracy: 0.9245 - val_loss: 0.4623 - val_accuracy: 0.7872\n",
      "Epoch 147/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2053 - accuracy: 0.9245 - val_loss: 0.4616 - val_accuracy: 0.7872\n",
      "Epoch 148/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3002 - accuracy: 0.9057 - val_loss: 0.4597 - val_accuracy: 0.7872\n",
      "Epoch 149/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.3246 - accuracy: 0.8491 - val_loss: 0.4583 - val_accuracy: 0.7872\n",
      "Epoch 150/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.4303 - accuracy: 0.8113 - val_loss: 0.4578 - val_accuracy: 0.7872\n",
      "Epoch 151/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2877 - accuracy: 0.9057 - val_loss: 0.4583 - val_accuracy: 0.7872\n",
      "Epoch 152/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2158 - accuracy: 0.9245 - val_loss: 0.4583 - val_accuracy: 0.7872\n",
      "Epoch 153/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2898 - accuracy: 0.8679 - val_loss: 0.4582 - val_accuracy: 0.7872\n",
      "Epoch 154/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2949 - accuracy: 0.8679 - val_loss: 0.4574 - val_accuracy: 0.7872\n",
      "Epoch 155/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 659us/step - loss: 0.2484 - accuracy: 0.9057 - val_loss: 0.4578 - val_accuracy: 0.7660\n",
      "Epoch 156/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2483 - accuracy: 0.9057 - val_loss: 0.4579 - val_accuracy: 0.7660\n",
      "Epoch 157/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2378 - accuracy: 0.8868 - val_loss: 0.4580 - val_accuracy: 0.7660\n",
      "Epoch 158/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.3196 - accuracy: 0.8679 - val_loss: 0.4583 - val_accuracy: 0.7660\n",
      "Epoch 159/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.3195 - accuracy: 0.8679 - val_loss: 0.4586 - val_accuracy: 0.7660\n",
      "Epoch 160/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.3261 - accuracy: 0.8491 - val_loss: 0.4605 - val_accuracy: 0.7660\n",
      "Epoch 161/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2294 - accuracy: 0.9245 - val_loss: 0.4617 - val_accuracy: 0.7660\n",
      "Epoch 162/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2540 - accuracy: 0.8868 - val_loss: 0.4625 - val_accuracy: 0.7447\n",
      "Epoch 163/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2907 - accuracy: 0.8868 - val_loss: 0.4644 - val_accuracy: 0.7660\n",
      "Epoch 164/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3240 - accuracy: 0.8679 - val_loss: 0.4673 - val_accuracy: 0.7660\n",
      "Epoch 165/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.3058 - accuracy: 0.8491 - val_loss: 0.4689 - val_accuracy: 0.7660\n",
      "Epoch 166/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2735 - accuracy: 0.8868 - val_loss: 0.4715 - val_accuracy: 0.7660\n",
      "Epoch 167/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.3378 - accuracy: 0.8302 - val_loss: 0.4756 - val_accuracy: 0.7660\n",
      "Epoch 168/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2443 - accuracy: 0.8868 - val_loss: 0.4784 - val_accuracy: 0.7447\n",
      "Epoch 169/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.3117 - accuracy: 0.8679 - val_loss: 0.4812 - val_accuracy: 0.7447\n",
      "Epoch 170/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2228 - accuracy: 0.8868 - val_loss: 0.4853 - val_accuracy: 0.7447\n",
      "Epoch 171/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.3180 - accuracy: 0.8868 - val_loss: 0.4884 - val_accuracy: 0.7447\n",
      "Epoch 172/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.3534 - accuracy: 0.8491 - val_loss: 0.4870 - val_accuracy: 0.7447\n",
      "Epoch 173/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.3059 - accuracy: 0.8679 - val_loss: 0.4892 - val_accuracy: 0.7660\n",
      "Epoch 174/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2912 - accuracy: 0.8679 - val_loss: 0.4877 - val_accuracy: 0.7660\n",
      "Epoch 175/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.3205 - accuracy: 0.8679 - val_loss: 0.4864 - val_accuracy: 0.7660\n",
      "Epoch 176/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2443 - accuracy: 0.8679 - val_loss: 0.4825 - val_accuracy: 0.7660\n",
      "Epoch 177/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3168 - accuracy: 0.8491 - val_loss: 0.4801 - val_accuracy: 0.7660\n",
      "Epoch 178/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.4645 - accuracy: 0.8113 - val_loss: 0.4765 - val_accuracy: 0.7447\n",
      "Epoch 179/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2302 - accuracy: 0.9245 - val_loss: 0.4679 - val_accuracy: 0.7447\n",
      "Epoch 180/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2807 - accuracy: 0.8679 - val_loss: 0.4625 - val_accuracy: 0.7660\n",
      "Epoch 181/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2589 - accuracy: 0.8679 - val_loss: 0.4572 - val_accuracy: 0.7660\n",
      "Epoch 182/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2859 - accuracy: 0.8868 - val_loss: 0.4536 - val_accuracy: 0.7660\n",
      "Epoch 183/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2504 - accuracy: 0.8679 - val_loss: 0.4527 - val_accuracy: 0.7872\n",
      "Epoch 184/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.3214 - accuracy: 0.8679 - val_loss: 0.4520 - val_accuracy: 0.7660\n",
      "Epoch 185/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3175 - accuracy: 0.8868 - val_loss: 0.4523 - val_accuracy: 0.7660\n",
      "Epoch 186/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2102 - accuracy: 0.9245 - val_loss: 0.4513 - val_accuracy: 0.7660\n",
      "Epoch 187/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2487 - accuracy: 0.8679 - val_loss: 0.4493 - val_accuracy: 0.7660\n",
      "Epoch 188/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2939 - accuracy: 0.8491 - val_loss: 0.4477 - val_accuracy: 0.7660\n",
      "Epoch 189/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3578 - accuracy: 0.8679 - val_loss: 0.4450 - val_accuracy: 0.7660\n",
      "Epoch 190/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2715 - accuracy: 0.9245 - val_loss: 0.4415 - val_accuracy: 0.7660\n",
      "Epoch 191/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2357 - accuracy: 0.9057 - val_loss: 0.4369 - val_accuracy: 0.7660\n",
      "Epoch 192/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.1879 - accuracy: 0.9057 - val_loss: 0.4346 - val_accuracy: 0.7660\n",
      "Epoch 193/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2761 - accuracy: 0.8679 - val_loss: 0.4337 - val_accuracy: 0.7872\n",
      "Epoch 194/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.3134 - accuracy: 0.8868 - val_loss: 0.4332 - val_accuracy: 0.7872\n",
      "Epoch 195/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3045 - accuracy: 0.8679 - val_loss: 0.4343 - val_accuracy: 0.7660\n",
      "Epoch 196/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2496 - accuracy: 0.8868 - val_loss: 0.4361 - val_accuracy: 0.7660\n",
      "Epoch 197/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2712 - accuracy: 0.8868 - val_loss: 0.4396 - val_accuracy: 0.7660\n",
      "Epoch 198/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2758 - accuracy: 0.8868 - val_loss: 0.4440 - val_accuracy: 0.7660\n",
      "Epoch 199/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2801 - accuracy: 0.8679 - val_loss: 0.4477 - val_accuracy: 0.7872\n",
      "Epoch 200/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.3487 - accuracy: 0.8491 - val_loss: 0.4500 - val_accuracy: 0.7872\n",
      "Epoch 201/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2598 - accuracy: 0.8868 - val_loss: 0.4534 - val_accuracy: 0.7872\n",
      "Epoch 202/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2385 - accuracy: 0.8868 - val_loss: 0.4543 - val_accuracy: 0.7872\n",
      "Epoch 203/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2574 - accuracy: 0.9057 - val_loss: 0.4552 - val_accuracy: 0.7872\n",
      "Epoch 204/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2848 - accuracy: 0.8679 - val_loss: 0.4550 - val_accuracy: 0.7872\n",
      "Epoch 205/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2727 - accuracy: 0.9057 - val_loss: 0.4534 - val_accuracy: 0.7872\n",
      "Epoch 206/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2923 - accuracy: 0.8491 - val_loss: 0.4517 - val_accuracy: 0.7872\n",
      "Epoch 207/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2535 - accuracy: 0.8868 - val_loss: 0.4496 - val_accuracy: 0.7872\n",
      "Epoch 208/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2619 - accuracy: 0.9245 - val_loss: 0.4460 - val_accuracy: 0.7660\n",
      "Epoch 209/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.3775 - accuracy: 0.8679 - val_loss: 0.4446 - val_accuracy: 0.7660\n",
      "Epoch 210/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3108 - accuracy: 0.8491 - val_loss: 0.4411 - val_accuracy: 0.7660\n",
      "Epoch 211/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2654 - accuracy: 0.9057 - val_loss: 0.4366 - val_accuracy: 0.7660\n",
      "Epoch 212/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3775 - accuracy: 0.8679 - val_loss: 0.4317 - val_accuracy: 0.7660\n",
      "Epoch 213/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2427 - accuracy: 0.9057 - val_loss: 0.4289 - val_accuracy: 0.7660\n",
      "Epoch 214/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3297 - accuracy: 0.8491 - val_loss: 0.4271 - val_accuracy: 0.7872\n",
      "Epoch 215/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2557 - accuracy: 0.9057 - val_loss: 0.4272 - val_accuracy: 0.7872\n",
      "Epoch 216/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2729 - accuracy: 0.8491 - val_loss: 0.4280 - val_accuracy: 0.7660\n",
      "Epoch 217/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2745 - accuracy: 0.8679 - val_loss: 0.4292 - val_accuracy: 0.7660\n",
      "Epoch 218/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2822 - accuracy: 0.8679 - val_loss: 0.4322 - val_accuracy: 0.7660\n",
      "Epoch 219/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2821 - accuracy: 0.9245 - val_loss: 0.4355 - val_accuracy: 0.7660\n",
      "Epoch 220/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2950 - accuracy: 0.8868 - val_loss: 0.4365 - val_accuracy: 0.7660\n",
      "Epoch 221/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.3053 - accuracy: 0.9057 - val_loss: 0.4364 - val_accuracy: 0.7660\n",
      "Epoch 222/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3499 - accuracy: 0.8868 - val_loss: 0.4353 - val_accuracy: 0.7660\n",
      "Epoch 223/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2977 - accuracy: 0.8868 - val_loss: 0.4355 - val_accuracy: 0.7660\n",
      "Epoch 224/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2399 - accuracy: 0.9245 - val_loss: 0.4346 - val_accuracy: 0.7660\n",
      "Epoch 225/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.3115 - accuracy: 0.8868 - val_loss: 0.4323 - val_accuracy: 0.7660\n",
      "Epoch 226/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2373 - accuracy: 0.8868 - val_loss: 0.4287 - val_accuracy: 0.7660\n",
      "Epoch 227/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2738 - accuracy: 0.8491 - val_loss: 0.4262 - val_accuracy: 0.7660\n",
      "Epoch 228/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2433 - accuracy: 0.9245 - val_loss: 0.4239 - val_accuracy: 0.7872\n",
      "Epoch 229/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2831 - accuracy: 0.9245 - val_loss: 0.4220 - val_accuracy: 0.7872\n",
      "Epoch 230/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.3041 - accuracy: 0.8491 - val_loss: 0.4214 - val_accuracy: 0.7872\n",
      "Epoch 231/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.3025 - accuracy: 0.8868 - val_loss: 0.4208 - val_accuracy: 0.7872\n",
      "Epoch 232/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2044 - accuracy: 0.9434 - val_loss: 0.4204 - val_accuracy: 0.7872\n",
      "Epoch 233/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2423 - accuracy: 0.9057 - val_loss: 0.4196 - val_accuracy: 0.7872\n",
      "Epoch 234/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2478 - accuracy: 0.9245 - val_loss: 0.4193 - val_accuracy: 0.7872\n",
      "Epoch 235/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2699 - accuracy: 0.9057 - val_loss: 0.4181 - val_accuracy: 0.7872\n",
      "Epoch 236/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2491 - accuracy: 0.8868 - val_loss: 0.4168 - val_accuracy: 0.7872\n",
      "Epoch 237/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3148 - accuracy: 0.8868 - val_loss: 0.4159 - val_accuracy: 0.7872\n",
      "Epoch 238/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2687 - accuracy: 0.9057 - val_loss: 0.4154 - val_accuracy: 0.7872\n",
      "Epoch 239/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.3086 - accuracy: 0.8679 - val_loss: 0.4145 - val_accuracy: 0.7872\n",
      "Epoch 240/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2821 - accuracy: 0.9057 - val_loss: 0.4135 - val_accuracy: 0.7872\n",
      "Epoch 241/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2444 - accuracy: 0.9057 - val_loss: 0.4126 - val_accuracy: 0.7872\n",
      "Epoch 242/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2674 - accuracy: 0.8679 - val_loss: 0.4118 - val_accuracy: 0.7872\n",
      "Epoch 243/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2790 - accuracy: 0.8491 - val_loss: 0.4114 - val_accuracy: 0.7872\n",
      "Epoch 244/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2341 - accuracy: 0.9057 - val_loss: 0.4113 - val_accuracy: 0.7872\n",
      "Epoch 245/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2240 - accuracy: 0.9057 - val_loss: 0.4118 - val_accuracy: 0.7872\n",
      "Epoch 246/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2399 - accuracy: 0.9245 - val_loss: 0.4123 - val_accuracy: 0.7872\n",
      "Epoch 247/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3055 - accuracy: 0.8868 - val_loss: 0.4144 - val_accuracy: 0.7872\n",
      "Epoch 248/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2900 - accuracy: 0.8679 - val_loss: 0.4163 - val_accuracy: 0.7872\n",
      "Epoch 249/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2262 - accuracy: 0.9057 - val_loss: 0.4188 - val_accuracy: 0.7872\n",
      "Epoch 250/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2034 - accuracy: 0.9245 - val_loss: 0.4218 - val_accuracy: 0.7660\n",
      "Epoch 251/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2613 - accuracy: 0.8868 - val_loss: 0.4242 - val_accuracy: 0.7660\n",
      "Epoch 252/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2767 - accuracy: 0.8868 - val_loss: 0.4263 - val_accuracy: 0.7660\n",
      "Epoch 253/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3061 - accuracy: 0.9057 - val_loss: 0.4252 - val_accuracy: 0.7660\n",
      "Epoch 254/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2334 - accuracy: 0.8868 - val_loss: 0.4246 - val_accuracy: 0.7660\n",
      "Epoch 255/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2278 - accuracy: 0.9057 - val_loss: 0.4248 - val_accuracy: 0.7660\n",
      "Epoch 256/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2868 - accuracy: 0.8868 - val_loss: 0.4244 - val_accuracy: 0.7872\n",
      "Epoch 257/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2698 - accuracy: 0.8868 - val_loss: 0.4246 - val_accuracy: 0.7872\n",
      "Epoch 258/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.3366 - accuracy: 0.8868 - val_loss: 0.4272 - val_accuracy: 0.7872\n",
      "Epoch 259/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2660 - accuracy: 0.9057 - val_loss: 0.4277 - val_accuracy: 0.7660\n",
      "Epoch 260/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2965 - accuracy: 0.8491 - val_loss: 0.4277 - val_accuracy: 0.7660\n",
      "Epoch 261/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.3195 - accuracy: 0.8302 - val_loss: 0.4254 - val_accuracy: 0.7872\n",
      "Epoch 262/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2651 - accuracy: 0.8868 - val_loss: 0.4234 - val_accuracy: 0.7872\n",
      "Epoch 263/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2429 - accuracy: 0.9245 - val_loss: 0.4205 - val_accuracy: 0.7872\n",
      "Epoch 264/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2532 - accuracy: 0.8868 - val_loss: 0.4191 - val_accuracy: 0.7872\n",
      "Epoch 265/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2802 - accuracy: 0.9057 - val_loss: 0.4186 - val_accuracy: 0.7872\n",
      "Epoch 266/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2639 - accuracy: 0.8679 - val_loss: 0.4182 - val_accuracy: 0.7872\n",
      "Epoch 267/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 621us/step - loss: 0.2431 - accuracy: 0.8679 - val_loss: 0.4185 - val_accuracy: 0.7872\n",
      "Epoch 268/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3123 - accuracy: 0.8868 - val_loss: 0.4208 - val_accuracy: 0.7872\n",
      "Epoch 269/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2553 - accuracy: 0.8679 - val_loss: 0.4225 - val_accuracy: 0.7872\n",
      "Epoch 270/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3308 - accuracy: 0.8679 - val_loss: 0.4242 - val_accuracy: 0.8085\n",
      "Epoch 271/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.3032 - accuracy: 0.8679 - val_loss: 0.4239 - val_accuracy: 0.8085\n",
      "Epoch 272/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2604 - accuracy: 0.8679 - val_loss: 0.4221 - val_accuracy: 0.8085\n",
      "Epoch 273/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2152 - accuracy: 0.9057 - val_loss: 0.4208 - val_accuracy: 0.8085\n",
      "Epoch 274/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.3306 - accuracy: 0.8491 - val_loss: 0.4211 - val_accuracy: 0.8085\n",
      "Epoch 275/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2947 - accuracy: 0.8679 - val_loss: 0.4206 - val_accuracy: 0.8085\n",
      "Epoch 276/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2544 - accuracy: 0.8679 - val_loss: 0.4198 - val_accuracy: 0.8085\n",
      "Epoch 277/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.3792 - accuracy: 0.8491 - val_loss: 0.4217 - val_accuracy: 0.8085\n",
      "Epoch 278/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2375 - accuracy: 0.8679 - val_loss: 0.4231 - val_accuracy: 0.7872\n",
      "Epoch 279/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2494 - accuracy: 0.9245 - val_loss: 0.4242 - val_accuracy: 0.7872\n",
      "Epoch 280/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2687 - accuracy: 0.8679 - val_loss: 0.4255 - val_accuracy: 0.7872\n",
      "Epoch 281/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.3046 - accuracy: 0.8679 - val_loss: 0.4265 - val_accuracy: 0.7872\n",
      "Epoch 282/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2542 - accuracy: 0.8868 - val_loss: 0.4277 - val_accuracy: 0.7872\n",
      "Epoch 283/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2931 - accuracy: 0.9057 - val_loss: 0.4300 - val_accuracy: 0.8085\n",
      "Epoch 284/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2468 - accuracy: 0.9057 - val_loss: 0.4345 - val_accuracy: 0.7872\n",
      "Epoch 285/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2931 - accuracy: 0.9245 - val_loss: 0.4407 - val_accuracy: 0.7872\n",
      "Epoch 286/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2888 - accuracy: 0.8491 - val_loss: 0.4464 - val_accuracy: 0.7872\n",
      "Epoch 287/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.3541 - accuracy: 0.8302 - val_loss: 0.4483 - val_accuracy: 0.7872\n",
      "Epoch 288/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.3197 - accuracy: 0.8491 - val_loss: 0.4525 - val_accuracy: 0.8085\n",
      "Epoch 289/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2424 - accuracy: 0.8868 - val_loss: 0.4562 - val_accuracy: 0.8085\n",
      "Epoch 290/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2964 - accuracy: 0.8491 - val_loss: 0.4574 - val_accuracy: 0.8085\n",
      "Epoch 291/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2682 - accuracy: 0.9057 - val_loss: 0.4589 - val_accuracy: 0.8085\n",
      "Epoch 292/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2743 - accuracy: 0.9245 - val_loss: 0.4607 - val_accuracy: 0.8085\n",
      "Epoch 293/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2695 - accuracy: 0.8868 - val_loss: 0.4631 - val_accuracy: 0.7872\n",
      "Epoch 294/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.3088 - accuracy: 0.8868 - val_loss: 0.4645 - val_accuracy: 0.7872\n",
      "Epoch 295/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2075 - accuracy: 0.9434 - val_loss: 0.4661 - val_accuracy: 0.7872\n",
      "Epoch 296/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2386 - accuracy: 0.8868 - val_loss: 0.4681 - val_accuracy: 0.7872\n",
      "Epoch 297/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.3281 - accuracy: 0.8679 - val_loss: 0.4687 - val_accuracy: 0.8085\n",
      "Epoch 298/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.3045 - accuracy: 0.8679 - val_loss: 0.4716 - val_accuracy: 0.8085\n",
      "Epoch 299/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2847 - accuracy: 0.8679 - val_loss: 0.4765 - val_accuracy: 0.8085\n",
      "Epoch 300/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3194 - accuracy: 0.8868 - val_loss: 0.4748 - val_accuracy: 0.8085\n",
      "Epoch 301/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2972 - accuracy: 0.8679 - val_loss: 0.4668 - val_accuracy: 0.8085\n",
      "Epoch 302/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.3539 - accuracy: 0.8113 - val_loss: 0.4595 - val_accuracy: 0.8085\n",
      "Epoch 303/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2987 - accuracy: 0.8491 - val_loss: 0.4558 - val_accuracy: 0.8085\n",
      "Epoch 304/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.3622 - accuracy: 0.9057 - val_loss: 0.4537 - val_accuracy: 0.8085\n",
      "Epoch 305/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.1944 - accuracy: 0.8868 - val_loss: 0.4482 - val_accuracy: 0.8085\n",
      "Epoch 306/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.3250 - accuracy: 0.8868 - val_loss: 0.4436 - val_accuracy: 0.8085\n",
      "Epoch 307/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.4983 - accuracy: 0.8113 - val_loss: 0.4367 - val_accuracy: 0.8085\n",
      "Epoch 308/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2847 - accuracy: 0.8491 - val_loss: 0.4349 - val_accuracy: 0.8085\n",
      "Epoch 309/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2818 - accuracy: 0.8679 - val_loss: 0.4354 - val_accuracy: 0.8085\n",
      "Epoch 310/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2110 - accuracy: 0.8868 - val_loss: 0.4354 - val_accuracy: 0.8085\n",
      "Epoch 311/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2633 - accuracy: 0.9057 - val_loss: 0.4368 - val_accuracy: 0.8085\n",
      "Epoch 312/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2385 - accuracy: 0.9057 - val_loss: 0.4373 - val_accuracy: 0.8085\n",
      "Epoch 313/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2522 - accuracy: 0.9057 - val_loss: 0.4372 - val_accuracy: 0.8085\n",
      "Epoch 314/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2489 - accuracy: 0.9057 - val_loss: 0.4395 - val_accuracy: 0.8085\n",
      "Epoch 315/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2005 - accuracy: 0.9245 - val_loss: 0.4427 - val_accuracy: 0.8085\n",
      "Epoch 316/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.3494 - accuracy: 0.8113 - val_loss: 0.4432 - val_accuracy: 0.8085\n",
      "Epoch 317/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.1741 - accuracy: 0.9434 - val_loss: 0.4424 - val_accuracy: 0.8085\n",
      "Epoch 318/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2904 - accuracy: 0.8868 - val_loss: 0.4419 - val_accuracy: 0.8085\n",
      "Epoch 319/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.3440 - accuracy: 0.8868 - val_loss: 0.4407 - val_accuracy: 0.8085\n",
      "Epoch 320/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.3009 - accuracy: 0.9057 - val_loss: 0.4419 - val_accuracy: 0.8085\n",
      "Epoch 321/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2436 - accuracy: 0.9057 - val_loss: 0.4432 - val_accuracy: 0.8085\n",
      "Epoch 322/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2993 - accuracy: 0.8491 - val_loss: 0.4468 - val_accuracy: 0.8085\n",
      "Epoch 323/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.3325 - accuracy: 0.8868 - val_loss: 0.4526 - val_accuracy: 0.8085\n",
      "Epoch 324/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.3042 - accuracy: 0.8491 - val_loss: 0.4557 - val_accuracy: 0.8085\n",
      "Epoch 325/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2486 - accuracy: 0.8868 - val_loss: 0.4594 - val_accuracy: 0.8085\n",
      "Epoch 326/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.3175 - accuracy: 0.8679 - val_loss: 0.4584 - val_accuracy: 0.8085\n",
      "Epoch 327/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3428 - accuracy: 0.8679 - val_loss: 0.4573 - val_accuracy: 0.8085\n",
      "Epoch 328/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2693 - accuracy: 0.8868 - val_loss: 0.4533 - val_accuracy: 0.8085\n",
      "Epoch 329/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2889 - accuracy: 0.8679 - val_loss: 0.4509 - val_accuracy: 0.8085\n",
      "Epoch 330/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.3090 - accuracy: 0.9057 - val_loss: 0.4519 - val_accuracy: 0.8085\n",
      "Epoch 331/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2736 - accuracy: 0.8679 - val_loss: 0.4505 - val_accuracy: 0.8085\n",
      "Epoch 332/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2343 - accuracy: 0.9245 - val_loss: 0.4504 - val_accuracy: 0.8085\n",
      "Epoch 333/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.3297 - accuracy: 0.8302 - val_loss: 0.4495 - val_accuracy: 0.8085\n",
      "Epoch 334/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2855 - accuracy: 0.8868 - val_loss: 0.4491 - val_accuracy: 0.8085\n",
      "Epoch 335/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2377 - accuracy: 0.9057 - val_loss: 0.4471 - val_accuracy: 0.8085\n",
      "Epoch 336/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2303 - accuracy: 0.9057 - val_loss: 0.4456 - val_accuracy: 0.8298\n",
      "Epoch 337/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2827 - accuracy: 0.8302 - val_loss: 0.4452 - val_accuracy: 0.8085\n",
      "Epoch 338/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.3098 - accuracy: 0.8491 - val_loss: 0.4471 - val_accuracy: 0.8085\n",
      "Epoch 339/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2879 - accuracy: 0.8679 - val_loss: 0.4506 - val_accuracy: 0.8085\n",
      "Epoch 340/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.1895 - accuracy: 0.9245 - val_loss: 0.4537 - val_accuracy: 0.8085\n",
      "Epoch 341/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2344 - accuracy: 0.8868 - val_loss: 0.4553 - val_accuracy: 0.8085\n",
      "Epoch 342/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2363 - accuracy: 0.9434 - val_loss: 0.4566 - val_accuracy: 0.8085\n",
      "Epoch 343/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.3061 - accuracy: 0.8868 - val_loss: 0.4600 - val_accuracy: 0.8085\n",
      "Epoch 344/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2193 - accuracy: 0.9057 - val_loss: 0.4651 - val_accuracy: 0.8085\n",
      "Epoch 345/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2456 - accuracy: 0.9057 - val_loss: 0.4710 - val_accuracy: 0.8085\n",
      "Epoch 346/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3404 - accuracy: 0.8491 - val_loss: 0.4791 - val_accuracy: 0.8085\n",
      "Epoch 347/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.3044 - accuracy: 0.8868 - val_loss: 0.4914 - val_accuracy: 0.7872\n",
      "Epoch 348/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2483 - accuracy: 0.9057 - val_loss: 0.5019 - val_accuracy: 0.7872\n",
      "Epoch 349/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2113 - accuracy: 0.9057 - val_loss: 0.5093 - val_accuracy: 0.7872\n",
      "Epoch 350/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2253 - accuracy: 0.8868 - val_loss: 0.5146 - val_accuracy: 0.7872\n",
      "Epoch 351/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2599 - accuracy: 0.8491 - val_loss: 0.5158 - val_accuracy: 0.7872\n",
      "Epoch 352/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.3305 - accuracy: 0.8679 - val_loss: 0.5144 - val_accuracy: 0.7872\n",
      "Epoch 353/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2595 - accuracy: 0.9057 - val_loss: 0.5102 - val_accuracy: 0.7872\n",
      "Epoch 354/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2612 - accuracy: 0.8868 - val_loss: 0.5035 - val_accuracy: 0.7872\n",
      "Epoch 355/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2176 - accuracy: 0.9057 - val_loss: 0.4921 - val_accuracy: 0.8085\n",
      "Epoch 356/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2305 - accuracy: 0.9245 - val_loss: 0.4836 - val_accuracy: 0.8085\n",
      "Epoch 357/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.4322 - accuracy: 0.8679 - val_loss: 0.4762 - val_accuracy: 0.8085\n",
      "Epoch 358/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2835 - accuracy: 0.8868 - val_loss: 0.4700 - val_accuracy: 0.8085\n",
      "Epoch 359/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2577 - accuracy: 0.8868 - val_loss: 0.4696 - val_accuracy: 0.8085\n",
      "Epoch 360/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2743 - accuracy: 0.8679 - val_loss: 0.4687 - val_accuracy: 0.8085\n",
      "Epoch 361/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2673 - accuracy: 0.8868 - val_loss: 0.4666 - val_accuracy: 0.8085\n",
      "Epoch 362/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2637 - accuracy: 0.8679 - val_loss: 0.4649 - val_accuracy: 0.8085\n",
      "Epoch 363/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2646 - accuracy: 0.8868 - val_loss: 0.4612 - val_accuracy: 0.8085\n",
      "Epoch 364/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2710 - accuracy: 0.8679 - val_loss: 0.4607 - val_accuracy: 0.8085\n",
      "Epoch 365/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.3003 - accuracy: 0.9057 - val_loss: 0.4629 - val_accuracy: 0.8085\n",
      "Epoch 366/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2563 - accuracy: 0.8868 - val_loss: 0.4646 - val_accuracy: 0.8085\n",
      "Epoch 367/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2467 - accuracy: 0.8868 - val_loss: 0.4672 - val_accuracy: 0.8085\n",
      "Epoch 368/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2615 - accuracy: 0.8491 - val_loss: 0.4656 - val_accuracy: 0.8085\n",
      "Epoch 369/1000\n",
      "53/53 [==============================] - 0s 979us/step - loss: 0.2477 - accuracy: 0.9057 - val_loss: 0.4639 - val_accuracy: 0.8085\n",
      "Epoch 370/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.2817 - accuracy: 0.8491 - val_loss: 0.4589 - val_accuracy: 0.8085\n",
      "Epoch 371/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2585 - accuracy: 0.8868 - val_loss: 0.4543 - val_accuracy: 0.8085\n",
      "Epoch 372/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2305 - accuracy: 0.9057 - val_loss: 0.4492 - val_accuracy: 0.8085\n",
      "Epoch 373/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2829 - accuracy: 0.8868 - val_loss: 0.4455 - val_accuracy: 0.8085\n",
      "Epoch 374/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.3051 - accuracy: 0.8302 - val_loss: 0.4450 - val_accuracy: 0.8085\n",
      "Epoch 375/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2887 - accuracy: 0.8679 - val_loss: 0.4421 - val_accuracy: 0.8085\n",
      "Epoch 376/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3063 - accuracy: 0.8679 - val_loss: 0.4402 - val_accuracy: 0.8085\n",
      "Epoch 377/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2413 - accuracy: 0.8868 - val_loss: 0.4403 - val_accuracy: 0.8085\n",
      "Epoch 378/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2457 - accuracy: 0.9245 - val_loss: 0.4375 - val_accuracy: 0.8085\n",
      "Epoch 379/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 677us/step - loss: 0.2830 - accuracy: 0.8679 - val_loss: 0.4342 - val_accuracy: 0.8085\n",
      "Epoch 380/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2329 - accuracy: 0.8868 - val_loss: 0.4318 - val_accuracy: 0.8085\n",
      "Epoch 381/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.3179 - accuracy: 0.9057 - val_loss: 0.4326 - val_accuracy: 0.8298\n",
      "Epoch 382/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2524 - accuracy: 0.8868 - val_loss: 0.4386 - val_accuracy: 0.8085\n",
      "Epoch 383/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.3181 - accuracy: 0.8491 - val_loss: 0.4462 - val_accuracy: 0.8085\n",
      "Epoch 384/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2130 - accuracy: 0.9057 - val_loss: 0.4568 - val_accuracy: 0.8085\n",
      "Epoch 385/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3106 - accuracy: 0.8679 - val_loss: 0.4652 - val_accuracy: 0.8085\n",
      "Epoch 386/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.2764 - accuracy: 0.9057 - val_loss: 0.4687 - val_accuracy: 0.8085\n",
      "Epoch 387/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2279 - accuracy: 0.9057 - val_loss: 0.4697 - val_accuracy: 0.8085\n",
      "Epoch 388/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2596 - accuracy: 0.8868 - val_loss: 0.4641 - val_accuracy: 0.8085\n",
      "Epoch 389/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2073 - accuracy: 0.9245 - val_loss: 0.4540 - val_accuracy: 0.8085\n",
      "Epoch 390/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2467 - accuracy: 0.8491 - val_loss: 0.4491 - val_accuracy: 0.8085\n",
      "Epoch 391/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2318 - accuracy: 0.9434 - val_loss: 0.4445 - val_accuracy: 0.8085\n",
      "Epoch 392/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2509 - accuracy: 0.9057 - val_loss: 0.4411 - val_accuracy: 0.8085\n",
      "Epoch 393/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2445 - accuracy: 0.8868 - val_loss: 0.4410 - val_accuracy: 0.8085\n",
      "Epoch 394/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2728 - accuracy: 0.9057 - val_loss: 0.4430 - val_accuracy: 0.8085\n",
      "Epoch 395/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2537 - accuracy: 0.8302 - val_loss: 0.4484 - val_accuracy: 0.8085\n",
      "Epoch 396/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2544 - accuracy: 0.8868 - val_loss: 0.4508 - val_accuracy: 0.8085\n",
      "Epoch 397/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2581 - accuracy: 0.9245 - val_loss: 0.4499 - val_accuracy: 0.8085\n",
      "Epoch 398/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2653 - accuracy: 0.9057 - val_loss: 0.4447 - val_accuracy: 0.8085\n",
      "Epoch 399/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2993 - accuracy: 0.8868 - val_loss: 0.4370 - val_accuracy: 0.8085\n",
      "Epoch 400/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2494 - accuracy: 0.8868 - val_loss: 0.4319 - val_accuracy: 0.8085\n",
      "Epoch 401/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2386 - accuracy: 0.9245 - val_loss: 0.4277 - val_accuracy: 0.8085\n",
      "Epoch 402/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.3092 - accuracy: 0.8491 - val_loss: 0.4252 - val_accuracy: 0.8085\n",
      "Epoch 403/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2400 - accuracy: 0.8868 - val_loss: 0.4273 - val_accuracy: 0.8085\n",
      "Epoch 404/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2358 - accuracy: 0.9434 - val_loss: 0.4284 - val_accuracy: 0.8085\n",
      "Epoch 405/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2784 - accuracy: 0.8679 - val_loss: 0.4315 - val_accuracy: 0.8085\n",
      "Epoch 406/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2657 - accuracy: 0.8491 - val_loss: 0.4321 - val_accuracy: 0.8085\n",
      "Epoch 407/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2775 - accuracy: 0.9057 - val_loss: 0.4359 - val_accuracy: 0.8085\n",
      "Epoch 408/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2968 - accuracy: 0.8491 - val_loss: 0.4366 - val_accuracy: 0.8085\n",
      "Epoch 409/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.3472 - accuracy: 0.8491 - val_loss: 0.4353 - val_accuracy: 0.8085\n",
      "Epoch 410/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.1960 - accuracy: 0.9057 - val_loss: 0.4327 - val_accuracy: 0.8085\n",
      "Epoch 411/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2550 - accuracy: 0.9245 - val_loss: 0.4307 - val_accuracy: 0.8085\n",
      "Epoch 412/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2597 - accuracy: 0.9057 - val_loss: 0.4291 - val_accuracy: 0.8085\n",
      "Epoch 413/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2356 - accuracy: 0.9434 - val_loss: 0.4279 - val_accuracy: 0.8085\n",
      "Epoch 414/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2903 - accuracy: 0.8302 - val_loss: 0.4239 - val_accuracy: 0.8085\n",
      "Epoch 415/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3130 - accuracy: 0.8868 - val_loss: 0.4234 - val_accuracy: 0.8085\n",
      "Epoch 416/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2629 - accuracy: 0.8491 - val_loss: 0.4259 - val_accuracy: 0.8085\n",
      "Epoch 417/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2733 - accuracy: 0.9434 - val_loss: 0.4309 - val_accuracy: 0.8085\n",
      "Epoch 418/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2299 - accuracy: 0.8679 - val_loss: 0.4336 - val_accuracy: 0.8085\n",
      "Epoch 419/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.3326 - accuracy: 0.8679 - val_loss: 0.4330 - val_accuracy: 0.8085\n",
      "Epoch 420/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2345 - accuracy: 0.9057 - val_loss: 0.4311 - val_accuracy: 0.8085\n",
      "Epoch 421/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2425 - accuracy: 0.9245 - val_loss: 0.4285 - val_accuracy: 0.8085\n",
      "Epoch 422/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2417 - accuracy: 0.8868 - val_loss: 0.4270 - val_accuracy: 0.8085\n",
      "Epoch 423/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.1687 - accuracy: 0.9245 - val_loss: 0.4231 - val_accuracy: 0.8085\n",
      "Epoch 424/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2635 - accuracy: 0.9057 - val_loss: 0.4189 - val_accuracy: 0.8085\n",
      "Epoch 425/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2282 - accuracy: 0.9623 - val_loss: 0.4168 - val_accuracy: 0.8085\n",
      "Epoch 426/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2965 - accuracy: 0.8868 - val_loss: 0.4163 - val_accuracy: 0.8085\n",
      "Epoch 427/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2654 - accuracy: 0.8868 - val_loss: 0.4200 - val_accuracy: 0.8085\n",
      "Epoch 428/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2790 - accuracy: 0.9057 - val_loss: 0.4214 - val_accuracy: 0.8085\n",
      "Epoch 429/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2865 - accuracy: 0.8868 - val_loss: 0.4241 - val_accuracy: 0.8085\n",
      "Epoch 430/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1692 - accuracy: 0.9623 - val_loss: 0.4246 - val_accuracy: 0.8085\n",
      "Epoch 431/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2860 - accuracy: 0.8679 - val_loss: 0.4272 - val_accuracy: 0.8085\n",
      "Epoch 432/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.3394 - accuracy: 0.8679 - val_loss: 0.4276 - val_accuracy: 0.8085\n",
      "Epoch 433/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2201 - accuracy: 0.9245 - val_loss: 0.4299 - val_accuracy: 0.8085\n",
      "Epoch 434/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2258 - accuracy: 0.8868 - val_loss: 0.4307 - val_accuracy: 0.8085\n",
      "Epoch 435/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.3206 - accuracy: 0.8491 - val_loss: 0.4337 - val_accuracy: 0.8085\n",
      "Epoch 436/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2749 - accuracy: 0.9057 - val_loss: 0.4317 - val_accuracy: 0.8085\n",
      "Epoch 437/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2083 - accuracy: 0.9245 - val_loss: 0.4285 - val_accuracy: 0.8085\n",
      "Epoch 438/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2906 - accuracy: 0.9057 - val_loss: 0.4277 - val_accuracy: 0.8085\n",
      "Epoch 439/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1996 - accuracy: 0.9245 - val_loss: 0.4269 - val_accuracy: 0.8085\n",
      "Epoch 440/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2394 - accuracy: 0.9057 - val_loss: 0.4212 - val_accuracy: 0.8085\n",
      "Epoch 441/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3124 - accuracy: 0.9057 - val_loss: 0.4212 - val_accuracy: 0.8085\n",
      "Epoch 442/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2493 - accuracy: 0.9245 - val_loss: 0.4244 - val_accuracy: 0.8085\n",
      "Epoch 443/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2061 - accuracy: 0.9245 - val_loss: 0.4256 - val_accuracy: 0.8085\n",
      "Epoch 444/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2992 - accuracy: 0.8491 - val_loss: 0.4234 - val_accuracy: 0.8085\n",
      "Epoch 445/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2734 - accuracy: 0.9057 - val_loss: 0.4258 - val_accuracy: 0.8085\n",
      "Epoch 446/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.1881 - accuracy: 0.9245 - val_loss: 0.4272 - val_accuracy: 0.8085\n",
      "Epoch 447/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2429 - accuracy: 0.9245 - val_loss: 0.4261 - val_accuracy: 0.8085\n",
      "Epoch 448/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.1929 - accuracy: 0.9434 - val_loss: 0.4224 - val_accuracy: 0.8085\n",
      "Epoch 449/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2383 - accuracy: 0.9057 - val_loss: 0.4187 - val_accuracy: 0.8085\n",
      "Epoch 450/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.3641 - accuracy: 0.8302 - val_loss: 0.4125 - val_accuracy: 0.8085\n",
      "Epoch 451/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2850 - accuracy: 0.8868 - val_loss: 0.4065 - val_accuracy: 0.8085\n",
      "Epoch 452/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2325 - accuracy: 0.8868 - val_loss: 0.4026 - val_accuracy: 0.8298\n",
      "Epoch 453/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2598 - accuracy: 0.9245 - val_loss: 0.4020 - val_accuracy: 0.8085\n",
      "Epoch 454/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2034 - accuracy: 0.9057 - val_loss: 0.4028 - val_accuracy: 0.8085\n",
      "Epoch 455/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2838 - accuracy: 0.9057 - val_loss: 0.4042 - val_accuracy: 0.8298\n",
      "Epoch 456/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2753 - accuracy: 0.8868 - val_loss: 0.4077 - val_accuracy: 0.8298\n",
      "Epoch 457/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2379 - accuracy: 0.8868 - val_loss: 0.4057 - val_accuracy: 0.8298\n",
      "Epoch 458/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2260 - accuracy: 0.8679 - val_loss: 0.3983 - val_accuracy: 0.8298\n",
      "Epoch 459/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2787 - accuracy: 0.8679 - val_loss: 0.3954 - val_accuracy: 0.8298\n",
      "Epoch 460/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.1772 - accuracy: 0.9057 - val_loss: 0.3922 - val_accuracy: 0.8298\n",
      "Epoch 461/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2254 - accuracy: 0.9434 - val_loss: 0.3865 - val_accuracy: 0.8298\n",
      "Epoch 462/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.3372 - accuracy: 0.9057 - val_loss: 0.3827 - val_accuracy: 0.8298\n",
      "Epoch 463/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2123 - accuracy: 0.8868 - val_loss: 0.3825 - val_accuracy: 0.8085\n",
      "Epoch 464/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2393 - accuracy: 0.8868 - val_loss: 0.3821 - val_accuracy: 0.8298\n",
      "Epoch 465/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2802 - accuracy: 0.9057 - val_loss: 0.3809 - val_accuracy: 0.8298\n",
      "Epoch 466/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2735 - accuracy: 0.8868 - val_loss: 0.3826 - val_accuracy: 0.8298\n",
      "Epoch 467/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2308 - accuracy: 0.8868 - val_loss: 0.3825 - val_accuracy: 0.8298\n",
      "Epoch 468/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.3068 - accuracy: 0.8679 - val_loss: 0.3879 - val_accuracy: 0.8298\n",
      "Epoch 469/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.1991 - accuracy: 0.9057 - val_loss: 0.3910 - val_accuracy: 0.8298\n",
      "Epoch 470/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2913 - accuracy: 0.8868 - val_loss: 0.3949 - val_accuracy: 0.8298\n",
      "Epoch 471/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2820 - accuracy: 0.8491 - val_loss: 0.3976 - val_accuracy: 0.8298\n",
      "Epoch 472/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1808 - accuracy: 0.9245 - val_loss: 0.4013 - val_accuracy: 0.8298\n",
      "Epoch 473/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2203 - accuracy: 0.8868 - val_loss: 0.4043 - val_accuracy: 0.8298\n",
      "Epoch 474/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2374 - accuracy: 0.9057 - val_loss: 0.4056 - val_accuracy: 0.8085\n",
      "Epoch 475/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2473 - accuracy: 0.9245 - val_loss: 0.4012 - val_accuracy: 0.8298\n",
      "Epoch 476/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2163 - accuracy: 0.9245 - val_loss: 0.3955 - val_accuracy: 0.8298\n",
      "Epoch 477/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.4307 - accuracy: 0.7925 - val_loss: 0.3910 - val_accuracy: 0.8298\n",
      "Epoch 478/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2651 - accuracy: 0.8679 - val_loss: 0.3848 - val_accuracy: 0.8298\n",
      "Epoch 479/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2680 - accuracy: 0.8868 - val_loss: 0.3788 - val_accuracy: 0.8298\n",
      "Epoch 480/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2599 - accuracy: 0.9245 - val_loss: 0.3767 - val_accuracy: 0.8298\n",
      "Epoch 481/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2318 - accuracy: 0.8868 - val_loss: 0.3772 - val_accuracy: 0.8298\n",
      "Epoch 482/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2600 - accuracy: 0.8868 - val_loss: 0.3784 - val_accuracy: 0.8298\n",
      "Epoch 483/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2404 - accuracy: 0.9057 - val_loss: 0.3797 - val_accuracy: 0.8298\n",
      "Epoch 484/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2561 - accuracy: 0.9057 - val_loss: 0.3768 - val_accuracy: 0.8298\n",
      "Epoch 485/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1406 - accuracy: 0.9623 - val_loss: 0.3762 - val_accuracy: 0.8298\n",
      "Epoch 486/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2261 - accuracy: 0.8679 - val_loss: 0.3791 - val_accuracy: 0.8298\n",
      "Epoch 487/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2220 - accuracy: 0.8868 - val_loss: 0.3846 - val_accuracy: 0.8298\n",
      "Epoch 488/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3450 - accuracy: 0.8868 - val_loss: 0.3924 - val_accuracy: 0.8298\n",
      "Epoch 489/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2605 - accuracy: 0.8679 - val_loss: 0.3994 - val_accuracy: 0.8298\n",
      "Epoch 490/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2310 - accuracy: 0.9057 - val_loss: 0.4083 - val_accuracy: 0.8298\n",
      "Epoch 491/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 677us/step - loss: 0.2462 - accuracy: 0.8868 - val_loss: 0.4131 - val_accuracy: 0.8298\n",
      "Epoch 492/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2517 - accuracy: 0.9057 - val_loss: 0.4141 - val_accuracy: 0.8298\n",
      "Epoch 493/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2207 - accuracy: 0.9245 - val_loss: 0.4098 - val_accuracy: 0.8298\n",
      "Epoch 494/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2754 - accuracy: 0.9434 - val_loss: 0.4066 - val_accuracy: 0.8298\n",
      "Epoch 495/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2542 - accuracy: 0.8679 - val_loss: 0.4027 - val_accuracy: 0.8298\n",
      "Epoch 496/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2899 - accuracy: 0.8868 - val_loss: 0.4018 - val_accuracy: 0.8298\n",
      "Epoch 497/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2718 - accuracy: 0.8868 - val_loss: 0.4007 - val_accuracy: 0.8298\n",
      "Epoch 498/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.1669 - accuracy: 0.9434 - val_loss: 0.4004 - val_accuracy: 0.8298\n",
      "Epoch 499/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2324 - accuracy: 0.9057 - val_loss: 0.3999 - val_accuracy: 0.8298\n",
      "Epoch 500/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2372 - accuracy: 0.9245 - val_loss: 0.3987 - val_accuracy: 0.8298\n",
      "Epoch 501/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2178 - accuracy: 0.9245 - val_loss: 0.3949 - val_accuracy: 0.8298\n",
      "Epoch 502/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2427 - accuracy: 0.9245 - val_loss: 0.3909 - val_accuracy: 0.8298\n",
      "Epoch 503/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.1951 - accuracy: 0.9245 - val_loss: 0.3862 - val_accuracy: 0.8298\n",
      "Epoch 504/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.1965 - accuracy: 0.9623 - val_loss: 0.3799 - val_accuracy: 0.8298\n",
      "Epoch 505/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2176 - accuracy: 0.8868 - val_loss: 0.3768 - val_accuracy: 0.8298\n",
      "Epoch 506/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2926 - accuracy: 0.8491 - val_loss: 0.3790 - val_accuracy: 0.8298\n",
      "Epoch 507/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3668 - accuracy: 0.8491 - val_loss: 0.3833 - val_accuracy: 0.8298\n",
      "Epoch 508/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3247 - accuracy: 0.8679 - val_loss: 0.3876 - val_accuracy: 0.8085\n",
      "Epoch 509/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3065 - accuracy: 0.9057 - val_loss: 0.3915 - val_accuracy: 0.8298\n",
      "Epoch 510/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1916 - accuracy: 0.9245 - val_loss: 0.3915 - val_accuracy: 0.8298\n",
      "Epoch 511/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2580 - accuracy: 0.9057 - val_loss: 0.3903 - val_accuracy: 0.8298\n",
      "Epoch 512/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2000 - accuracy: 0.9245 - val_loss: 0.3877 - val_accuracy: 0.8298\n",
      "Epoch 513/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2268 - accuracy: 0.9434 - val_loss: 0.3820 - val_accuracy: 0.8298\n",
      "Epoch 514/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2572 - accuracy: 0.9057 - val_loss: 0.3764 - val_accuracy: 0.8511\n",
      "Epoch 515/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.3166 - accuracy: 0.8679 - val_loss: 0.3720 - val_accuracy: 0.8511\n",
      "Epoch 516/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.1483 - accuracy: 0.9434 - val_loss: 0.3674 - val_accuracy: 0.8511\n",
      "Epoch 517/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2942 - accuracy: 0.8868 - val_loss: 0.3649 - val_accuracy: 0.8298\n",
      "Epoch 518/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2766 - accuracy: 0.8491 - val_loss: 0.3610 - val_accuracy: 0.8298\n",
      "Epoch 519/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2784 - accuracy: 0.8679 - val_loss: 0.3629 - val_accuracy: 0.8298\n",
      "Epoch 520/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3062 - accuracy: 0.8868 - val_loss: 0.3702 - val_accuracy: 0.8298\n",
      "Epoch 521/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2730 - accuracy: 0.8868 - val_loss: 0.3728 - val_accuracy: 0.8298\n",
      "Epoch 522/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2299 - accuracy: 0.9057 - val_loss: 0.3770 - val_accuracy: 0.8511\n",
      "Epoch 523/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2322 - accuracy: 0.9245 - val_loss: 0.3811 - val_accuracy: 0.8511\n",
      "Epoch 524/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2552 - accuracy: 0.8679 - val_loss: 0.3873 - val_accuracy: 0.8511\n",
      "Epoch 525/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2858 - accuracy: 0.8491 - val_loss: 0.3921 - val_accuracy: 0.8511\n",
      "Epoch 526/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2814 - accuracy: 0.8679 - val_loss: 0.4006 - val_accuracy: 0.8298\n",
      "Epoch 527/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1413 - accuracy: 0.9434 - val_loss: 0.4076 - val_accuracy: 0.8298\n",
      "Epoch 528/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1880 - accuracy: 0.9057 - val_loss: 0.4099 - val_accuracy: 0.8298\n",
      "Epoch 529/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2098 - accuracy: 0.8868 - val_loss: 0.4074 - val_accuracy: 0.8298\n",
      "Epoch 530/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2681 - accuracy: 0.8868 - val_loss: 0.4058 - val_accuracy: 0.8298\n",
      "Epoch 531/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3333 - accuracy: 0.8868 - val_loss: 0.4055 - val_accuracy: 0.8298\n",
      "Epoch 532/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2251 - accuracy: 0.8868 - val_loss: 0.3989 - val_accuracy: 0.8511\n",
      "Epoch 533/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2600 - accuracy: 0.9057 - val_loss: 0.3932 - val_accuracy: 0.8511\n",
      "Epoch 534/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2816 - accuracy: 0.8302 - val_loss: 0.3888 - val_accuracy: 0.8511\n",
      "Epoch 535/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2737 - accuracy: 0.9057 - val_loss: 0.3821 - val_accuracy: 0.8511\n",
      "Epoch 536/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2870 - accuracy: 0.8868 - val_loss: 0.3833 - val_accuracy: 0.8511\n",
      "Epoch 537/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.2979 - accuracy: 0.8302 - val_loss: 0.3855 - val_accuracy: 0.8511\n",
      "Epoch 538/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2427 - accuracy: 0.9057 - val_loss: 0.3938 - val_accuracy: 0.8511\n",
      "Epoch 539/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2362 - accuracy: 0.9245 - val_loss: 0.4055 - val_accuracy: 0.8298\n",
      "Epoch 540/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.3883 - accuracy: 0.8302 - val_loss: 0.4197 - val_accuracy: 0.8298\n",
      "Epoch 541/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2599 - accuracy: 0.9057 - val_loss: 0.4322 - val_accuracy: 0.8511\n",
      "Epoch 542/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2119 - accuracy: 0.9245 - val_loss: 0.4419 - val_accuracy: 0.8511\n",
      "Epoch 543/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1924 - accuracy: 0.9623 - val_loss: 0.4469 - val_accuracy: 0.8511\n",
      "Epoch 544/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2778 - accuracy: 0.9245 - val_loss: 0.4480 - val_accuracy: 0.8511\n",
      "Epoch 545/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2242 - accuracy: 0.9057 - val_loss: 0.4412 - val_accuracy: 0.8511\n",
      "Epoch 546/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2778 - accuracy: 0.8868 - val_loss: 0.4291 - val_accuracy: 0.8511\n",
      "Epoch 547/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2707 - accuracy: 0.9434 - val_loss: 0.4146 - val_accuracy: 0.8298\n",
      "Epoch 548/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1904 - accuracy: 0.9245 - val_loss: 0.3979 - val_accuracy: 0.8298\n",
      "Epoch 549/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2181 - accuracy: 0.9057 - val_loss: 0.3810 - val_accuracy: 0.8511\n",
      "Epoch 550/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2359 - accuracy: 0.9057 - val_loss: 0.3705 - val_accuracy: 0.8298\n",
      "Epoch 551/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2543 - accuracy: 0.9057 - val_loss: 0.3661 - val_accuracy: 0.8298\n",
      "Epoch 552/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2343 - accuracy: 0.9057 - val_loss: 0.3611 - val_accuracy: 0.8298\n",
      "Epoch 553/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2895 - accuracy: 0.8679 - val_loss: 0.3570 - val_accuracy: 0.8298\n",
      "Epoch 554/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2616 - accuracy: 0.9057 - val_loss: 0.3597 - val_accuracy: 0.8298\n",
      "Epoch 555/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2581 - accuracy: 0.8491 - val_loss: 0.3687 - val_accuracy: 0.8298\n",
      "Epoch 556/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3192 - accuracy: 0.8302 - val_loss: 0.3822 - val_accuracy: 0.8298\n",
      "Epoch 557/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2242 - accuracy: 0.9057 - val_loss: 0.3957 - val_accuracy: 0.8511\n",
      "Epoch 558/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1746 - accuracy: 0.9623 - val_loss: 0.4061 - val_accuracy: 0.8511\n",
      "Epoch 559/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2382 - accuracy: 0.9245 - val_loss: 0.4093 - val_accuracy: 0.8511\n",
      "Epoch 560/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2770 - accuracy: 0.8491 - val_loss: 0.4113 - val_accuracy: 0.8511\n",
      "Epoch 561/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3328 - accuracy: 0.9057 - val_loss: 0.4077 - val_accuracy: 0.8511\n",
      "Epoch 562/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2209 - accuracy: 0.9057 - val_loss: 0.3967 - val_accuracy: 0.8511\n",
      "Epoch 563/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2055 - accuracy: 0.9057 - val_loss: 0.3847 - val_accuracy: 0.8511\n",
      "Epoch 564/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2138 - accuracy: 0.9434 - val_loss: 0.3764 - val_accuracy: 0.8511\n",
      "Epoch 565/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2626 - accuracy: 0.9245 - val_loss: 0.3674 - val_accuracy: 0.8723\n",
      "Epoch 566/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2645 - accuracy: 0.9245 - val_loss: 0.3607 - val_accuracy: 0.8723\n",
      "Epoch 567/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1960 - accuracy: 0.9245 - val_loss: 0.3550 - val_accuracy: 0.8723\n",
      "Epoch 568/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3437 - accuracy: 0.8302 - val_loss: 0.3563 - val_accuracy: 0.8723\n",
      "Epoch 569/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1707 - accuracy: 0.9057 - val_loss: 0.3572 - val_accuracy: 0.8723\n",
      "Epoch 570/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1780 - accuracy: 0.9057 - val_loss: 0.3544 - val_accuracy: 0.8723\n",
      "Epoch 571/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2763 - accuracy: 0.9057 - val_loss: 0.3540 - val_accuracy: 0.8723\n",
      "Epoch 572/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1923 - accuracy: 0.8868 - val_loss: 0.3528 - val_accuracy: 0.8723\n",
      "Epoch 573/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2334 - accuracy: 0.9245 - val_loss: 0.3487 - val_accuracy: 0.8723\n",
      "Epoch 574/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2242 - accuracy: 0.9057 - val_loss: 0.3469 - val_accuracy: 0.8723\n",
      "Epoch 575/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3668 - accuracy: 0.8302 - val_loss: 0.3466 - val_accuracy: 0.8511\n",
      "Epoch 576/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2248 - accuracy: 0.8868 - val_loss: 0.3422 - val_accuracy: 0.8511\n",
      "Epoch 577/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.1852 - accuracy: 0.9245 - val_loss: 0.3394 - val_accuracy: 0.8511\n",
      "Epoch 578/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2071 - accuracy: 0.9057 - val_loss: 0.3378 - val_accuracy: 0.8298\n",
      "Epoch 579/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2077 - accuracy: 0.9434 - val_loss: 0.3371 - val_accuracy: 0.8298\n",
      "Epoch 580/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2557 - accuracy: 0.8868 - val_loss: 0.3392 - val_accuracy: 0.8298\n",
      "Epoch 581/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2258 - accuracy: 0.8868 - val_loss: 0.3376 - val_accuracy: 0.8298\n",
      "Epoch 582/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.4098 - accuracy: 0.8302 - val_loss: 0.3438 - val_accuracy: 0.8298\n",
      "Epoch 583/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3070 - accuracy: 0.8679 - val_loss: 0.3491 - val_accuracy: 0.8511\n",
      "Epoch 584/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3019 - accuracy: 0.8868 - val_loss: 0.3525 - val_accuracy: 0.8511\n",
      "Epoch 585/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2121 - accuracy: 0.9057 - val_loss: 0.3605 - val_accuracy: 0.8511\n",
      "Epoch 586/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.1513 - accuracy: 0.9245 - val_loss: 0.3641 - val_accuracy: 0.8723\n",
      "Epoch 587/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2802 - accuracy: 0.8679 - val_loss: 0.3650 - val_accuracy: 0.8723\n",
      "Epoch 588/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1995 - accuracy: 0.9434 - val_loss: 0.3670 - val_accuracy: 0.8723\n",
      "Epoch 589/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2452 - accuracy: 0.8868 - val_loss: 0.3649 - val_accuracy: 0.8723\n",
      "Epoch 590/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2213 - accuracy: 0.8868 - val_loss: 0.3613 - val_accuracy: 0.8723\n",
      "Epoch 591/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.2489 - accuracy: 0.8868 - val_loss: 0.3529 - val_accuracy: 0.8723\n",
      "Epoch 592/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3296 - accuracy: 0.8679 - val_loss: 0.3463 - val_accuracy: 0.8723\n",
      "Epoch 593/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2051 - accuracy: 0.9057 - val_loss: 0.3460 - val_accuracy: 0.8723\n",
      "Epoch 594/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2509 - accuracy: 0.9245 - val_loss: 0.3438 - val_accuracy: 0.8723\n",
      "Epoch 595/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2942 - accuracy: 0.8868 - val_loss: 0.3484 - val_accuracy: 0.8723\n",
      "Epoch 596/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1698 - accuracy: 0.9434 - val_loss: 0.3569 - val_accuracy: 0.8511\n",
      "Epoch 597/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2327 - accuracy: 0.9057 - val_loss: 0.3601 - val_accuracy: 0.8511\n",
      "Epoch 598/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2215 - accuracy: 0.8679 - val_loss: 0.3616 - val_accuracy: 0.8511\n",
      "Epoch 599/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1949 - accuracy: 0.9057 - val_loss: 0.3561 - val_accuracy: 0.8511\n",
      "Epoch 600/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2348 - accuracy: 0.8113 - val_loss: 0.3488 - val_accuracy: 0.8723\n",
      "Epoch 601/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1592 - accuracy: 0.9245 - val_loss: 0.3392 - val_accuracy: 0.8723\n",
      "Epoch 602/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2183 - accuracy: 0.8679 - val_loss: 0.3303 - val_accuracy: 0.8723\n",
      "Epoch 603/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 696us/step - loss: 0.2543 - accuracy: 0.8868 - val_loss: 0.3256 - val_accuracy: 0.8723\n",
      "Epoch 604/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3450 - accuracy: 0.8679 - val_loss: 0.3237 - val_accuracy: 0.8723\n",
      "Epoch 605/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2052 - accuracy: 0.9245 - val_loss: 0.3222 - val_accuracy: 0.8723\n",
      "Epoch 606/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2503 - accuracy: 0.8868 - val_loss: 0.3226 - val_accuracy: 0.8723\n",
      "Epoch 607/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3610 - accuracy: 0.8868 - val_loss: 0.3169 - val_accuracy: 0.8723\n",
      "Epoch 608/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1990 - accuracy: 0.9245 - val_loss: 0.3122 - val_accuracy: 0.8723\n",
      "Epoch 609/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2017 - accuracy: 0.9057 - val_loss: 0.3050 - val_accuracy: 0.8723\n",
      "Epoch 610/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2402 - accuracy: 0.8868 - val_loss: 0.3037 - val_accuracy: 0.8723\n",
      "Epoch 611/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1935 - accuracy: 0.9623 - val_loss: 0.3071 - val_accuracy: 0.8723\n",
      "Epoch 612/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2891 - accuracy: 0.9245 - val_loss: 0.3132 - val_accuracy: 0.8723\n",
      "Epoch 613/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2606 - accuracy: 0.9057 - val_loss: 0.3170 - val_accuracy: 0.8723\n",
      "Epoch 614/1000\n",
      "53/53 [==============================] - 0s 678us/step - loss: 0.2833 - accuracy: 0.9057 - val_loss: 0.3190 - val_accuracy: 0.8723\n",
      "Epoch 615/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3094 - accuracy: 0.8868 - val_loss: 0.3198 - val_accuracy: 0.8723\n",
      "Epoch 616/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1773 - accuracy: 0.9434 - val_loss: 0.3197 - val_accuracy: 0.8723\n",
      "Epoch 617/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.1931 - accuracy: 0.9434 - val_loss: 0.3207 - val_accuracy: 0.8723\n",
      "Epoch 618/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1513 - accuracy: 0.9057 - val_loss: 0.3239 - val_accuracy: 0.8723\n",
      "Epoch 619/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2101 - accuracy: 0.9057 - val_loss: 0.3260 - val_accuracy: 0.8511\n",
      "Epoch 620/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2319 - accuracy: 0.9057 - val_loss: 0.3317 - val_accuracy: 0.8511\n",
      "Epoch 621/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1953 - accuracy: 0.9245 - val_loss: 0.3330 - val_accuracy: 0.8511\n",
      "Epoch 622/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2236 - accuracy: 0.8868 - val_loss: 0.3319 - val_accuracy: 0.8511\n",
      "Epoch 623/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2041 - accuracy: 0.9245 - val_loss: 0.3299 - val_accuracy: 0.8511\n",
      "Epoch 624/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2215 - accuracy: 0.8868 - val_loss: 0.3305 - val_accuracy: 0.8298\n",
      "Epoch 625/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2102 - accuracy: 0.8868 - val_loss: 0.3320 - val_accuracy: 0.8298\n",
      "Epoch 626/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2396 - accuracy: 0.9057 - val_loss: 0.3298 - val_accuracy: 0.8298\n",
      "Epoch 627/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2546 - accuracy: 0.8868 - val_loss: 0.3248 - val_accuracy: 0.8298\n",
      "Epoch 628/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1944 - accuracy: 0.9245 - val_loss: 0.3209 - val_accuracy: 0.8298\n",
      "Epoch 629/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2548 - accuracy: 0.9057 - val_loss: 0.3183 - val_accuracy: 0.8511\n",
      "Epoch 630/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2741 - accuracy: 0.8868 - val_loss: 0.3194 - val_accuracy: 0.8511\n",
      "Epoch 631/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2713 - accuracy: 0.8679 - val_loss: 0.3229 - val_accuracy: 0.8723\n",
      "Epoch 632/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.1629 - accuracy: 0.9434 - val_loss: 0.3247 - val_accuracy: 0.8723\n",
      "Epoch 633/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2794 - accuracy: 0.8679 - val_loss: 0.3282 - val_accuracy: 0.8723\n",
      "Epoch 634/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2555 - accuracy: 0.9057 - val_loss: 0.3397 - val_accuracy: 0.8723\n",
      "Epoch 635/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2104 - accuracy: 0.9057 - val_loss: 0.3515 - val_accuracy: 0.8723\n",
      "Epoch 636/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2427 - accuracy: 0.8679 - val_loss: 0.3529 - val_accuracy: 0.8723\n",
      "Epoch 637/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.1901 - accuracy: 0.9245 - val_loss: 0.3530 - val_accuracy: 0.8723\n",
      "Epoch 638/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.3716 - accuracy: 0.8679 - val_loss: 0.3513 - val_accuracy: 0.8723\n",
      "Epoch 639/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3249 - accuracy: 0.8679 - val_loss: 0.3522 - val_accuracy: 0.8511\n",
      "Epoch 640/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2483 - accuracy: 0.8679 - val_loss: 0.3607 - val_accuracy: 0.8511\n",
      "Epoch 641/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1836 - accuracy: 0.9057 - val_loss: 0.3702 - val_accuracy: 0.8511\n",
      "Epoch 642/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.2021 - accuracy: 0.9245 - val_loss: 0.3812 - val_accuracy: 0.8298\n",
      "Epoch 643/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.2552 - accuracy: 0.8868 - val_loss: 0.3815 - val_accuracy: 0.8298\n",
      "Epoch 644/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.3344 - accuracy: 0.8679 - val_loss: 0.3757 - val_accuracy: 0.8723\n",
      "Epoch 645/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.1991 - accuracy: 0.9057 - val_loss: 0.3620 - val_accuracy: 0.8723\n",
      "Epoch 646/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2515 - accuracy: 0.8868 - val_loss: 0.3453 - val_accuracy: 0.8723\n",
      "Epoch 647/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2086 - accuracy: 0.9245 - val_loss: 0.3338 - val_accuracy: 0.8723\n",
      "Epoch 648/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.2330 - accuracy: 0.9057 - val_loss: 0.3243 - val_accuracy: 0.8723\n",
      "Epoch 649/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.1905 - accuracy: 0.8868 - val_loss: 0.3123 - val_accuracy: 0.8723\n",
      "Epoch 650/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2174 - accuracy: 0.9245 - val_loss: 0.3020 - val_accuracy: 0.8723\n",
      "Epoch 651/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2948 - accuracy: 0.8868 - val_loss: 0.2947 - val_accuracy: 0.8723\n",
      "Epoch 652/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2012 - accuracy: 0.9245 - val_loss: 0.2947 - val_accuracy: 0.8723\n",
      "Epoch 653/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1836 - accuracy: 0.9434 - val_loss: 0.2964 - val_accuracy: 0.8723\n",
      "Epoch 654/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2528 - accuracy: 0.8679 - val_loss: 0.3010 - val_accuracy: 0.8723\n",
      "Epoch 655/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3048 - accuracy: 0.8113 - val_loss: 0.3098 - val_accuracy: 0.8723\n",
      "Epoch 656/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1930 - accuracy: 0.9057 - val_loss: 0.3171 - val_accuracy: 0.8723\n",
      "Epoch 657/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2751 - accuracy: 0.9245 - val_loss: 0.3246 - val_accuracy: 0.8723\n",
      "Epoch 658/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.1711 - accuracy: 0.9434 - val_loss: 0.3288 - val_accuracy: 0.8723\n",
      "Epoch 659/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2892 - accuracy: 0.8491 - val_loss: 0.3294 - val_accuracy: 0.8723\n",
      "Epoch 660/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2199 - accuracy: 0.9245 - val_loss: 0.3199 - val_accuracy: 0.8723\n",
      "Epoch 661/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1665 - accuracy: 0.9057 - val_loss: 0.3115 - val_accuracy: 0.8723\n",
      "Epoch 662/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2210 - accuracy: 0.9057 - val_loss: 0.3052 - val_accuracy: 0.8723\n",
      "Epoch 663/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2425 - accuracy: 0.8868 - val_loss: 0.3065 - val_accuracy: 0.8723\n",
      "Epoch 664/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.1768 - accuracy: 0.9057 - val_loss: 0.3134 - val_accuracy: 0.8723\n",
      "Epoch 665/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2572 - accuracy: 0.9057 - val_loss: 0.3189 - val_accuracy: 0.8723\n",
      "Epoch 666/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2092 - accuracy: 0.9245 - val_loss: 0.3266 - val_accuracy: 0.8723\n",
      "Epoch 667/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.1927 - accuracy: 0.9434 - val_loss: 0.3341 - val_accuracy: 0.8723\n",
      "Epoch 668/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2021 - accuracy: 0.9245 - val_loss: 0.3446 - val_accuracy: 0.8723\n",
      "Epoch 669/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2481 - accuracy: 0.9434 - val_loss: 0.3572 - val_accuracy: 0.8723\n",
      "Epoch 670/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1844 - accuracy: 0.9245 - val_loss: 0.3686 - val_accuracy: 0.8511\n",
      "Epoch 671/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2017 - accuracy: 0.8868 - val_loss: 0.3765 - val_accuracy: 0.8511\n",
      "Epoch 672/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2757 - accuracy: 0.9057 - val_loss: 0.3799 - val_accuracy: 0.8511\n",
      "Epoch 673/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2094 - accuracy: 0.9057 - val_loss: 0.3814 - val_accuracy: 0.8511\n",
      "Epoch 674/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3064 - accuracy: 0.8679 - val_loss: 0.3742 - val_accuracy: 0.8511\n",
      "Epoch 675/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2703 - accuracy: 0.8302 - val_loss: 0.3599 - val_accuracy: 0.8723\n",
      "Epoch 676/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2130 - accuracy: 0.9057 - val_loss: 0.3456 - val_accuracy: 0.8723\n",
      "Epoch 677/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2238 - accuracy: 0.9057 - val_loss: 0.3305 - val_accuracy: 0.8723\n",
      "Epoch 678/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2401 - accuracy: 0.8868 - val_loss: 0.3214 - val_accuracy: 0.8723\n",
      "Epoch 679/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1962 - accuracy: 0.9245 - val_loss: 0.3157 - val_accuracy: 0.8723\n",
      "Epoch 680/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2547 - accuracy: 0.9057 - val_loss: 0.3134 - val_accuracy: 0.8723\n",
      "Epoch 681/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2841 - accuracy: 0.8302 - val_loss: 0.3228 - val_accuracy: 0.8723\n",
      "Epoch 682/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1832 - accuracy: 0.9434 - val_loss: 0.3233 - val_accuracy: 0.8723\n",
      "Epoch 683/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2298 - accuracy: 0.9057 - val_loss: 0.3238 - val_accuracy: 0.8723\n",
      "Epoch 684/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2682 - accuracy: 0.9057 - val_loss: 0.3282 - val_accuracy: 0.8723\n",
      "Epoch 685/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2258 - accuracy: 0.9057 - val_loss: 0.3358 - val_accuracy: 0.8723\n",
      "Epoch 686/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1597 - accuracy: 0.9623 - val_loss: 0.3374 - val_accuracy: 0.8723\n",
      "Epoch 687/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3429 - accuracy: 0.9057 - val_loss: 0.3319 - val_accuracy: 0.8723\n",
      "Epoch 688/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2020 - accuracy: 0.8679 - val_loss: 0.3195 - val_accuracy: 0.8723\n",
      "Epoch 689/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2393 - accuracy: 0.8868 - val_loss: 0.3101 - val_accuracy: 0.8723\n",
      "Epoch 690/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1357 - accuracy: 0.9623 - val_loss: 0.3077 - val_accuracy: 0.8723\n",
      "Epoch 691/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.1783 - accuracy: 0.9245 - val_loss: 0.3054 - val_accuracy: 0.8723\n",
      "Epoch 692/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2381 - accuracy: 0.9057 - val_loss: 0.3060 - val_accuracy: 0.8723\n",
      "Epoch 693/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2194 - accuracy: 0.9245 - val_loss: 0.3104 - val_accuracy: 0.8723\n",
      "Epoch 694/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2139 - accuracy: 0.9245 - val_loss: 0.3154 - val_accuracy: 0.8723\n",
      "Epoch 695/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2378 - accuracy: 0.9057 - val_loss: 0.3180 - val_accuracy: 0.8723\n",
      "Epoch 696/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1602 - accuracy: 0.9245 - val_loss: 0.3218 - val_accuracy: 0.8723\n",
      "Epoch 697/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2266 - accuracy: 0.9245 - val_loss: 0.3241 - val_accuracy: 0.8723\n",
      "Epoch 698/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2667 - accuracy: 0.8868 - val_loss: 0.3234 - val_accuracy: 0.8723\n",
      "Epoch 699/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1824 - accuracy: 0.9434 - val_loss: 0.3172 - val_accuracy: 0.8723\n",
      "Epoch 700/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3069 - accuracy: 0.8679 - val_loss: 0.3135 - val_accuracy: 0.8723\n",
      "Epoch 701/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1269 - accuracy: 0.9245 - val_loss: 0.3063 - val_accuracy: 0.8723\n",
      "Epoch 702/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.1686 - accuracy: 0.9434 - val_loss: 0.3012 - val_accuracy: 0.8723\n",
      "Epoch 703/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1849 - accuracy: 0.9245 - val_loss: 0.2939 - val_accuracy: 0.8723\n",
      "Epoch 704/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2114 - accuracy: 0.9245 - val_loss: 0.2895 - val_accuracy: 0.8723\n",
      "Epoch 705/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1307 - accuracy: 0.9811 - val_loss: 0.2870 - val_accuracy: 0.8723\n",
      "Epoch 706/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1702 - accuracy: 0.9434 - val_loss: 0.2851 - val_accuracy: 0.8723\n",
      "Epoch 707/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2594 - accuracy: 0.8302 - val_loss: 0.2823 - val_accuracy: 0.8723\n",
      "Epoch 708/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2667 - accuracy: 0.8868 - val_loss: 0.2821 - val_accuracy: 0.8723\n",
      "Epoch 709/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2156 - accuracy: 0.8868 - val_loss: 0.2848 - val_accuracy: 0.8723\n",
      "Epoch 710/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2881 - accuracy: 0.8679 - val_loss: 0.2914 - val_accuracy: 0.8723\n",
      "Epoch 711/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2317 - accuracy: 0.8868 - val_loss: 0.3087 - val_accuracy: 0.8723\n",
      "Epoch 712/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2588 - accuracy: 0.9057 - val_loss: 0.3301 - val_accuracy: 0.8723\n",
      "Epoch 713/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2028 - accuracy: 0.8868 - val_loss: 0.3471 - val_accuracy: 0.8723\n",
      "Epoch 714/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1347 - accuracy: 0.9623 - val_loss: 0.3610 - val_accuracy: 0.8723\n",
      "Epoch 715/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 659us/step - loss: 0.1771 - accuracy: 0.9245 - val_loss: 0.3683 - val_accuracy: 0.8723\n",
      "Epoch 716/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.1786 - accuracy: 0.9057 - val_loss: 0.3739 - val_accuracy: 0.8511\n",
      "Epoch 717/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2591 - accuracy: 0.8868 - val_loss: 0.3798 - val_accuracy: 0.8511\n",
      "Epoch 718/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2245 - accuracy: 0.8868 - val_loss: 0.3807 - val_accuracy: 0.8511\n",
      "Epoch 719/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2461 - accuracy: 0.9245 - val_loss: 0.3720 - val_accuracy: 0.8511\n",
      "Epoch 720/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1853 - accuracy: 0.9245 - val_loss: 0.3552 - val_accuracy: 0.8723\n",
      "Epoch 721/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2177 - accuracy: 0.9245 - val_loss: 0.3371 - val_accuracy: 0.8723\n",
      "Epoch 722/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1909 - accuracy: 0.9245 - val_loss: 0.3201 - val_accuracy: 0.8723\n",
      "Epoch 723/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2170 - accuracy: 0.9057 - val_loss: 0.3101 - val_accuracy: 0.8723\n",
      "Epoch 724/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1523 - accuracy: 0.9245 - val_loss: 0.3001 - val_accuracy: 0.8723\n",
      "Epoch 725/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2506 - accuracy: 0.9057 - val_loss: 0.2920 - val_accuracy: 0.8723\n",
      "Epoch 726/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2683 - accuracy: 0.8868 - val_loss: 0.2882 - val_accuracy: 0.8723\n",
      "Epoch 727/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2151 - accuracy: 0.9245 - val_loss: 0.2793 - val_accuracy: 0.8723\n",
      "Epoch 728/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2266 - accuracy: 0.9245 - val_loss: 0.2780 - val_accuracy: 0.8723\n",
      "Epoch 729/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.1489 - accuracy: 0.9434 - val_loss: 0.2743 - val_accuracy: 0.8723\n",
      "Epoch 730/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2577 - accuracy: 0.8679 - val_loss: 0.2741 - val_accuracy: 0.8723\n",
      "Epoch 731/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2386 - accuracy: 0.8868 - val_loss: 0.2766 - val_accuracy: 0.8723\n",
      "Epoch 732/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2230 - accuracy: 0.9057 - val_loss: 0.2834 - val_accuracy: 0.8723\n",
      "Epoch 733/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2291 - accuracy: 0.8868 - val_loss: 0.2918 - val_accuracy: 0.8723\n",
      "Epoch 734/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1984 - accuracy: 0.9057 - val_loss: 0.2974 - val_accuracy: 0.8723\n",
      "Epoch 735/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2583 - accuracy: 0.9057 - val_loss: 0.3009 - val_accuracy: 0.8723\n",
      "Epoch 736/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2754 - accuracy: 0.8679 - val_loss: 0.3044 - val_accuracy: 0.8723\n",
      "Epoch 737/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.1730 - accuracy: 0.9245 - val_loss: 0.3016 - val_accuracy: 0.8723\n",
      "Epoch 738/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2408 - accuracy: 0.9245 - val_loss: 0.2972 - val_accuracy: 0.8723\n",
      "Epoch 739/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1943 - accuracy: 0.8679 - val_loss: 0.2972 - val_accuracy: 0.8723\n",
      "Epoch 740/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2641 - accuracy: 0.8679 - val_loss: 0.3128 - val_accuracy: 0.8723\n",
      "Epoch 741/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1387 - accuracy: 0.9245 - val_loss: 0.3307 - val_accuracy: 0.8723\n",
      "Epoch 742/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1676 - accuracy: 0.9434 - val_loss: 0.3422 - val_accuracy: 0.8723\n",
      "Epoch 743/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.1843 - accuracy: 0.9245 - val_loss: 0.3463 - val_accuracy: 0.8723\n",
      "Epoch 744/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1692 - accuracy: 0.9245 - val_loss: 0.3468 - val_accuracy: 0.8723\n",
      "Epoch 745/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2394 - accuracy: 0.9057 - val_loss: 0.3431 - val_accuracy: 0.8723\n",
      "Epoch 746/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3071 - accuracy: 0.9057 - val_loss: 0.3485 - val_accuracy: 0.8723\n",
      "Epoch 747/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1828 - accuracy: 0.9245 - val_loss: 0.3535 - val_accuracy: 0.8723\n",
      "Epoch 748/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3134 - accuracy: 0.9057 - val_loss: 0.3496 - val_accuracy: 0.8723\n",
      "Epoch 749/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3294 - accuracy: 0.8491 - val_loss: 0.3511 - val_accuracy: 0.8723\n",
      "Epoch 750/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2102 - accuracy: 0.9057 - val_loss: 0.3583 - val_accuracy: 0.8723\n",
      "Epoch 751/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2628 - accuracy: 0.8491 - val_loss: 0.3671 - val_accuracy: 0.8723\n",
      "Epoch 752/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2689 - accuracy: 0.8868 - val_loss: 0.3777 - val_accuracy: 0.8723\n",
      "Epoch 753/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2522 - accuracy: 0.9057 - val_loss: 0.3851 - val_accuracy: 0.8511\n",
      "Epoch 754/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2024 - accuracy: 0.9245 - val_loss: 0.3937 - val_accuracy: 0.8511\n",
      "Epoch 755/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2891 - accuracy: 0.8679 - val_loss: 0.3972 - val_accuracy: 0.8511\n",
      "Epoch 756/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2246 - accuracy: 0.9434 - val_loss: 0.3996 - val_accuracy: 0.8511\n",
      "Epoch 757/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2501 - accuracy: 0.9057 - val_loss: 0.4022 - val_accuracy: 0.8511\n",
      "Epoch 758/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2302 - accuracy: 0.9245 - val_loss: 0.4069 - val_accuracy: 0.8511\n",
      "Epoch 759/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2320 - accuracy: 0.9245 - val_loss: 0.4092 - val_accuracy: 0.8511\n",
      "Epoch 760/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1779 - accuracy: 0.9434 - val_loss: 0.4112 - val_accuracy: 0.8511\n",
      "Epoch 761/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2023 - accuracy: 0.9057 - val_loss: 0.4089 - val_accuracy: 0.8511\n",
      "Epoch 762/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2664 - accuracy: 0.9057 - val_loss: 0.4039 - val_accuracy: 0.8511\n",
      "Epoch 763/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2390 - accuracy: 0.8868 - val_loss: 0.3960 - val_accuracy: 0.8511\n",
      "Epoch 764/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1873 - accuracy: 0.9245 - val_loss: 0.3902 - val_accuracy: 0.8511\n",
      "Epoch 765/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1202 - accuracy: 0.9623 - val_loss: 0.3835 - val_accuracy: 0.8511\n",
      "Epoch 766/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2307 - accuracy: 0.8868 - val_loss: 0.3675 - val_accuracy: 0.8723\n",
      "Epoch 767/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2461 - accuracy: 0.9057 - val_loss: 0.3501 - val_accuracy: 0.8723\n",
      "Epoch 768/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2697 - accuracy: 0.8868 - val_loss: 0.3490 - val_accuracy: 0.8723\n",
      "Epoch 769/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1961 - accuracy: 0.9245 - val_loss: 0.3501 - val_accuracy: 0.8723\n",
      "Epoch 770/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2220 - accuracy: 0.9245 - val_loss: 0.3453 - val_accuracy: 0.8723\n",
      "Epoch 771/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2060 - accuracy: 0.8679 - val_loss: 0.3481 - val_accuracy: 0.8723\n",
      "Epoch 772/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2246 - accuracy: 0.8491 - val_loss: 0.3424 - val_accuracy: 0.8723\n",
      "Epoch 773/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3373 - accuracy: 0.8679 - val_loss: 0.3352 - val_accuracy: 0.8723\n",
      "Epoch 774/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2173 - accuracy: 0.8868 - val_loss: 0.3286 - val_accuracy: 0.8723\n",
      "Epoch 775/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1999 - accuracy: 0.9434 - val_loss: 0.3162 - val_accuracy: 0.8723\n",
      "Epoch 776/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2249 - accuracy: 0.8868 - val_loss: 0.3015 - val_accuracy: 0.8723\n",
      "Epoch 777/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1642 - accuracy: 0.9245 - val_loss: 0.2911 - val_accuracy: 0.8723\n",
      "Epoch 778/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1977 - accuracy: 0.9245 - val_loss: 0.2807 - val_accuracy: 0.8723\n",
      "Epoch 779/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1870 - accuracy: 0.9057 - val_loss: 0.2786 - val_accuracy: 0.8723\n",
      "Epoch 780/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1455 - accuracy: 0.9434 - val_loss: 0.2769 - val_accuracy: 0.8723\n",
      "Epoch 781/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1746 - accuracy: 0.9245 - val_loss: 0.2750 - val_accuracy: 0.8723\n",
      "Epoch 782/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.1270 - accuracy: 0.9623 - val_loss: 0.2787 - val_accuracy: 0.8723\n",
      "Epoch 783/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1484 - accuracy: 0.9057 - val_loss: 0.2883 - val_accuracy: 0.8723\n",
      "Epoch 784/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2682 - accuracy: 0.8679 - val_loss: 0.2981 - val_accuracy: 0.8723\n",
      "Epoch 785/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1835 - accuracy: 0.9057 - val_loss: 0.3069 - val_accuracy: 0.8723\n",
      "Epoch 786/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2091 - accuracy: 0.9434 - val_loss: 0.3110 - val_accuracy: 0.8723\n",
      "Epoch 787/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0923 - accuracy: 0.9623 - val_loss: 0.3116 - val_accuracy: 0.8723\n",
      "Epoch 788/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2005 - accuracy: 0.9245 - val_loss: 0.3068 - val_accuracy: 0.8723\n",
      "Epoch 789/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2451 - accuracy: 0.9057 - val_loss: 0.3034 - val_accuracy: 0.8723\n",
      "Epoch 790/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2719 - accuracy: 0.8868 - val_loss: 0.3046 - val_accuracy: 0.8723\n",
      "Epoch 791/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2687 - accuracy: 0.8868 - val_loss: 0.3051 - val_accuracy: 0.8723\n",
      "Epoch 792/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2089 - accuracy: 0.9434 - val_loss: 0.3104 - val_accuracy: 0.8723\n",
      "Epoch 793/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1820 - accuracy: 0.8868 - val_loss: 0.3096 - val_accuracy: 0.8723\n",
      "Epoch 794/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.1854 - accuracy: 0.9245 - val_loss: 0.3105 - val_accuracy: 0.8723\n",
      "Epoch 795/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2832 - accuracy: 0.9245 - val_loss: 0.3112 - val_accuracy: 0.8723\n",
      "Epoch 796/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1789 - accuracy: 0.9245 - val_loss: 0.3150 - val_accuracy: 0.8723\n",
      "Epoch 797/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2089 - accuracy: 0.9057 - val_loss: 0.3145 - val_accuracy: 0.8723\n",
      "Epoch 798/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1848 - accuracy: 0.9057 - val_loss: 0.3099 - val_accuracy: 0.8723\n",
      "Epoch 799/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2327 - accuracy: 0.8868 - val_loss: 0.2986 - val_accuracy: 0.8723\n",
      "Epoch 800/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2323 - accuracy: 0.8679 - val_loss: 0.2933 - val_accuracy: 0.8723\n",
      "Epoch 801/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.1585 - accuracy: 0.9245 - val_loss: 0.2950 - val_accuracy: 0.8723\n",
      "Epoch 802/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2800 - accuracy: 0.8868 - val_loss: 0.3001 - val_accuracy: 0.8723\n",
      "Epoch 803/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.1949 - accuracy: 0.9057 - val_loss: 0.3085 - val_accuracy: 0.8723\n",
      "Epoch 804/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1652 - accuracy: 0.9623 - val_loss: 0.3202 - val_accuracy: 0.8723\n",
      "Epoch 805/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1515 - accuracy: 0.9434 - val_loss: 0.3348 - val_accuracy: 0.8723\n",
      "Epoch 806/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2030 - accuracy: 0.8868 - val_loss: 0.3417 - val_accuracy: 0.8723\n",
      "Epoch 807/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1702 - accuracy: 0.9057 - val_loss: 0.3491 - val_accuracy: 0.8723\n",
      "Epoch 808/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1074 - accuracy: 1.0000 - val_loss: 0.3567 - val_accuracy: 0.8723\n",
      "Epoch 809/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1984 - accuracy: 0.9623 - val_loss: 0.3635 - val_accuracy: 0.8723\n",
      "Epoch 810/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2492 - accuracy: 0.8868 - val_loss: 0.3757 - val_accuracy: 0.8723\n",
      "Epoch 811/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.1831 - accuracy: 0.9245 - val_loss: 0.3827 - val_accuracy: 0.8511\n",
      "Epoch 812/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.1218 - accuracy: 0.9623 - val_loss: 0.3816 - val_accuracy: 0.8511\n",
      "Epoch 813/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2173 - accuracy: 0.9245 - val_loss: 0.3760 - val_accuracy: 0.8723\n",
      "Epoch 814/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2103 - accuracy: 0.9245 - val_loss: 0.3730 - val_accuracy: 0.8723\n",
      "Epoch 815/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1830 - accuracy: 0.9245 - val_loss: 0.3664 - val_accuracy: 0.8723\n",
      "Epoch 816/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1452 - accuracy: 0.9623 - val_loss: 0.3553 - val_accuracy: 0.8723\n",
      "Epoch 817/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1737 - accuracy: 0.9245 - val_loss: 0.3412 - val_accuracy: 0.8723\n",
      "Epoch 818/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2106 - accuracy: 0.9057 - val_loss: 0.3268 - val_accuracy: 0.8723\n",
      "Epoch 819/1000\n",
      "53/53 [==============================] - 0s 771us/step - loss: 0.1837 - accuracy: 0.9245 - val_loss: 0.3126 - val_accuracy: 0.8723\n",
      "Epoch 820/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2501 - accuracy: 0.9245 - val_loss: 0.2996 - val_accuracy: 0.8723\n",
      "Epoch 821/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3193 - accuracy: 0.8113 - val_loss: 0.2936 - val_accuracy: 0.8723\n",
      "Epoch 822/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2406 - accuracy: 0.8868 - val_loss: 0.2825 - val_accuracy: 0.8723\n",
      "Epoch 823/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2147 - accuracy: 0.9057 - val_loss: 0.2746 - val_accuracy: 0.8723\n",
      "Epoch 824/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2297 - accuracy: 0.9245 - val_loss: 0.2665 - val_accuracy: 0.8723\n",
      "Epoch 825/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2202 - accuracy: 0.9057 - val_loss: 0.2606 - val_accuracy: 0.8723\n",
      "Epoch 826/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2424 - accuracy: 0.8868 - val_loss: 0.2614 - val_accuracy: 0.8723\n",
      "Epoch 827/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 677us/step - loss: 0.2261 - accuracy: 0.9057 - val_loss: 0.2660 - val_accuracy: 0.8723\n",
      "Epoch 828/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1571 - accuracy: 0.9245 - val_loss: 0.2755 - val_accuracy: 0.8723\n",
      "Epoch 829/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2006 - accuracy: 0.9245 - val_loss: 0.2882 - val_accuracy: 0.8723\n",
      "Epoch 830/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2174 - accuracy: 0.8868 - val_loss: 0.3091 - val_accuracy: 0.8723\n",
      "Epoch 831/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1790 - accuracy: 0.9245 - val_loss: 0.3261 - val_accuracy: 0.8723\n",
      "Epoch 832/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2406 - accuracy: 0.9245 - val_loss: 0.3391 - val_accuracy: 0.8723\n",
      "Epoch 833/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1231 - accuracy: 0.9623 - val_loss: 0.3479 - val_accuracy: 0.8723\n",
      "Epoch 834/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2153 - accuracy: 0.9245 - val_loss: 0.3588 - val_accuracy: 0.8723\n",
      "Epoch 835/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2605 - accuracy: 0.9057 - val_loss: 0.3646 - val_accuracy: 0.8723\n",
      "Epoch 836/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3357 - accuracy: 0.8868 - val_loss: 0.3651 - val_accuracy: 0.8723\n",
      "Epoch 837/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2178 - accuracy: 0.9245 - val_loss: 0.3593 - val_accuracy: 0.8723\n",
      "Epoch 838/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1824 - accuracy: 0.9245 - val_loss: 0.3519 - val_accuracy: 0.8723\n",
      "Epoch 839/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3141 - accuracy: 0.9057 - val_loss: 0.3489 - val_accuracy: 0.8723\n",
      "Epoch 840/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1816 - accuracy: 0.9434 - val_loss: 0.3433 - val_accuracy: 0.8723\n",
      "Epoch 841/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2020 - accuracy: 0.9057 - val_loss: 0.3268 - val_accuracy: 0.8723\n",
      "Epoch 842/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1428 - accuracy: 0.9245 - val_loss: 0.3075 - val_accuracy: 0.8723\n",
      "Epoch 843/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2313 - accuracy: 0.8679 - val_loss: 0.2913 - val_accuracy: 0.8723\n",
      "Epoch 844/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2895 - accuracy: 0.8679 - val_loss: 0.2833 - val_accuracy: 0.8723\n",
      "Epoch 845/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.1737 - accuracy: 0.9434 - val_loss: 0.2791 - val_accuracy: 0.8723\n",
      "Epoch 846/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2245 - accuracy: 0.8679 - val_loss: 0.2772 - val_accuracy: 0.8723\n",
      "Epoch 847/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2713 - accuracy: 0.8679 - val_loss: 0.2800 - val_accuracy: 0.8723\n",
      "Epoch 848/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2054 - accuracy: 0.9057 - val_loss: 0.2864 - val_accuracy: 0.8723\n",
      "Epoch 849/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2597 - accuracy: 0.8679 - val_loss: 0.2929 - val_accuracy: 0.8723\n",
      "Epoch 850/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1639 - accuracy: 0.9434 - val_loss: 0.2990 - val_accuracy: 0.8723\n",
      "Epoch 851/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1681 - accuracy: 0.9057 - val_loss: 0.3000 - val_accuracy: 0.8723\n",
      "Epoch 852/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1995 - accuracy: 0.9434 - val_loss: 0.2982 - val_accuracy: 0.8723\n",
      "Epoch 853/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1143 - accuracy: 0.9623 - val_loss: 0.2977 - val_accuracy: 0.8723\n",
      "Epoch 854/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2582 - accuracy: 0.8868 - val_loss: 0.3052 - val_accuracy: 0.8723\n",
      "Epoch 855/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1992 - accuracy: 0.8679 - val_loss: 0.3143 - val_accuracy: 0.8723\n",
      "Epoch 856/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2149 - accuracy: 0.9245 - val_loss: 0.3173 - val_accuracy: 0.8723\n",
      "Epoch 857/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2350 - accuracy: 0.9434 - val_loss: 0.3153 - val_accuracy: 0.8723\n",
      "Epoch 858/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1977 - accuracy: 0.9245 - val_loss: 0.3100 - val_accuracy: 0.8723\n",
      "Epoch 859/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2444 - accuracy: 0.9057 - val_loss: 0.2997 - val_accuracy: 0.8723\n",
      "Epoch 860/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2358 - accuracy: 0.9245 - val_loss: 0.2915 - val_accuracy: 0.8723\n",
      "Epoch 861/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1244 - accuracy: 0.9623 - val_loss: 0.2829 - val_accuracy: 0.8723\n",
      "Epoch 862/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1117 - accuracy: 0.9623 - val_loss: 0.2731 - val_accuracy: 0.8723\n",
      "Epoch 863/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1982 - accuracy: 0.9057 - val_loss: 0.2627 - val_accuracy: 0.8723\n",
      "Epoch 864/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.1839 - accuracy: 0.9057 - val_loss: 0.2640 - val_accuracy: 0.8723\n",
      "Epoch 865/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1988 - accuracy: 0.9057 - val_loss: 0.2603 - val_accuracy: 0.8723\n",
      "Epoch 866/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3021 - accuracy: 0.8491 - val_loss: 0.2558 - val_accuracy: 0.8723\n",
      "Epoch 867/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1780 - accuracy: 0.9623 - val_loss: 0.2502 - val_accuracy: 0.8723\n",
      "Epoch 868/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1757 - accuracy: 0.9057 - val_loss: 0.2445 - val_accuracy: 0.8723\n",
      "Epoch 869/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2782 - accuracy: 0.9057 - val_loss: 0.2422 - val_accuracy: 0.8723\n",
      "Epoch 870/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.1154 - accuracy: 0.9623 - val_loss: 0.2386 - val_accuracy: 0.8723\n",
      "Epoch 871/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2470 - accuracy: 0.8868 - val_loss: 0.2398 - val_accuracy: 0.8723\n",
      "Epoch 872/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2311 - accuracy: 0.9245 - val_loss: 0.2444 - val_accuracy: 0.8723\n",
      "Epoch 873/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.1517 - accuracy: 0.9245 - val_loss: 0.2470 - val_accuracy: 0.8723\n",
      "Epoch 874/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2008 - accuracy: 0.9245 - val_loss: 0.2502 - val_accuracy: 0.8723\n",
      "Epoch 875/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.2009 - accuracy: 0.9245 - val_loss: 0.2500 - val_accuracy: 0.8723\n",
      "Epoch 876/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.1379 - accuracy: 0.9623 - val_loss: 0.2476 - val_accuracy: 0.8723\n",
      "Epoch 877/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.1822 - accuracy: 0.9245 - val_loss: 0.2497 - val_accuracy: 0.8723\n",
      "Epoch 878/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2116 - accuracy: 0.9057 - val_loss: 0.2528 - val_accuracy: 0.8723\n",
      "Epoch 879/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0920 - accuracy: 0.9811 - val_loss: 0.2566 - val_accuracy: 0.8723\n",
      "Epoch 880/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2656 - accuracy: 0.8868 - val_loss: 0.2648 - val_accuracy: 0.8723\n",
      "Epoch 881/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.1330 - accuracy: 0.9811 - val_loss: 0.2734 - val_accuracy: 0.8723\n",
      "Epoch 882/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3058 - accuracy: 0.8491 - val_loss: 0.2734 - val_accuracy: 0.8723\n",
      "Epoch 883/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2739 - accuracy: 0.8491 - val_loss: 0.2829 - val_accuracy: 0.8723\n",
      "Epoch 884/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.1228 - accuracy: 0.9811 - val_loss: 0.2850 - val_accuracy: 0.8723\n",
      "Epoch 885/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1590 - accuracy: 0.9623 - val_loss: 0.2855 - val_accuracy: 0.8723\n",
      "Epoch 886/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2479 - accuracy: 0.8868 - val_loss: 0.2805 - val_accuracy: 0.8723\n",
      "Epoch 887/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2164 - accuracy: 0.8868 - val_loss: 0.2783 - val_accuracy: 0.8723\n",
      "Epoch 888/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.4049 - accuracy: 0.8679 - val_loss: 0.2870 - val_accuracy: 0.8723\n",
      "Epoch 889/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2791 - accuracy: 0.8679 - val_loss: 0.2994 - val_accuracy: 0.8723\n",
      "Epoch 890/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2466 - accuracy: 0.9245 - val_loss: 0.3042 - val_accuracy: 0.8723\n",
      "Epoch 891/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2061 - accuracy: 0.9245 - val_loss: 0.3103 - val_accuracy: 0.8723\n",
      "Epoch 892/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1722 - accuracy: 0.9245 - val_loss: 0.3154 - val_accuracy: 0.8723\n",
      "Epoch 893/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.1785 - accuracy: 0.9434 - val_loss: 0.3127 - val_accuracy: 0.8723\n",
      "Epoch 894/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2853 - accuracy: 0.8679 - val_loss: 0.3126 - val_accuracy: 0.8723\n",
      "Epoch 895/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2442 - accuracy: 0.8868 - val_loss: 0.3129 - val_accuracy: 0.8723\n",
      "Epoch 896/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1945 - accuracy: 0.9245 - val_loss: 0.3098 - val_accuracy: 0.8723\n",
      "Epoch 897/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2610 - accuracy: 0.9057 - val_loss: 0.3116 - val_accuracy: 0.8723\n",
      "Epoch 898/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.1728 - accuracy: 0.9057 - val_loss: 0.3128 - val_accuracy: 0.8723\n",
      "Epoch 899/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2253 - accuracy: 0.8679 - val_loss: 0.3090 - val_accuracy: 0.8723\n",
      "Epoch 900/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3468 - accuracy: 0.8679 - val_loss: 0.3084 - val_accuracy: 0.8723\n",
      "Epoch 901/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.1729 - accuracy: 0.9245 - val_loss: 0.3071 - val_accuracy: 0.8723\n",
      "Epoch 902/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1256 - accuracy: 0.9434 - val_loss: 0.3025 - val_accuracy: 0.8723\n",
      "Epoch 903/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1495 - accuracy: 0.9434 - val_loss: 0.2939 - val_accuracy: 0.8723\n",
      "Epoch 904/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1511 - accuracy: 0.9245 - val_loss: 0.2853 - val_accuracy: 0.8723\n",
      "Epoch 905/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2099 - accuracy: 0.9057 - val_loss: 0.2802 - val_accuracy: 0.8723\n",
      "Epoch 906/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1610 - accuracy: 0.9245 - val_loss: 0.2725 - val_accuracy: 0.8723\n",
      "Epoch 907/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1918 - accuracy: 0.9434 - val_loss: 0.2690 - val_accuracy: 0.8723\n",
      "Epoch 908/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2346 - accuracy: 0.8868 - val_loss: 0.2723 - val_accuracy: 0.8723\n",
      "Epoch 909/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2870 - accuracy: 0.8491 - val_loss: 0.2815 - val_accuracy: 0.8723\n",
      "Epoch 910/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1913 - accuracy: 0.9434 - val_loss: 0.2924 - val_accuracy: 0.8723\n",
      "Epoch 911/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2185 - accuracy: 0.9245 - val_loss: 0.2982 - val_accuracy: 0.8723\n",
      "Epoch 912/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2028 - accuracy: 0.9434 - val_loss: 0.3045 - val_accuracy: 0.8723\n",
      "Epoch 913/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2609 - accuracy: 0.8868 - val_loss: 0.3079 - val_accuracy: 0.8723\n",
      "Epoch 914/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2284 - accuracy: 0.9245 - val_loss: 0.3019 - val_accuracy: 0.8723\n",
      "Epoch 915/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1546 - accuracy: 0.9245 - val_loss: 0.2944 - val_accuracy: 0.8723\n",
      "Epoch 916/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2727 - accuracy: 0.9245 - val_loss: 0.2954 - val_accuracy: 0.8723\n",
      "Epoch 917/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2425 - accuracy: 0.8868 - val_loss: 0.3035 - val_accuracy: 0.8723\n",
      "Epoch 918/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2524 - accuracy: 0.8868 - val_loss: 0.3188 - val_accuracy: 0.8723\n",
      "Epoch 919/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1342 - accuracy: 0.9057 - val_loss: 0.3333 - val_accuracy: 0.8723\n",
      "Epoch 920/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1985 - accuracy: 0.9245 - val_loss: 0.3373 - val_accuracy: 0.8723\n",
      "Epoch 921/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.3901 - accuracy: 0.8679 - val_loss: 0.3320 - val_accuracy: 0.8723\n",
      "Epoch 922/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1998 - accuracy: 0.8868 - val_loss: 0.3233 - val_accuracy: 0.8723\n",
      "Epoch 923/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2828 - accuracy: 0.8679 - val_loss: 0.3188 - val_accuracy: 0.8723\n",
      "Epoch 924/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1823 - accuracy: 0.9245 - val_loss: 0.3121 - val_accuracy: 0.8723\n",
      "Epoch 925/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.1586 - accuracy: 0.9434 - val_loss: 0.3012 - val_accuracy: 0.8723\n",
      "Epoch 926/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.1591 - accuracy: 0.9434 - val_loss: 0.2871 - val_accuracy: 0.8723\n",
      "Epoch 927/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2453 - accuracy: 0.9057 - val_loss: 0.2777 - val_accuracy: 0.8723\n",
      "Epoch 928/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1662 - accuracy: 0.9434 - val_loss: 0.2709 - val_accuracy: 0.8723\n",
      "Epoch 929/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2144 - accuracy: 0.9057 - val_loss: 0.2633 - val_accuracy: 0.8723\n",
      "Epoch 930/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2153 - accuracy: 0.9057 - val_loss: 0.2601 - val_accuracy: 0.8723\n",
      "Epoch 931/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.1589 - accuracy: 0.9245 - val_loss: 0.2590 - val_accuracy: 0.8723\n",
      "Epoch 932/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.1701 - accuracy: 0.9623 - val_loss: 0.2551 - val_accuracy: 0.8723\n",
      "Epoch 933/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2975 - accuracy: 0.8868 - val_loss: 0.2506 - val_accuracy: 0.8723\n",
      "Epoch 934/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.4240 - accuracy: 0.8491 - val_loss: 0.2590 - val_accuracy: 0.8723\n",
      "Epoch 935/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1514 - accuracy: 0.9057 - val_loss: 0.2711 - val_accuracy: 0.8723\n",
      "Epoch 936/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1339 - accuracy: 0.9434 - val_loss: 0.2762 - val_accuracy: 0.8723\n",
      "Epoch 937/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1464 - accuracy: 0.9623 - val_loss: 0.2807 - val_accuracy: 0.8723\n",
      "Epoch 938/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2193 - accuracy: 0.9245 - val_loss: 0.2852 - val_accuracy: 0.8723\n",
      "Epoch 939/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 715us/step - loss: 0.2523 - accuracy: 0.8868 - val_loss: 0.2866 - val_accuracy: 0.8723\n",
      "Epoch 940/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1956 - accuracy: 0.9057 - val_loss: 0.2842 - val_accuracy: 0.8723\n",
      "Epoch 941/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.1809 - accuracy: 0.9434 - val_loss: 0.2791 - val_accuracy: 0.8723\n",
      "Epoch 942/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2642 - accuracy: 0.8679 - val_loss: 0.2717 - val_accuracy: 0.8723\n",
      "Epoch 943/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1907 - accuracy: 0.9057 - val_loss: 0.2723 - val_accuracy: 0.8723\n",
      "Epoch 944/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2966 - accuracy: 0.8491 - val_loss: 0.2824 - val_accuracy: 0.8723\n",
      "Epoch 945/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2136 - accuracy: 0.9245 - val_loss: 0.2910 - val_accuracy: 0.8723\n",
      "Epoch 946/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.1625 - accuracy: 0.9245 - val_loss: 0.2920 - val_accuracy: 0.8723\n",
      "Epoch 947/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1523 - accuracy: 0.9057 - val_loss: 0.2874 - val_accuracy: 0.8723\n",
      "Epoch 948/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2158 - accuracy: 0.9057 - val_loss: 0.2787 - val_accuracy: 0.8723\n",
      "Epoch 949/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1698 - accuracy: 0.9245 - val_loss: 0.2785 - val_accuracy: 0.8723\n",
      "Epoch 950/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2471 - accuracy: 0.8868 - val_loss: 0.2817 - val_accuracy: 0.8723\n",
      "Epoch 951/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2359 - accuracy: 0.9245 - val_loss: 0.2855 - val_accuracy: 0.8723\n",
      "Epoch 952/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2213 - accuracy: 0.9057 - val_loss: 0.2872 - val_accuracy: 0.8723\n",
      "Epoch 953/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2635 - accuracy: 0.8679 - val_loss: 0.2882 - val_accuracy: 0.8723\n",
      "Epoch 954/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2685 - accuracy: 0.8868 - val_loss: 0.2875 - val_accuracy: 0.8723\n",
      "Epoch 955/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1583 - accuracy: 0.9057 - val_loss: 0.2894 - val_accuracy: 0.8723\n",
      "Epoch 956/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2014 - accuracy: 0.9057 - val_loss: 0.2979 - val_accuracy: 0.8723\n",
      "Epoch 957/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1237 - accuracy: 0.9434 - val_loss: 0.3065 - val_accuracy: 0.8723\n",
      "Epoch 958/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1817 - accuracy: 0.9245 - val_loss: 0.3169 - val_accuracy: 0.8723\n",
      "Epoch 959/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2852 - accuracy: 0.9057 - val_loss: 0.3291 - val_accuracy: 0.8723\n",
      "Epoch 960/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2432 - accuracy: 0.9057 - val_loss: 0.3417 - val_accuracy: 0.8723\n",
      "Epoch 961/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1387 - accuracy: 0.9434 - val_loss: 0.3455 - val_accuracy: 0.8723\n",
      "Epoch 962/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2347 - accuracy: 0.9245 - val_loss: 0.3456 - val_accuracy: 0.8723\n",
      "Epoch 963/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2177 - accuracy: 0.9057 - val_loss: 0.3405 - val_accuracy: 0.8723\n",
      "Epoch 964/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1954 - accuracy: 0.9434 - val_loss: 0.3307 - val_accuracy: 0.8723\n",
      "Epoch 965/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2499 - accuracy: 0.8868 - val_loss: 0.3212 - val_accuracy: 0.8723\n",
      "Epoch 966/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2083 - accuracy: 0.8868 - val_loss: 0.3182 - val_accuracy: 0.8723\n",
      "Epoch 967/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2097 - accuracy: 0.9245 - val_loss: 0.3093 - val_accuracy: 0.8723\n",
      "Epoch 968/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1749 - accuracy: 0.9057 - val_loss: 0.2963 - val_accuracy: 0.8723\n",
      "Epoch 969/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3442 - accuracy: 0.8679 - val_loss: 0.2845 - val_accuracy: 0.8723\n",
      "Epoch 970/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3854 - accuracy: 0.8113 - val_loss: 0.2841 - val_accuracy: 0.8723\n",
      "Epoch 971/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.1668 - accuracy: 0.9245 - val_loss: 0.2852 - val_accuracy: 0.8723\n",
      "Epoch 972/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.1939 - accuracy: 0.9245 - val_loss: 0.2803 - val_accuracy: 0.8723\n",
      "Epoch 973/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2110 - accuracy: 0.9057 - val_loss: 0.2740 - val_accuracy: 0.8723\n",
      "Epoch 974/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2710 - accuracy: 0.9245 - val_loss: 0.2698 - val_accuracy: 0.8723\n",
      "Epoch 975/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2776 - accuracy: 0.8868 - val_loss: 0.2656 - val_accuracy: 0.8723\n",
      "Epoch 976/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1270 - accuracy: 0.9623 - val_loss: 0.2677 - val_accuracy: 0.8723\n",
      "Epoch 977/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1758 - accuracy: 0.9057 - val_loss: 0.2745 - val_accuracy: 0.8723\n",
      "Epoch 978/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2632 - accuracy: 0.8302 - val_loss: 0.2789 - val_accuracy: 0.8723\n",
      "Epoch 979/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1771 - accuracy: 0.9434 - val_loss: 0.2803 - val_accuracy: 0.8723\n",
      "Epoch 980/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1185 - accuracy: 0.9623 - val_loss: 0.2829 - val_accuracy: 0.8723\n",
      "Epoch 981/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1273 - accuracy: 0.9623 - val_loss: 0.2822 - val_accuracy: 0.8723\n",
      "Epoch 982/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1631 - accuracy: 0.9434 - val_loss: 0.2745 - val_accuracy: 0.8723\n",
      "Epoch 983/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2343 - accuracy: 0.9057 - val_loss: 0.2658 - val_accuracy: 0.8723\n",
      "Epoch 984/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1740 - accuracy: 0.9245 - val_loss: 0.2594 - val_accuracy: 0.8723\n",
      "Epoch 985/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1569 - accuracy: 0.9245 - val_loss: 0.2550 - val_accuracy: 0.8723\n",
      "Epoch 986/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1803 - accuracy: 0.9623 - val_loss: 0.2579 - val_accuracy: 0.8723\n",
      "Epoch 987/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.1801 - accuracy: 0.8868 - val_loss: 0.2566 - val_accuracy: 0.8723\n",
      "Epoch 988/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2092 - accuracy: 0.8868 - val_loss: 0.2535 - val_accuracy: 0.8723\n",
      "Epoch 989/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2452 - accuracy: 0.9245 - val_loss: 0.2508 - val_accuracy: 0.8723\n",
      "Epoch 990/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2856 - accuracy: 0.8679 - val_loss: 0.2488 - val_accuracy: 0.8723\n",
      "Epoch 991/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2597 - accuracy: 0.8679 - val_loss: 0.2463 - val_accuracy: 0.8723\n",
      "Epoch 992/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1340 - accuracy: 0.9434 - val_loss: 0.2390 - val_accuracy: 0.8723\n",
      "Epoch 993/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1405 - accuracy: 0.9623 - val_loss: 0.2307 - val_accuracy: 0.8723\n",
      "Epoch 994/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1140 - accuracy: 0.9434 - val_loss: 0.2247 - val_accuracy: 0.8936\n",
      "Epoch 995/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2210 - accuracy: 0.8679 - val_loss: 0.2210 - val_accuracy: 0.9149\n",
      "Epoch 996/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2154 - accuracy: 0.9245 - val_loss: 0.2206 - val_accuracy: 0.8936\n",
      "Epoch 997/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1600 - accuracy: 0.9434 - val_loss: 0.2222 - val_accuracy: 0.8936\n",
      "Epoch 998/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1257 - accuracy: 0.9245 - val_loss: 0.2228 - val_accuracy: 0.8936\n",
      "Epoch 999/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2362 - accuracy: 0.9057 - val_loss: 0.2241 - val_accuracy: 0.8723\n",
      "Epoch 1000/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1334 - accuracy: 0.9434 - val_loss: 0.2251 - val_accuracy: 0.8723\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2c7be486f60>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import History\n",
    "\n",
    "# learning rate schedule\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.0001\n",
    "    drop = 0.5\n",
    "    epochs_drop = 10.0\n",
    "    lrate = initial_lrate * np.power(drop, np.floor((1+epoch)/epochs_drop))\n",
    "    return lrate\n",
    "\n",
    "\n",
    "history_Adam_1 = History()\n",
    "model = Sequential()\n",
    "model.add(Dense(1000, use_bias=False,input_shape=(X_train.shape[1],)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(500, use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(200, use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(X_train, y_train, validation_data= (X_test, y_test), epochs=1000, callbacks=[history_Adam_1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_Adam.history['loss'], label = \"tarina\")\n",
    "plt.plot(history_Adam.history['val_loss'], label = \"test \")\n",
    "\n",
    "plt.plot(history_Adam_1.history['loss'], label = \"tarina\")\n",
    "plt.plot(history_Adam_1.history['val_loss'], label = \"test \")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n",
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from help_plot import plot_decision_regions\n",
    "plot_decision_regions(X_test, y_test, model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
