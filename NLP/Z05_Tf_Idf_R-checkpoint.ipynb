{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Przekształcenie Tf-Idf\n",
    "\n",
    "Przekształcenie to mierzy jak ważne są poszczególne słowa w poszczególnych dokumentach.\n",
    "\n",
    "Tf - term frequency - częstość słowa w dokumencie.\n",
    "\n",
    "Idf - inverse document frequency - odwrotność częstości słowa w zbiorze dokumentów.\n",
    "\n",
    "Wartość ważności słowa $w$ w dokumencie $d$ to:\n",
    "\n",
    "$$TFIDF(w,d) = tf(w,d) \\cdot idf(w).$$\n",
    "\n",
    "Istnieje wiele różnych wariantów tej miary. Podstawowa to:\n",
    "\n",
    "**tf(w,d)** - liczba wystąpień słowa $w$ w dokumencie $d$ podzielona przez liczbę wszystkich słów w dokumencie $d$;\n",
    "\n",
    "**idf(w)** - logarytm z liczby dokumentów w korpusie podzielonej przez liczbę dokumentów, w których wystąpiło słowo $w$.\n",
    "\n",
    "### https://en.wikipedia.org/wiki/Tf%E2%80%93idf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad\n",
    "Podzielmy zdania na słowa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello Mr. Smith, how are you doing today?', 'The weather is great, and Python is awesome.', 'The sky is pinkish-blue.', \"You shouldn't eat cardboard.\", \"I'm 20 years old.\"]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "EXAMPLE_TEXT = \"Hello Mr. Smith, how are you doing today? The weather is great, and Python is awesome. The sky is pinkish-blue. You shouldn't eat cardboard. I'm 20 years old.\"\n",
    "sentences = sent_tokenize(EXAMPLE_TEXT)\n",
    "\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad\n",
    "\n",
    "Wykonajmy transformatę Tf-Idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hello': 9, 'mr': 12, 'smith': 18, 'how': 10, 'are': 2, 'you': 23, 'doing': 6, 'today': 20, 'the': 19, 'weather': 21, 'is': 11, 'great': 8, 'and': 1, 'python': 15, 'awesome': 3, 'sky': 17, 'pinkish': 14, 'blue': 4, 'shouldn': 16, 'eat': 7, 'cardboard': 5, '20': 0, 'years': 22, 'old': 13}\n",
      "----\n",
      "(5, 24)\n",
      "[[0.         0.         0.36152912 0.         0.         0.\n",
      "  0.36152912 0.         0.         0.36152912 0.36152912 0.\n",
      "  0.36152912 0.         0.         0.         0.         0.\n",
      "  0.36152912 0.         0.36152912 0.         0.         0.29167942]\n",
      " [0.         0.3480587  0.         0.3480587  0.         0.\n",
      "  0.         0.         0.3480587  0.         0.         0.56162314\n",
      "  0.         0.         0.         0.3480587  0.         0.\n",
      "  0.         0.28081157 0.         0.3480587  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.48214012 0.\n",
      "  0.         0.         0.         0.         0.         0.38898761\n",
      "  0.         0.         0.48214012 0.         0.         0.48214012\n",
      "  0.         0.38898761 0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.52335825\n",
      "  0.         0.52335825 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.52335825 0.\n",
      "  0.         0.         0.         0.         0.         0.42224214]\n",
      " [0.57735027 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.57735027 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.57735027 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(sentences)\n",
    "print( tfidf_vectorizer.vocabulary_ )\n",
    "print(\"----\")\n",
    "print(tfidf_matrix.todense().shape)\n",
    "print(tfidf_matrix.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad\n",
    "\n",
    "Porównaj wynik Tf-Idf i reprezentacji bag-of-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hello': 9, 'mr': 12, 'smith': 18, 'how': 10, 'are': 2, 'you': 23, 'doing': 6, 'today': 20, 'the': 19, 'weather': 21, 'is': 11, 'great': 8, 'and': 1, 'python': 15, 'awesome': 3, 'sky': 17, 'pinkish': 14, 'blue': 4, 'shouldn': 16, 'eat': 7, 'cardboard': 5, '20': 0, 'years': 22, 'old': 13}\n",
      "----\n",
      "(5, 24)\n",
      "[[0 0 1 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 1 0 1 0 0 1]\n",
      " [0 1 0 1 0 0 0 0 1 0 0 2 0 0 0 1 0 0 0 1 0 1 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "cv_matrix = vectorizer.fit_transform(sentences)\n",
    "print( vectorizer.vocabulary_ )\n",
    "print(\"----\")\n",
    "print(cv_matrix.todense().shape)\n",
    "print(cv_matrix.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad \n",
    "Wypisz 5 najważniejszych sów w każdym, zdaniu względem Tf-Idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello' 'today' 'are' 'smith' 'doing']\n",
      "['is' 'weather' 'and' 'awesome' 'python']\n",
      "['sky' 'blue' 'pinkish' 'is' 'the']\n",
      "['cardboard' 'shouldn' 'eat' 'you' 'how']\n",
      "['20' 'old' 'years' 'how' 'and']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for i in range(len(sentences)):\n",
    "    print(np.array(tfidf_vectorizer.get_feature_names())[\n",
    "        tfidf_matrix.getrow(i).todense().argsort().A.flatten()[-5:][::-1]\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pytanie: do czego innego można zastosować TFIDF niż ważności słów w tekście?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad\n",
    "Porównaj wyniki z najczęstszymi słowami w kolejnych zdaniach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['you' 'hello' 'today' 'are' 'smith']\n",
      "['is' 'weather' 'and' 'the' 'awesome']\n",
      "['is' 'the' 'sky' 'blue' 'pinkish']\n",
      "['you' 'cardboard' 'shouldn' 'eat' 'how']\n",
      "['20' 'old' 'years' 'how' 'and']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for i in range(len(sentences)):\n",
    "    print(np.array(vectorizer.get_feature_names())[\n",
    "        cv_matrix.getrow(i).todense().argsort().A.flatten()[-5:][::-1]\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Odległość między wektorami\n",
    "\n",
    "* Znaczenia wyrazów w semantyce dystrybucyjnej są reprezentowane przez wektory liczbowe.\n",
    "\n",
    "* Odległość między wektorami będziemy interpretować jako stopień podobieństwa reprezentowanych przez nie wyrazów.\n",
    "\n",
    "* Najpopularniejszą miarą odległości dla reprezentacji wektorowej jest miara kosinusowa. \n",
    "\n",
    "* Wyrazy podobne, tzn. takie, które opisują ściśle związane ze sobą pojęcia, powinny odpowiadać wektorom leżącym blisko siebie, co oznacza, że kąt pomiędzy nimi powinien być jak najmniejszy, a co za tym idzie, kosinus tego kąta powinien być bliski 1.\n",
    "\n",
    "* Wyrazy, które nie są ze sobą powiązane semantycznie powinny być reprezentowane przez wektory ortogonalne, a więc kosinus kąta pomiędzy nimi powinien być bliski 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Różne odległości"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.spatial.distance as dis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# euclidean\n",
    "\n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.euclidean.html#scipy.spatial.distance.euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT4AAAEyCAYAAABj+rxLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n9jahk/4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = []\n",
    "for i in np.linspace(-2.0, 2.0, num=100):\n",
    "    for j in np.linspace(-2.0, 2.0, num=100):\n",
    "        if( dis.euclidean([0,0],[i,j]) < 1 ):\n",
    "            data.append( [i,j] )\n",
    "data = np.array(data)   \n",
    "\n",
    "plt.figure(figsize=(5,5));\n",
    "plt.scatter(data[:,0], data[:,1])\n",
    "plt.axis(\"equal\")\n",
    "plt.xlim(-3,3)\n",
    "plt.ylim(-3,3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cityblock\n",
    "\n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.cityblock.html#scipy.spatial.distance.cityblock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT4AAAEyCAYAAABj+rxLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQ/ABSIfgA5AOwQcgHYIPQDoEH4B0/g/j4mS1ruPBYgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = []\n",
    "for i in np.linspace(-2.0, 2.0, num=100):\n",
    "    for j in np.linspace(-2.0, 2.0, num=100):\n",
    "        if( dis.cityblock([0,0],[i,j]) < 1 ): ########### zmien p = 1,2,3\n",
    "            data.append( [i,j] )\n",
    "data = np.array(data)   \n",
    "\n",
    "plt.figure(figsize=(5,5));\n",
    "plt.scatter(data[:,0], data[:,1])\n",
    "plt.axis(\"equal\")\n",
    "plt.xlim(-3,3)\n",
    "plt.ylim(-3,3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cosine\n",
    "\n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.cosine.html#scipy.spatial.distance.cosine\n",
    "\n",
    "https://en.wikipedia.org/wiki/Cosine_similarity\n",
    "\n",
    "Miarą, która wydaje się być lepiej dopasowana do naszego przypadku jest ***podobieństwo cosinusowe***. Definiujemy je następująco:\n",
    "\n",
    "$$ sim(A, B) = \\frac{A \\cdot B}{\\|A\\| \\|B\\|} = \\frac{\\sum_{i=1}^{n}A_i B_i}{\\sqrt{\\sum_{i=1}^{n}A_i^2}\\sqrt{\\sum_{i=1}^{n}B_i^2}} $$\n",
    "\n",
    "Oczywiście łatwo wyprowadzić wzór na odległość:\n",
    "\n",
    "$$ dist(A, B) = 1 - sim(A, B) $$\n",
    "\n",
    "\n",
    "Mierzy ona podobieństwo wektorów na podstawie rozkładu wartości elementów (proporcji), a nie wartości bewzględnych. Matematycznie: podobieństwo jest określane na podstawie kąta pomiędzy wektorami (wartości cosinusa tego kąta), a nie na podstawie długości wektorów.\n",
    "\n",
    "\n",
    "https://en.wikipedia.org/wiki/Cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUwAAAEyCAYAAACRRunuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJgAkojABIBGFCQCJKEwASERhAkCi/wN8q718NgI9TQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = []\n",
    "data1 = []\n",
    "for i in np.linspace(-1., 1.0, num=10):\n",
    "    for j in np.linspace(-1., 1.0, num=10):\n",
    "        if( dis.cosine([0,1],[i,j]) < 1 ):\n",
    "            data.append( [i,j] )\n",
    "#         print(dis.cosine([0.1,0.1],[i,j]))\n",
    "        else:\n",
    "            data1.append( [i,j] )\n",
    "#             print(1)\n",
    "data = np.array(data)   \n",
    "data1 = np.array(data1)   \n",
    "\n",
    "plt.figure(figsize=(5,5));\n",
    "plt.scatter(data[:,0], data[:,1])\n",
    "plt.scatter(data1[:,0], data1[:,1])\n",
    "V = np.array([[0,1]])\n",
    "origin = [0], [0] # origin point\n",
    "\n",
    "plt.quiver(*origin, V[:,0], V[:,1], angles='xy', scale_units='xy', scale=1)\n",
    "plt.axis(\"equal\")\n",
    "plt.xlim(-2,2)\n",
    "plt.ylim(-2,2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad\n",
    "Jednym z zadań NLP jest wyszukiwanie dokumentów podobnych dla danego zapytania (wyszukiwarki internetowe).\n",
    "\n",
    "* Weźmy korpus dokumentów, jak poniżej. \n",
    "\n",
    "* Zadajemy zapytanie złorzone z \"dies, dagger\". \n",
    "\n",
    "* Prosze uszeregować dokumenty w kolejności od najbardziej pasujących. \n",
    "\n",
    "* Transformujemy query do naszej reprezentacji i liczymy odległość kosinusową (mnożenie wektorów i sumowanie)\n",
    "\n",
    "Policz odległość między zdaniami: \n",
    " * \"I eat an apple.\"\n",
    " * \"I ate the apple.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I eat an apple.', 'I eat an apple I eat an apple.', 'I eat an apple apple apple.']\n",
      "{'eat': 2, 'an': 0, 'apple': 1}\n",
      "[[1 1 1]\n",
      " [2 2 2]\n",
      " [1 3 1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "sentences = [\"I eat an apple.\", \"I eat an apple I eat an apple.\", \"I eat an apple apple apple.\"]\n",
    "\n",
    "\n",
    "print(sentences)\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(sentences)\n",
    "print( vectorizer.vocabulary_ )\n",
    "bag_of_words = vectorizer.transform(sentences)\n",
    "print(bag_of_words.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1]\n",
      "[2 2 2]\n",
      "[1 3 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "t1 = np.array(bag_of_words[0].todense()).flatten()\n",
    "t2 = np.array(bag_of_words[1].todense()).flatten()\n",
    "t3 = np.array(bag_of_words[2].todense()).flatten()\n",
    "print(t1)\n",
    "print(t2)\n",
    "print(t3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.1296117202215108\n",
      "----\n",
      "1.7320508075688772\n",
      "2.0\n",
      "----\n",
      "3\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "print(cosine(t1,t2))\n",
    "print(cosine(t1,t3))\n",
    "print(\"----\")\n",
    "print(dis.euclidean(t1,t2))\n",
    "print(dis.euclidean(t1,t3))\n",
    "print(\"----\")\n",
    "print(dis.cityblock(t1,t2))\n",
    "print(dis.cityblock(t1,t3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eat': 2, 'an': 0, 'apple': 1}\n",
      "----\n",
      "[[0.57735027 0.57735027 0.57735027]\n",
      " [0.57735027 0.57735027 0.57735027]\n",
      " [0.30151134 0.90453403 0.30151134]]\n",
      "[0.57735027 0.57735027 0.57735027]\n",
      "[0.57735027 0.57735027 0.57735027]\n",
      "[0.30151134 0.90453403 0.30151134]\n",
      "0.0\n",
      "0.1296117202215108\n",
      "----\n",
      "0.0\n",
      "0.5091399026230626\n",
      "----\n",
      "0.0\n",
      "0.8788616137673895\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(sentences)\n",
    "print( tfidf_vectorizer.vocabulary_ )\n",
    "print(\"----\")\n",
    "print(tfidf_matrix.todense())\n",
    "\n",
    "t1 = np.array(tfidf_matrix[0].todense()).flatten()\n",
    "t2 = np.array(tfidf_matrix[1].todense()).flatten()\n",
    "t3 = np.array(tfidf_matrix[2].todense()).flatten()\n",
    "print(t1)\n",
    "print(t2)\n",
    "print(t3)\n",
    "\n",
    "print(cosine(t1,t2))\n",
    "print(cosine(t1,t3))\n",
    "print(\"----\")\n",
    "print(dis.euclidean(t1,t2))\n",
    "print(dis.euclidean(t1,t3))\n",
    "print(\"----\")\n",
    "print(dis.cityblock(t1,t2))\n",
    "print(dis.cityblock(t1,t3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wniosek: Odległość cosinsusowa jest typową odległością na tekstach - ważny jest tylko kąt a nie długość.\n",
    "\n",
    "# Zad\n",
    "Znajdź najbliższe zdanie z korpusu do zestwu słów:\n",
    "\n",
    "```python\n",
    "query = [\"dies\", \"dagger\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = [\"Romeo and Juliet died\",\n",
    "         \"Juliet: O happy dagger\",\n",
    "         \"Romeo died by dagger\",\n",
    "         \"'Live free or die', that’s the New-Hampshire’s motto\",\n",
    "         \"Did you know, New-Hampshire is in New-England\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = [\"dies\", \"dagger\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformuje corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'romeo': 10, 'juliet': 5, 'die': 2, 'happi': 4, 'dagger': 1, \"'live\": 0, 'free': 3, '’': 11, 'new-hampshir': 9, 'motto': 7, 'know': 6, 'new-england': 8}\n",
      "[[0.         0.         0.50620441 0.         0.         0.60981846\n",
      "  0.         0.         0.         0.         0.60981846 0.        ]\n",
      " [0.         0.53177225 0.         0.         0.659118   0.53177225\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.60981846 0.50620441 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.60981846 0.        ]\n",
      " [0.35137655 0.         0.23532097 0.35137655 0.         0.\n",
      "  0.         0.35137655 0.         0.28348839 0.         0.70275311]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.61418897 0.         0.61418897 0.49552379 0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "def my_tokenizer(sent):\n",
    "    tokens = word_tokenize(sent)\n",
    "    stemmer = PorterStemmer()\n",
    "    res = [stemmer.stem(word) for word in tokens]\n",
    "    return res \n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(tokenizer=my_tokenizer, stop_words=stopwords.words('english') + list(string.punctuation))\n",
    "vectorizer.fit(corpus)\n",
    "print(vectorizer.vocabulary_)\n",
    "data = vectorizer.transform(corpus)\n",
    "print(data.todense())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformuje query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "query_data = vectorizer.transform(query)\n",
    "print(query_data.todense())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Liczymy odległość kosinusową"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.50620441, 0.        ],\n",
       "        [0.        , 0.53177225],\n",
       "        [0.50620441, 0.60981846],\n",
       "        [0.23532097, 0.        ],\n",
       "        [0.        , 0.        ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = np.dot(data, query_data.T).todense()\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wniosek: zapytanie \"dies, dagger\" najbardziej pasuje do \"Romeo died by dagger\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
